(undo-tree-save-format-version . 1)
"9cea0ccae2cd89511ee973f0ce6c9e01fb9f7a81"
[nil nil nil nil (25760 29781 139674 803000) 0 nil]
([nil nil ((#("# coding: utf-8
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 16 (fontified t face font-lock-comment-face)) . 23) (undo-tree-id55 . -15) (undo-tree-id56 . -16) (t 25760 29719 59449 120000)) nil (25760 29789 427838 386000) 0 nil] [nil nil ((22 . 23) (t 25760 29719 59449 120000)) ((#("3" 0 1 (fontified t face font-lock-comment-face)) . 22)) (25760 29781 139118 211000) 0 nil])
([nil nil ((#("# **Chapter 15 – Processing Sequences Using RNNs and CNNs**
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 60 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id53 . -59) (undo-tree-id54 . -60)) nil (25760 29789 427835 814000) 0 nil])
nil
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id52 . -1)) nil (25760 29789 427833 742000) 0 nil])
([nil nil ((#("# _This notebook contains all the sample code in chapter 15._
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 61 (fontified t face font-lock-comment-face) 61 62 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id49 . -61) (undo-tree-id50 . -61) (undo-tree-id51 . -62)) nil (25760 29789 427832 342000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id48 . -1)) nil (25760 29789 427829 698000) 0 nil])
([nil nil ((#("# <table align=\"left\">
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 22 (fontified t face font-lock-comment-face) 22 23 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id45 . -22) (undo-tree-id46 . -22) (undo-tree-id47 . -23)) nil (25760 29789 427827 790000) 0 nil])
([nil nil ((#("#   <td>
" 0 4 (fontified t face font-lock-comment-delimiter-face) 4 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id42 . -8) (undo-tree-id43 . -8) (undo-tree-id44 . -9)) nil (25760 29789 427824 910000) 0 nil])
([nil nil ((#("#     <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>
" 0 6 (fontified t face font-lock-comment-delimiter-face) 6 248 (fontified t face font-lock-comment-face) 248 249 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id39 . -248) (undo-tree-id40 . -248) (undo-tree-id41 . -249)) nil (25760 29789 427822 326000) 0 nil])
([nil nil ((#("#   </td>
" 0 4 (fontified t face font-lock-comment-delimiter-face) 4 9 (fontified t face font-lock-comment-face) 9 10 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id36 . -9) (undo-tree-id37 . -9) (undo-tree-id38 . -10)) nil (25760 29789 427819 746000) 0 nil])
([nil nil ((#("#   <td>
" 0 4 (fontified t face font-lock-comment-delimiter-face) 4 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id33 . -8) (undo-tree-id34 . -8) (undo-tree-id35 . -9)) nil (25760 29789 427816 944000) 0 nil])
([nil nil ((#("#     <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>
" 0 6 (fontified t face font-lock-comment-delimiter-face) 6 37 (fontified t face font-lock-comment-face) 37 59 (fontified t face font-lock-comment-face) 59 76 (fontified t face font-lock-comment-face) 76 137 (fontified t face font-lock-comment-face) 137 200 (fontified t face font-lock-comment-face) 200 240 (fontified t face font-lock-comment-face) 240 241 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id30 . -240) (undo-tree-id31 . -240) (undo-tree-id32 . -241)) nil (25760 29789 427814 21000) 0 nil])
([nil nil ((#("#   </td>
" 0 4 (fontified t face font-lock-comment-delimiter-face) 4 9 (fontified t face font-lock-comment-face) 9 10 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id27 . -9) (undo-tree-id28 . -9) (undo-tree-id29 . -10)) nil (25760 29789 427810 827000) 0 nil])
([nil nil ((#("# </table>
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 10 (fontified t face font-lock-comment-face) 10 11 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id24 . -10) (undo-tree-id25 . -10) (undo-tree-id26 . -11)) nil (25760 29789 427808 162000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id23 . -1)) nil (25760 29789 427805 134000) 0 nil])
([nil nil ((#("# # Setup
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 9 (fontified t face font-lock-comment-face) 9 10 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id20 . -9) (undo-tree-id21 . -9) (undo-tree-id22 . -10)) nil (25760 29789 427803 760000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id19 . -1)) nil (25760 29789 427801 185000) 0 nil])
([nil nil ((#("# First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 207 (fontified t face font-lock-comment-face) 207 329 (fontified t face font-lock-comment-face) 329 330 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id16 . -329) (undo-tree-id17 . -329) (undo-tree-id18 . -330)) nil (25760 29789 427799 608000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id15 . -1)) nil (25760 29789 427795 431000) 0 nil])
([nil nil ((#("# In[1]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id12 . -8) (undo-tree-id13 . -8) (undo-tree-id14 . -9)) nil (25760 29789 427791 528000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id11 . -1)) nil (25760 29789 427452 260000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id10 . -1)) nil (25760 29789 427450 789000) 0 nil])
([nil nil ((#("# Python ≥3.5 is required
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 25 (fontified t face font-lock-comment-face) 25 26 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id7 . -25) (undo-tree-id8 . -25) (undo-tree-id9 . -26)) nil (25760 29790 339850 383000) 0 nil])
([nil nil ((#("import sys
" 0 6 (fontified t face font-lock-keyword-face) 6 10 (fontified t) 10 11 (fontified t)) . 24) (undo-tree-id2695 . -10) (undo-tree-id2696 . -10) (undo-tree-id2697 . -11)) nil (25760 29817 770741 692000) 0 nil] [nil nil ((#("import sys
" 0 6 (fontified t face font-lock-keyword-face) 6 10 (fontified t) 10 11 (fontified t)) . 24) (undo-tree-id4 . -10) (undo-tree-id5 . -10) (undo-tree-id6 . -11)) ((24 . 35)) (25760 29789 630182 141000) 0 nil])
([nil nil ((#("assert sys.version_info >= (3, 5)
" 0 6 (fontified t face font-lock-keyword-face) 6 27 (fontified t) 27 28 (fontified t face (rainbow-delimiters-depth-1-face)) 28 32 (fontified t) 32 33 (fontified t face (rainbow-delimiters-depth-1-face)) 33 34 (fontified t)) . 24) (undo-tree-id2691 . -33) (undo-tree-id2692 . -33) (undo-tree-id2693 . -33) (undo-tree-id2694 . -34)) nil (25760 29817 770738 432000) 0 nil])
([nil nil ((#("assert sys.version_info >= (3, 5)
" 0 6 (fontified t face font-lock-keyword-face) 6 27 (fontified t) 27 28 (fontified t face (rainbow-delimiters-depth-1-face)) 28 32 (fontified t) 32 33 (fontified t face (rainbow-delimiters-depth-1-face)) 33 34 (fontified t)) . 24) (undo-tree-id1 . -33) (undo-tree-id2 . -33) (undo-tree-id3 . -34)) ((24 . 58)) (25760 29789 428277 776000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id2690 . -1)) nil (25760 29817 770734 229000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id0 . -1)) ((24 . 25)) (25760 29789 427435 387000) 0 nil])
([nil nil ((#("# Is this notebook running on Colab or Kaggle?
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 46 (fontified t face font-lock-comment-face) 46 47 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id2683 . -46) (undo-tree-id2684 . -47) (undo-tree-id2685 . -47) (undo-tree-id2686 . -47) (undo-tree-id2687 . -47) (undo-tree-id2688 . -46) (undo-tree-id2689 . -47)) nil (25760 29817 770731 680000) 0 nil])
nil
([nil nil ((#("IS_COLAB = \"google.colab\" in sys.modules
" 0 6 (fontified t face font-lock-variable-name-face) 6 8 (fontified t face font-lock-variable-name-face) 8 11 (fontified t) 11 25 (fontified t face font-lock-string-face) 25 26 (fontified t) 26 28 (fontified t face font-lock-keyword-face) 28 40 (fontified t) 40 41 (fontified t)) . 24) (undo-tree-id2673 . -40) (undo-tree-id2674 . -11) (undo-tree-id2675 . -41) (undo-tree-id2676 . -41) (undo-tree-id2677 . -11) (undo-tree-id2678 . -41) (undo-tree-id2679 . -41) (undo-tree-id2680 . -11) (undo-tree-id2681 . -40) (undo-tree-id2682 . -41)) nil (25760 29817 770725 179000) 0 nil])
([nil nil ((#("IS_KAGGLE = \"kaggle_secrets\" in sys.modules
" 0 9 (fontified t face font-lock-variable-name-face) 9 12 (fontified t) 12 28 (fontified t face font-lock-string-face) 28 29 (fontified t) 29 31 (fontified t face font-lock-keyword-face) 31 43 (fontified t) 43 44 (fontified t)) . 24) (undo-tree-id2667 . -43) (undo-tree-id2668 . -12) (undo-tree-id2669 . -12) (undo-tree-id2670 . -12) (undo-tree-id2671 . -43) (undo-tree-id2672 . -44)) nil (25760 29817 770717 674000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 24) (undo-tree-id2666 . -1)) nil (25760 29817 770711 526000) 0 nil])
([nil nil ((#("# Scikit-Learn ≥0.20 is required
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 32 (fontified t face font-lock-comment-face) 32 33 (fontified t face font-lock-comment-face)) . 24) (undo-tree-id2662 . -32) (undo-tree-id2663 . -33) (undo-tree-id2664 . -32) (undo-tree-id2665 . -33)) nil (25760 29817 770709 809000) 0 nil])
([nil nil ((#("# TensorFlow ≥2.0 is required
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 30 (fontified t face font-lock-comment-face)) . 77) (undo-tree-id2659 . -29) (undo-tree-id2660 . -30) (undo-tree-id2661 . -30)) nil (25760 29817 770706 335000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 76) (undo-tree-id2602 . -1) (undo-tree-id2603 . -1) (undo-tree-id2604 . -1) (undo-tree-id2605 . -1) (undo-tree-id2606 . -1) (undo-tree-id2607 . -1) (undo-tree-id2608 . -1) (undo-tree-id2609 . -1) (undo-tree-id2610 . -1) (undo-tree-id2611 . -1) (undo-tree-id2612 . -1) (undo-tree-id2613 . -1) (undo-tree-id2614 . -1) (undo-tree-id2615 . -1) (undo-tree-id2616 . -1) (undo-tree-id2617 . -1) (undo-tree-id2618 . -1) (undo-tree-id2619 . -1) (undo-tree-id2620 . -1) (undo-tree-id2621 . -1) (undo-tree-id2622 . -1) (undo-tree-id2623 . -1) (undo-tree-id2624 . -1) (undo-tree-id2625 . -1) (undo-tree-id2626 . -1) (undo-tree-id2627 . -1) (undo-tree-id2628 . -1) (undo-tree-id2629 . -1) (undo-tree-id2630 . -1) (undo-tree-id2631 . -1) (undo-tree-id2632 . -1) (undo-tree-id2633 . -1) (undo-tree-id2634 . -1) (undo-tree-id2635 . -1) (undo-tree-id2636 . -1) (undo-tree-id2637 . -1) (undo-tree-id2638 . -1) (undo-tree-id2639 . -1) (undo-tree-id2640 . -1) (undo-tree-id2641 . -1) (undo-tree-id2642 . -1) (undo-tree-id2643 . -1) (undo-tree-id2644 . -1) (undo-tree-id2645 . -1) (undo-tree-id2646 . -1) (undo-tree-id2647 . -1) (undo-tree-id2648 . -1) (undo-tree-id2649 . -1) (undo-tree-id2650 . -1) (undo-tree-id2651 . -1) (undo-tree-id2652 . -1) (undo-tree-id2653 . -1) (undo-tree-id2654 . -1) (undo-tree-id2655 . -1) (undo-tree-id2656 . -1) (undo-tree-id2657 . -1) (undo-tree-id2658 . -1)) nil (25760 29817 770701 852000) 0 nil])
([nil nil ((#("assert sklearn.__version__ >= \"0.20\"
" 0 6 (fontified t face font-lock-keyword-face) 6 30 (fontified t) 30 36 (fontified t face font-lock-string-face) 36 37 (fontified t)) . 39) (undo-tree-id2463 . -36) (undo-tree-id2464 . -37) (undo-tree-id2465 . -37) (undo-tree-id2466 . -37) (undo-tree-id2467 . -37) (undo-tree-id2468 . -37) (undo-tree-id2469 . -37) (undo-tree-id2470 . -37) (undo-tree-id2471 . -37) (undo-tree-id2472 . -37) (undo-tree-id2473 . -37) (undo-tree-id2474 . -37) (undo-tree-id2475 . -37) (undo-tree-id2476 . -37) (undo-tree-id2477 . -37) (undo-tree-id2478 . -37) (undo-tree-id2479 . -37) (undo-tree-id2480 . -37) (undo-tree-id2481 . -37) (undo-tree-id2482 . -37) (undo-tree-id2483 . -37) (undo-tree-id2484 . -37) (undo-tree-id2485 . -37) (undo-tree-id2486 . -37) (undo-tree-id2487 . -37) (undo-tree-id2488 . -37) (undo-tree-id2489 . -37) (undo-tree-id2490 . -37) (undo-tree-id2491 . -37) (undo-tree-id2492 . -37) (undo-tree-id2493 . -37) (undo-tree-id2494 . -37) (undo-tree-id2495 . -37) (undo-tree-id2496 . -37) (undo-tree-id2497 . -37) (undo-tree-id2498 . -37) (undo-tree-id2499 . -37) (undo-tree-id2500 . -37) (undo-tree-id2501 . -37) (undo-tree-id2502 . -37) (undo-tree-id2503 . -37) (undo-tree-id2504 . -37) (undo-tree-id2505 . -37) (undo-tree-id2506 . -37) (undo-tree-id2507 . -37) (undo-tree-id2508 . -37) (undo-tree-id2509 . -37) (undo-tree-id2510 . -37) (undo-tree-id2511 . -37) (undo-tree-id2512 . -37) (undo-tree-id2513 . -37) (undo-tree-id2514 . -37) (undo-tree-id2515 . -37) (undo-tree-id2516 . -37) (undo-tree-id2517 . -37) (undo-tree-id2518 . -37) (undo-tree-id2519 . -37) (undo-tree-id2520 . -37) (undo-tree-id2521 . -37) (undo-tree-id2522 . -37) (undo-tree-id2523 . -37) (undo-tree-id2524 . -37) (undo-tree-id2525 . -37) (undo-tree-id2526 . -37) (undo-tree-id2527 . -37) (undo-tree-id2528 . -37) (undo-tree-id2529 . -37) (undo-tree-id2530 . -37) (undo-tree-id2531 . -37) (undo-tree-id2532 . -37) (undo-tree-id2533 . -37) (undo-tree-id2534 . -37) (undo-tree-id2535 . -37) (undo-tree-id2536 . -37) (undo-tree-id2537 . -37) (undo-tree-id2538 . -37) (undo-tree-id2539 . -37) (undo-tree-id2540 . -37) (undo-tree-id2541 . -37) (undo-tree-id2542 . -37) (undo-tree-id2543 . -37) (undo-tree-id2544 . -37) (undo-tree-id2545 . -37) (undo-tree-id2546 . -37) (undo-tree-id2547 . -37) (undo-tree-id2548 . -37) (undo-tree-id2549 . -37) (undo-tree-id2550 . -37) (undo-tree-id2551 . -37) (undo-tree-id2552 . -37) (undo-tree-id2553 . -37) (undo-tree-id2554 . -37) (undo-tree-id2555 . -37) (undo-tree-id2556 . -37) (undo-tree-id2557 . -37) (undo-tree-id2558 . -37) (undo-tree-id2559 . -37) (undo-tree-id2560 . -37) (undo-tree-id2561 . -37) (undo-tree-id2562 . -37) (undo-tree-id2563 . -37) (undo-tree-id2564 . -37) (undo-tree-id2565 . -37) (undo-tree-id2566 . -37) (undo-tree-id2567 . -37) (undo-tree-id2568 . -37) (undo-tree-id2569 . -37) (undo-tree-id2570 . -37) (undo-tree-id2571 . -37) (undo-tree-id2572 . -37) (undo-tree-id2573 . -37) (undo-tree-id2574 . -37) (undo-tree-id2575 . -37) (undo-tree-id2576 . -37) (undo-tree-id2577 . -37) (undo-tree-id2578 . -37) (undo-tree-id2579 . -37) (undo-tree-id2580 . -37) (undo-tree-id2581 . -37) (undo-tree-id2582 . -37) (undo-tree-id2583 . -37) (undo-tree-id2584 . -37) (undo-tree-id2585 . -37) (undo-tree-id2586 . -37) (undo-tree-id2587 . -37) (undo-tree-id2588 . -37) (undo-tree-id2589 . -37) (undo-tree-id2590 . -37) (undo-tree-id2591 . -37) (undo-tree-id2592 . -37) (undo-tree-id2593 . -37) (undo-tree-id2594 . -37) (undo-tree-id2595 . -37) (undo-tree-id2596 . -37) (undo-tree-id2597 . -37) (undo-tree-id2598 . -37) (undo-tree-id2599 . -37) (undo-tree-id2600 . -37) (undo-tree-id2601 . -37)) nil (25760 29817 770659 43000) 0 nil])
([nil nil ((#("assert tf.__version__ >= \"2.0\"
" 0 6 (fontified t face font-lock-keyword-face) 6 25 (fontified t) 25 30 (fontified t face font-lock-string-face) 30 31 (fontified t)) . 92) (undo-tree-id2461 . -30) (undo-tree-id2462 . -31)) nil (25760 29817 770536 651000) 0 nil])
([nil nil ((#("if not tf.config.list_physical_devices('GPU'):
" 0 2 (fontified t face font-lock-keyword-face) 2 3 (fontified t) 3 6 (fontified t face font-lock-keyword-face) 6 38 (fontified t) 38 39 (fontified t face (rainbow-delimiters-depth-1-face)) 39 44 (fontified t face font-lock-string-face) 44 45 (fontified t face (rainbow-delimiters-depth-1-face)) 45 47 (fontified t)) . 93) (undo-tree-id2459 . -46) (undo-tree-id2460 . -47)) nil (25760 29817 770534 602000) 0 nil])
([nil nil ((#("    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")
" 0 4 (fontified t) 4 9 (fontified t face font-lock-keyword-face) 9 10 (fontified t face (rainbow-delimiters-depth-1-face)) 10 35 (fontified t face font-lock-string-face) 35 79 (fontified t face font-lock-string-face) 79 80 (fontified t face (rainbow-delimiters-depth-1-face)) 80 81 (fontified t)) . 93) (undo-tree-id2436 . -80) (undo-tree-id2437 . -4) (undo-tree-id2438 . -4) (undo-tree-id2439 . -79) (undo-tree-id2440 . -80) (undo-tree-id2441 . -4) (undo-tree-id2442 . -4) (undo-tree-id2443 . -4) (undo-tree-id2444 . -4) (undo-tree-id2445 . -4) (undo-tree-id2446 . -4) (undo-tree-id2447 . -4) (undo-tree-id2448 . -4) (undo-tree-id2449 . -4) (undo-tree-id2450 . -4) (undo-tree-id2451 . -4) (undo-tree-id2452 . -4) (undo-tree-id2453 . -4) (undo-tree-id2454 . -4) (undo-tree-id2455 . -4) (undo-tree-id2456 . -4) (undo-tree-id2457 . -80) (undo-tree-id2458 . -81)) nil (25760 29817 770530 848000) 0 nil])
([nil nil ((#("    if IS_COLAB:
" 0 4 (fontified t) 4 6 (fontified t face font-lock-keyword-face) 6 16 (fontified t) 16 17 (fontified t)) . 93) (undo-tree-id2433 . -16) (undo-tree-id2434 . -16) (undo-tree-id2435 . -17)) nil (25760 29817 770514 973000) 0 nil])
([nil nil ((#("        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")
" 0 8 (fontified t) 8 13 (fontified t face font-lock-keyword-face) 13 14 (fontified t face (rainbow-delimiters-depth-1-face)) 14 20 (fontified t face font-lock-string-face) 20 21 (fontified t face font-lock-string-face) 21 85 (fontified t face font-lock-string-face) 85 86 (fontified t face (rainbow-delimiters-depth-1-face)) 86 87 (fontified t)) . 93) (undo-tree-id2410 . -86) (undo-tree-id2411 . -8) (undo-tree-id2412 . -8) (undo-tree-id2413 . -72) (undo-tree-id2414 . -83) (undo-tree-id2415 . -8) (undo-tree-id2416 . -8) (undo-tree-id2417 . -8) (undo-tree-id2418 . -8) (undo-tree-id2419 . -8) (undo-tree-id2420 . -8) (undo-tree-id2421 . -8) (undo-tree-id2422 . -8) (undo-tree-id2423 . -8) (undo-tree-id2424 . -8) (undo-tree-id2425 . -8) (undo-tree-id2426 . -8) (undo-tree-id2427 . -8) (undo-tree-id2428 . -8) (undo-tree-id2429 . -8) (undo-tree-id2430 . -8) (undo-tree-id2431 . -86) (undo-tree-id2432 . -87)) nil (25760 29817 770511 319000) 0 nil])
([nil nil ((#("    if IS_KAGGLE:
" 0 4 (fontified t) 4 6 (fontified t face font-lock-keyword-face) 6 17 (fontified t) 17 18 (fontified t)) . 93) (undo-tree-id2407 . -17) (undo-tree-id2408 . -17) (undo-tree-id2409 . -18)) nil (25760 29817 770496 453000) 0 nil])
([nil nil ((#("        print(\"Go to Settings > Accelerator and select GPU.\")
" 0 4 (fontified t) 4 8 (fontified t) 8 13 (fontified t face font-lock-keyword-face) 13 14 (fontified t face (rainbow-delimiters-depth-1-face)) 14 60 (fontified t face font-lock-string-face) 60 61 (fontified t face (rainbow-delimiters-depth-1-face)) 61 62 (fontified t)) . 93) (undo-tree-id2386 . -61) (undo-tree-id2387 . -8) (undo-tree-id2388 . -8) (undo-tree-id2389 . -8) (undo-tree-id2390 . -8) (undo-tree-id2391 . -8) (undo-tree-id2392 . -8) (undo-tree-id2393 . -8) (undo-tree-id2394 . -8) (undo-tree-id2395 . -8) (undo-tree-id2396 . -8) (undo-tree-id2397 . -8) (undo-tree-id2398 . -8) (undo-tree-id2399 . -8) (undo-tree-id2400 . -8) (undo-tree-id2401 . -8) (undo-tree-id2402 . -8) (undo-tree-id2403 . -8) (undo-tree-id2404 . -8) (undo-tree-id2405 . -61) (undo-tree-id2406 . -62)) nil (25760 29817 770493 176000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 93) (undo-tree-id2385 . -1)) nil (25760 29817 770479 80000) 0 nil])
([nil nil ((#("# Common imports
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 16 (fontified t face font-lock-comment-face) 16 17 (fontified t face font-lock-comment-face)) . 93) (undo-tree-id2381 . -16) (undo-tree-id2382 . -17) (undo-tree-id2383 . -16) (undo-tree-id2384 . -17)) nil (25760 29817 770477 99000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 92) (undo-tree-id2028 . -1) (undo-tree-id2029 . -1) (undo-tree-id2030 . -1) (undo-tree-id2031 . -1) (undo-tree-id2032 . -1) (undo-tree-id2033 . -1) (undo-tree-id2034 . -1) (undo-tree-id2035 . -1) (undo-tree-id2036 . -1) (undo-tree-id2037 . -1) (undo-tree-id2038 . -1) (undo-tree-id2039 . -1) (undo-tree-id2040 . -1) (undo-tree-id2041 . -1) (undo-tree-id2042 . -1) (undo-tree-id2043 . -1) (undo-tree-id2044 . -1) (undo-tree-id2045 . -1) (undo-tree-id2046 . -1) (undo-tree-id2047 . -1) (undo-tree-id2048 . -1) (undo-tree-id2049 . -1) (undo-tree-id2050 . -1) (undo-tree-id2051 . -1) (undo-tree-id2052 . -1) (undo-tree-id2053 . -1) (undo-tree-id2054 . -1) (undo-tree-id2055 . -1) (undo-tree-id2056 . -1) (undo-tree-id2057 . -1) (undo-tree-id2058 . -1) (undo-tree-id2059 . -1) (undo-tree-id2060 . -1) (undo-tree-id2061 . -1) (undo-tree-id2062 . -1) (undo-tree-id2063 . -1) (undo-tree-id2064 . -1) (undo-tree-id2065 . -1) (undo-tree-id2066 . -1) (undo-tree-id2067 . -1) (undo-tree-id2068 . -1) (undo-tree-id2069 . -1) (undo-tree-id2070 . -1) (undo-tree-id2071 . -1) (undo-tree-id2072 . -1) (undo-tree-id2073 . -1) (undo-tree-id2074 . -1) (undo-tree-id2075 . -1) (undo-tree-id2076 . -1) (undo-tree-id2077 . -1) (undo-tree-id2078 . -1) (undo-tree-id2079 . -1) (undo-tree-id2080 . -1) (undo-tree-id2081 . -1) (undo-tree-id2082 . -1) (undo-tree-id2083 . -1) (undo-tree-id2084 . -1) (undo-tree-id2085 . -1) (undo-tree-id2086 . -1) (undo-tree-id2087 . -1) (undo-tree-id2088 . -1) (undo-tree-id2089 . -1) (undo-tree-id2090 . -1) (undo-tree-id2091 . -1) (undo-tree-id2092 . -1) (undo-tree-id2093 . -1) (undo-tree-id2094 . -1) (undo-tree-id2095 . -1) (undo-tree-id2096 . -1) (undo-tree-id2097 . -1) (undo-tree-id2098 . -1) (undo-tree-id2099 . -1) (undo-tree-id2100 . -1) (undo-tree-id2101 . -1) (undo-tree-id2102 . -1) (undo-tree-id2103 . -1) (undo-tree-id2104 . -1) (undo-tree-id2105 . -1) (undo-tree-id2106 . -1) (undo-tree-id2107 . -1) (undo-tree-id2108 . -1) (undo-tree-id2109 . -1) (undo-tree-id2110 . -1) (undo-tree-id2111 . -1) (undo-tree-id2112 . -1) (undo-tree-id2113 . -1) (undo-tree-id2114 . -1) (undo-tree-id2115 . -1) (undo-tree-id2116 . -1) (undo-tree-id2117 . -1) (undo-tree-id2118 . -1) (undo-tree-id2119 . -1) (undo-tree-id2120 . -1) (undo-tree-id2121 . -1) (undo-tree-id2122 . -1) (undo-tree-id2123 . -1) (undo-tree-id2124 . -1) (undo-tree-id2125 . -1) (undo-tree-id2126 . -1) (undo-tree-id2127 . -1) (undo-tree-id2128 . -1) (undo-tree-id2129 . -1) (undo-tree-id2130 . -1) (undo-tree-id2131 . -1) (undo-tree-id2132 . -1) (undo-tree-id2133 . -1) (undo-tree-id2134 . -1) (undo-tree-id2135 . -1) (undo-tree-id2136 . -1) (undo-tree-id2137 . -1) (undo-tree-id2138 . -1) (undo-tree-id2139 . -1) (undo-tree-id2140 . -1) (undo-tree-id2141 . -1) (undo-tree-id2142 . -1) (undo-tree-id2143 . -1) (undo-tree-id2144 . -1) (undo-tree-id2145 . -1) (undo-tree-id2146 . -1) (undo-tree-id2147 . -1) (undo-tree-id2148 . -1) (undo-tree-id2149 . -1) (undo-tree-id2150 . -1) (undo-tree-id2151 . -1) (undo-tree-id2152 . -1) (undo-tree-id2153 . -1) (undo-tree-id2154 . -1) (undo-tree-id2155 . -1) (undo-tree-id2156 . -1) (undo-tree-id2157 . -1) (undo-tree-id2158 . -1) (undo-tree-id2159 . -1) (undo-tree-id2160 . -1) (undo-tree-id2161 . -1) (undo-tree-id2162 . -1) (undo-tree-id2163 . -1) (undo-tree-id2164 . -1) (undo-tree-id2165 . -1) (undo-tree-id2166 . -1) (undo-tree-id2167 . -1) (undo-tree-id2168 . -1) (undo-tree-id2169 . -1) (undo-tree-id2170 . -1) (undo-tree-id2171 . -1) (undo-tree-id2172 . -1) (undo-tree-id2173 . -1) (undo-tree-id2174 . -1) (undo-tree-id2175 . -1) (undo-tree-id2176 . -1) (undo-tree-id2177 . -1) (undo-tree-id2178 . -1) (undo-tree-id2179 . -1) (undo-tree-id2180 . -1) (undo-tree-id2181 . -1) (undo-tree-id2182 . -1) (undo-tree-id2183 . -1) (undo-tree-id2184 . -1) (undo-tree-id2185 . -1) (undo-tree-id2186 . -1) (undo-tree-id2187 . -1) (undo-tree-id2188 . -1) (undo-tree-id2189 . -1) (undo-tree-id2190 . -1) (undo-tree-id2191 . -1) (undo-tree-id2192 . -1) (undo-tree-id2193 . -1) (undo-tree-id2194 . -1) (undo-tree-id2195 . -1) (undo-tree-id2196 . -1) (undo-tree-id2197 . -1) (undo-tree-id2198 . -1) (undo-tree-id2199 . -1) (undo-tree-id2200 . -1) (undo-tree-id2201 . -1) (undo-tree-id2202 . -1) (undo-tree-id2203 . -1) (undo-tree-id2204 . -1) (undo-tree-id2205 . -1) (undo-tree-id2206 . -1) (undo-tree-id2207 . -1) (undo-tree-id2208 . -1) (undo-tree-id2209 . -1) (undo-tree-id2210 . -1) (undo-tree-id2211 . -1) (undo-tree-id2212 . -1) (undo-tree-id2213 . -1) (undo-tree-id2214 . -1) (undo-tree-id2215 . -1) (undo-tree-id2216 . -1) (undo-tree-id2217 . -1) (undo-tree-id2218 . -1) (undo-tree-id2219 . -1) (undo-tree-id2220 . -1) (undo-tree-id2221 . -1) (undo-tree-id2222 . -1) (undo-tree-id2223 . -1) (undo-tree-id2224 . -1) (undo-tree-id2225 . -1) (undo-tree-id2226 . -1) (undo-tree-id2227 . -1) (undo-tree-id2228 . -1) (undo-tree-id2229 . -1) (undo-tree-id2230 . -1) (undo-tree-id2231 . -1) (undo-tree-id2232 . -1) (undo-tree-id2233 . -1) (undo-tree-id2234 . -1) (undo-tree-id2235 . -1) (undo-tree-id2236 . -1) (undo-tree-id2237 . -1) (undo-tree-id2238 . -1) (undo-tree-id2239 . -1) (undo-tree-id2240 . -1) (undo-tree-id2241 . -1) (undo-tree-id2242 . -1) (undo-tree-id2243 . -1) (undo-tree-id2244 . -1) (undo-tree-id2245 . -1) (undo-tree-id2246 . -1) (undo-tree-id2247 . -1) (undo-tree-id2248 . -1) (undo-tree-id2249 . -1) (undo-tree-id2250 . -1) (undo-tree-id2251 . -1) (undo-tree-id2252 . -1) (undo-tree-id2253 . -1) (undo-tree-id2254 . -1) (undo-tree-id2255 . -1) (undo-tree-id2256 . -1) (undo-tree-id2257 . -1) (undo-tree-id2258 . -1) (undo-tree-id2259 . -1) (undo-tree-id2260 . -1) (undo-tree-id2261 . -1) (undo-tree-id2262 . -1) (undo-tree-id2263 . -1) (undo-tree-id2264 . -1) (undo-tree-id2265 . -1) (undo-tree-id2266 . -1) (undo-tree-id2267 . -1) (undo-tree-id2268 . -1) (undo-tree-id2269 . -1) (undo-tree-id2270 . -1) (undo-tree-id2271 . -1) (undo-tree-id2272 . -1) (undo-tree-id2273 . -1) (undo-tree-id2274 . -1) (undo-tree-id2275 . -1) (undo-tree-id2276 . -1) (undo-tree-id2277 . -1) (undo-tree-id2278 . -1) (undo-tree-id2279 . -1) (undo-tree-id2280 . -1) (undo-tree-id2281 . -1) (undo-tree-id2282 . -1) (undo-tree-id2283 . -1) (undo-tree-id2284 . -1) (undo-tree-id2285 . -1) (undo-tree-id2286 . -1) (undo-tree-id2287 . -1) (undo-tree-id2288 . -1) (undo-tree-id2289 . -1) (undo-tree-id2290 . -1) (undo-tree-id2291 . -1) (undo-tree-id2292 . -1) (undo-tree-id2293 . -1) (undo-tree-id2294 . -1) (undo-tree-id2295 . -1) (undo-tree-id2296 . -1) (undo-tree-id2297 . -1) (undo-tree-id2298 . -1) (undo-tree-id2299 . -1) (undo-tree-id2300 . -1) (undo-tree-id2301 . -1) (undo-tree-id2302 . -1) (undo-tree-id2303 . -1) (undo-tree-id2304 . -1) (undo-tree-id2305 . -1) (undo-tree-id2306 . -1) (undo-tree-id2307 . -1) (undo-tree-id2308 . -1) (undo-tree-id2309 . -1) (undo-tree-id2310 . -1) (undo-tree-id2311 . -1) (undo-tree-id2312 . -1) (undo-tree-id2313 . -1) (undo-tree-id2314 . -1) (undo-tree-id2315 . -1) (undo-tree-id2316 . -1) (undo-tree-id2317 . -1) (undo-tree-id2318 . -1) (undo-tree-id2319 . -1) (undo-tree-id2320 . -1) (undo-tree-id2321 . -1) (undo-tree-id2322 . -1) (undo-tree-id2323 . -1) (undo-tree-id2324 . -1) (undo-tree-id2325 . -1) (undo-tree-id2326 . -1) (undo-tree-id2327 . -1) (undo-tree-id2328 . -1) (undo-tree-id2329 . -1) (undo-tree-id2330 . -1) (undo-tree-id2331 . -1) (undo-tree-id2332 . -1) (undo-tree-id2333 . -1) (undo-tree-id2334 . -1) (undo-tree-id2335 . -1) (undo-tree-id2336 . -1) (undo-tree-id2337 . -1) (undo-tree-id2338 . -1) (undo-tree-id2339 . -1) (undo-tree-id2340 . -1) (undo-tree-id2341 . -1) (undo-tree-id2342 . -1) (undo-tree-id2343 . -1) (undo-tree-id2344 . -1) (undo-tree-id2345 . -1) (undo-tree-id2346 . -1) (undo-tree-id2347 . -1) (undo-tree-id2348 . -1) (undo-tree-id2349 . -1) (undo-tree-id2350 . -1) (undo-tree-id2351 . -1) (undo-tree-id2352 . -1) (undo-tree-id2353 . -1) (undo-tree-id2354 . -1) (undo-tree-id2355 . -1) (undo-tree-id2356 . -1) (undo-tree-id2357 . -1) (undo-tree-id2358 . -1) (undo-tree-id2359 . -1) (undo-tree-id2360 . -1) (undo-tree-id2361 . -1) (undo-tree-id2362 . -1) (undo-tree-id2363 . -1) (undo-tree-id2364 . -1) (undo-tree-id2365 . -1) (undo-tree-id2366 . -1) (undo-tree-id2367 . -1) (undo-tree-id2368 . -1) (undo-tree-id2369 . -1) (undo-tree-id2370 . -1) (undo-tree-id2371 . -1) (undo-tree-id2372 . -1) (undo-tree-id2373 . -1) (undo-tree-id2374 . -1) (undo-tree-id2375 . -1) (undo-tree-id2376 . -1) (undo-tree-id2377 . -1) (undo-tree-id2378 . -1) (undo-tree-id2379 . -1) (undo-tree-id2380 . -1)) nil (25760 29817 770462 303000) 0 nil])
([nil nil ((#("import os
" 0 6 (fontified t face font-lock-keyword-face) 6 10 (fontified t)) . 111) (undo-tree-id2024 . -9) (undo-tree-id2025 . -6) (undo-tree-id2026 . -10) (undo-tree-id2027 . -10)) nil (25760 29817 770209 607000) 0 nil])
([nil nil ((#("# To plot pretty figures
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 20 (fontified t face font-lock-comment-face) 20 25 (fontified t face font-lock-comment-face)) . 232) (undo-tree-id1969 . -24) (undo-tree-id1970 . -25) (undo-tree-id1971 . -25) (undo-tree-id1972 . -25) (undo-tree-id1973 . -25) (undo-tree-id1974 . -25) (undo-tree-id1975 . -25) (undo-tree-id1976 . -25) (undo-tree-id1977 . -25) (undo-tree-id1978 . -25) (undo-tree-id1979 . -25) (undo-tree-id1980 . -25) (undo-tree-id1981 . -25) (undo-tree-id1982 . -25) (undo-tree-id1983 . -25) (undo-tree-id1984 . -25) (undo-tree-id1985 . -25) (undo-tree-id1986 . -25) (undo-tree-id1987 . -25) (undo-tree-id1988 . -25) (undo-tree-id1989 . -25) (undo-tree-id1990 . -25) (undo-tree-id1991 . -25) (undo-tree-id1992 . -25) (undo-tree-id1993 . -25) (undo-tree-id1994 . -25) (undo-tree-id1995 . -25) (undo-tree-id1996 . -25) (undo-tree-id1997 . -25) (undo-tree-id1998 . -25) (undo-tree-id1999 . -25) (undo-tree-id2000 . -25) (undo-tree-id2001 . -25) (undo-tree-id2002 . -25) (undo-tree-id2003 . -25) (undo-tree-id2004 . -25) (undo-tree-id2005 . -25) (undo-tree-id2006 . -25) (undo-tree-id2007 . -25) (undo-tree-id2008 . -25) (undo-tree-id2009 . -25) (undo-tree-id2010 . -25) (undo-tree-id2011 . -25) (undo-tree-id2012 . -25) (undo-tree-id2013 . -25) (undo-tree-id2014 . -25) (undo-tree-id2015 . -25) (undo-tree-id2016 . -25) (undo-tree-id2017 . -25) (undo-tree-id2018 . -25) (undo-tree-id2019 . -25) (undo-tree-id2020 . -25) (undo-tree-id2021 . -25) (undo-tree-id2022 . -25) (undo-tree-id2023 . -25)) nil (25760 29817 770203 990000) 0 nil])
([nil nil ((#("get_ipython().run_line_magic('matplotlib', 'inline')
" 0 11 (fontified t) 11 12 (fontified t face (rainbow-delimiters-depth-1-face)) 12 13 (fontified t face (rainbow-delimiters-depth-1-face)) 13 28 (fontified t) 28 29 (fontified t face (rainbow-delimiters-depth-1-face)) 29 41 (fontified t face font-lock-string-face) 41 43 (fontified t) 43 51 (fontified t face font-lock-string-face) 51 52 (fontified t face (rainbow-delimiters-depth-1-face)) 52 53 (fontified t)) . 232) (undo-tree-id1963 . -52) (undo-tree-id1964 . -11) (undo-tree-id1965 . -53) (undo-tree-id1966 . -52) (undo-tree-id1967 . -11) (undo-tree-id1968 . -53)) nil (25760 29817 770157 263000) 0 nil])
([nil nil ((1 . 42655) (#("#!/usr/bin/env python

import sklearn
import tensorflow as tf
from tensorflow import keras
import numpy as np
from pathlib import Path

# to make this notebook's output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = \".\"
CHAPTER_ID = \"rnn\"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)
    print(\"Saving figure\", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)


# # Basic RNNs

# ## Generate the Dataset

# In[2]:


def generate_time_series(batch_size, n_steps):
    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)
    time = np.linspace(0, 1, n_steps)
    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1
    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2
    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise
    return series[..., np.newaxis].astype(np.float32)


# In[3]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]


# In[4]:


X_train.shape, y_train.shape


# In[5]:


def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True):
    plt.plot(series, \".-\")
    if y is not None:
        plt.plot(n_steps, y, \"bo\", label=\"Target\")
    if y_pred is not None:
        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=\"upper left\")

fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(X_valid[col, :, 0], y_valid[col, 0],
                y_label=(\"$x(t)$\" if col==0 else None),
                legend=(col == 0))
save_fig(\"time_series_plot\")
plt.show()


# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.

# ## Computing Some Baselines

# Naive predictions (just predict the last observed value):

# In[6]:


y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))


# In[7]:


plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Linear predictions:

# In[8]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[50, 1]),
    keras.layers.Dense(1)
])

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))


# In[9]:


model.evaluate(X_valid, y_valid)


# In[10]:


def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(\"Epochs\")
    plt.ylabel(\"Loss\")
    plt.grid(True)

plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[11]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Using a Simple RNN

# In[12]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(1, input_shape=[None, 1])
])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=\"mse\", optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))


# In[13]:


model.evaluate(X_valid, y_valid)


# In[14]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[15]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Deep RNNs

# In[16]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.SimpleRNN(1)
])

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))


# In[17]:


model.evaluate(X_valid, y_valid)


# In[18]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[19]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Make the second `SimpleRNN` layer return only the last output:

# In[20]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20),
    keras.layers.Dense(1)
])

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))


# In[21]:


model.evaluate(X_valid, y_valid)


# In[22]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[23]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Forecasting Several Steps Ahead

# In[24]:


np.random.seed(43) # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]


# In[25]:


Y_pred.shape


# In[26]:


def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")
    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"rx-\", label=\"Forecast\", markersize=10)
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)

plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(\"forecast_ahead_plot\")
plt.show()


# Now let's use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.

# In[27]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]


# Now let's predict the next 10 values one by one:

# In[28]:


X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]


# In[29]:


Y_pred.shape


# In[30]:


np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))


# Let's compare this performance with some baselines: naive predictions and a simple linear model:

# In[31]:


Y_naive_pred = np.tile(X_valid[:, -1], 10) # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))


# In[32]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[50, 1]),
    keras.layers.Dense(10)
])

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# Now let's create an RNN that predicts all 10 next values at once:

# In[33]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20),
    keras.layers.Dense(10)
])

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# In[34]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]


# In[35]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# Now let's create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.

# In[36]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]


# In[37]:


X_train.shape, Y_train.shape


# In[38]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])

model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# In[39]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[40]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # Deep RNN with Batch Norm

# In[41]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.BatchNormalization(),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.BatchNormalization(),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# # Deep RNNs with Layer Norm

# In[42]:


from tensorflow.keras.layers import LayerNormalization


# In[43]:


class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,
                                                          activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)
    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]
    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]


# In[44]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,
                     input_shape=[None, 1]),
    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# # Creating a Custom RNN Class

# In[45]:


class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, \"get_initial_state\", self.fallback_initial_state)
    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]
    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0))
        outputs = tf.zeros(shape=[batch_size, self.cell.output_size], dtype=inputs.dtype)
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs


# In[46]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    MyRNN(LNSimpleRNNCell(20), return_sequences=True,
          input_shape=[None, 1]),
    MyRNN(LNSimpleRNNCell(20), return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# # LSTMs

# In[47]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.LSTM(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# In[48]:


model.evaluate(X_valid, Y_valid)


# In[49]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[50]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[51]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # GRUs

# In[52]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# In[53]:


model.evaluate(X_valid, Y_valid)


# In[54]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[55]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[56]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# ## Using One-Dimensional Convolutional Layers to Process Sequences

# ```
# 1D conv layer with kernel size 4, stride 2, VALID padding:
# 
#               |-----2-----|     |-----5---...------|     |-----23----|
#         |-----1-----|     |-----4-----|   ...      |-----22----|
#   |-----0----|      |-----3-----|     |---...|-----21----|
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 42 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 43 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 52 53 54 55 56 57 58 59
# 
# Output:
# 
# X:     0/3   2/5   4/7   6/9   8/11 10/13 .../43 42/45 44/47 46/49
# Y:     4/13  6/15  8/17 10/19 12/21 14/23 .../53 46/55 48/57 50/59
# ```

# In[57]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",
                        input_shape=[None, 1]),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train[:, 3::2], epochs=20,
                    validation_data=(X_valid, Y_valid[:, 3::2]))


# ## WaveNet

# ```
# C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\.../\\ /\\ /\\ /\\ /\\ /\\
#    \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\       /  \\  /  \\  /  \\
#      /    \\      /    \\      /    \\                 /    \\
# C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /.../\\ /\\ /\\ /\\ /\\ /\\ /\\
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 53 54 55 56 57 58 59
# ```

# In[58]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",
                                  activation=\"relu\", dilation_rate=rate))
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))


# Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:

# In[59]:


class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)
    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate


# In[60]:


def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=\"causal\",
                            dilation_rate=dilation_rate)(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z


# In[61]:


keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3 # 10 in the paper
n_blocks = 1 # 3 in the paper
n_filters = 32 # 128 in the paper
n_outputs = 10 # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)
skip_to_last = []
for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])


# In[62]:


model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2,
                    validation_data=(X_valid, Y_valid))


# In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.

# # Exercise solutions

# ## 1. to 8.

# See Appendix A.

# ## 9. Tackling the SketchRNN Dataset

# _Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets._

# The dataset is not available in TFDS yet, the [pull request](https://github.com/tensorflow/datasets/pull/361) is still work in progress. Luckily, the data is conveniently available as TFRecords, so let's download it (it might take a while, as it's about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):

# In[63]:


DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"
FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=\"datasets/quickdraw\",
                                extract=True)


# In[64]:


quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])


# In[65]:


train_files


# In[66]:


eval_files


# In[67]:


with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:
    test_classes = test_classes_file.readlines()
    
with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:
    train_classes = train_classes_file.readlines()


# In[68]:


assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]


# In[69]:


sorted(class_names)


# In[70]:


def parse(data_batch):
    feature_descriptions = {
        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),
        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),
        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64)
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[\"shape\"][:, 0]
    labels = examples[\"class_index\"][:, 0]
    return sketches, lengths, labels


# In[71]:


def quickdraw_dataset(filepaths, batch_size=32, shuffle_buffer_size=None,
                      n_parse_threads=5, n_read_threads=5, cache=False):
    dataset = tf.data.TFRecordDataset(filepaths,
                                      num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)


# In[72]:


train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])


# In[73]:


for sketches, lengths, labels in train_set.take(1):
    print(\"sketches =\", sketches)
    print(\"lengths =\", lengths)
    print(\"labels =\", labels)


# In[74]:


def draw_sketch(sketch, label=None):
    origin = np.array([[0., 0., 0.]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1]==1.)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else \"Try to guess\"
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")
    plt.axis(\"off\")

def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(range(n_sketches), sketches, lengths, labels):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()

for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)


# Most sketches are composed of less than 100 points:

# In[75]:


lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(\"length\")
plt.ylabel(\"density\")
plt.show()


# In[76]:


def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))

cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)


# In[77]:


model = keras.models.Sequential([
    keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(128, return_sequences=True),
    keras.layers.LSTM(128),
    keras.layers.Dense(len(class_names), activation=\"softmax\")
])
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.)
model.compile(loss=\"sparse_categorical_crossentropy\",
              optimizer=optimizer,
              metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"])
history = model.fit(cropped_train_set, epochs=2,
                    validation_data=cropped_valid_set)


# In[78]:


y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)


# In[79]:


np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))


# In[80]:


n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(\"Top-5 predictions:\".format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))
    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))


# In[81]:


model.save(\"my_sketchrnn\")


# ## 10. Bach Chorales
# _Exercise: Download the [Bach chorales](https://homl.info/bach) dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out [Google's Coconet model](https://homl.info/coconet), which was used for a nice [Google doodle about Bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)._
# 
# 

# In[82]:


DOWNLOAD_ROOT = \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"
FILENAME = \"jsb_chorales.tgz\"
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=\"datasets/jsb_chorales\",
                                extract=True)


# In[83]:


jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))
valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))
test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))


# In[84]:


import pandas as pd

def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]

train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)


# In[85]:


train_chorales[0]


# Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:

# In[86]:


notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81


# Let's write a few functions to listen to these chorales (you don't need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):

# In[87]:


from IPython.display import Audio

def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440

def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 9.).reshape(-1, 1)
    return sine_waves.reshape(-1)

def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer
    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)
                     for melody in freqs.T], axis=0)
    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note
    fade_out = np.linspace(1., 0., n_fade_out_samples)**2
    merged[-n_fade_out_samples:] *= fade_out
    return merged

def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile
        samples = (2**15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))


# Now let's listen to a few chorales:

# In[88]:


for index in range(3):
    play_chords(train_chorales[index])


# Divine! :)

# In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don't go very well together (believe me, I tried). It's much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.
# 
# We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).
# 
# And we will train the model on windows of 128 notes (i.e., 32 chords).
# 
# Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).

# In[89]:


def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:] # predict next note in each arpegio, at each step
    return X, Y

def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1) # shift values
    return tf.reshape(window, [-1]) # convert to arpegio

def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,
                 window_size=32, window_shift=16, cache=True):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)


# Now let's create the training set, the validation set and the test set:

# In[90]:


train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)


# Now let's create the model:
# 
# * We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C\\#3, it's very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an `Embedding` layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of `[batch_size, window_size, 5]`.
# * We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 `Conv1D` layers with doubling dilation rates. We will intersperse these layers with `BatchNormalization` layers for faster better convergence.
# * Then one `LSTM` layer to try to capture long-term patterns.
# * And finally a `Dense` layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be `[batch_size, window_size, 47]`.

# In[91]:


n_embedding_dims = 5

model = keras.models.Sequential([
    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,
                           input_shape=[None]),
    keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(256, return_sequences=True),
    keras.layers.Dense(n_notes, activation=\"softmax\")
])

model.summary()


# Now we're ready to compile and train the model!

# In[92]:


optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,
              metrics=[\"accuracy\"])
model.fit(train_set, epochs=20, validation_data=valid_set)


# I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the `LSTM` layer and replacing it with `Conv1D` layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.

# Once you're satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:

# In[93]:


model.save(\"my_bach_model.h5\")
model.evaluate(test_set)


# **Note:** There's no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.

# Now let's write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.

# **Warning**: `model.predict_classes(X)` is deprecated. It is replaced with `np.argmax(model.predict(X), axis=-1)`.

# In[94]:


def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            #next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# To test this function, we need some seed chords. Let's use the first 8 chords of one of the test chorales (it's actually just 2 different chords, each played 4 times):

# In[95]:


seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)


# Now we are ready to generate our first chorale! Let's ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):

# In[96]:


new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)


# This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.
# 
# So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a `temperature` parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.

# In[97]:


def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# Let's generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!
# 
# **Please share your most beautiful generated chorale with me on Twitter @aureliengeron, I would really appreciate it! :))**

# In[98]:


new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")


# In[99]:


new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")


# In[100]:


new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")


# Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!

# In[101]:


play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")

" 0 1 (fontified t face font-lock-comment-delimiter-face) 1 22 (fontified t face font-lock-comment-face) 22 23 (fontified t) 23 29 (fontified t face font-lock-keyword-face) 29 37 (fontified t) 37 38 (fontified t) 38 44 (fontified t face font-lock-keyword-face) 44 56 (fontified t) 56 58 (fontified t face font-lock-keyword-face) 58 61 (fontified t) 61 62 (fontified t) 62 66 (fontified t face font-lock-keyword-face) 66 78 (fontified t) 78 84 (fontified t face font-lock-keyword-face) 84 91 (fontified t) 91 93 (fontified t face font-lock-keyword-face) 93 97 (fontified t face font-lock-keyword-face) 97 104 (fontified t) 104 106 (fontified t face font-lock-keyword-face) 106 108 (fontified t) 108 109 (fontified t) 109 110 (fontified t) 110 114 (fontified t face font-lock-keyword-face) 114 123 (fontified t) 123 129 (fontified t face font-lock-keyword-face) 129 134 (fontified t) 134 135 (fontified t) 135 136 (fontified t) 136 138 (fontified t face font-lock-comment-delimiter-face) 138 188 (fontified t face font-lock-comment-face) 188 190 (fontified t) 190 202 (fontified t) 202 203 (fontified t face (rainbow-delimiters-depth-1-face)) 203 205 (fontified t) 205 206 (fontified t face (rainbow-delimiters-depth-1-face)) 206 207 (fontified t) 207 225 (fontified t) 225 226 (fontified t face (rainbow-delimiters-depth-1-face)) 226 228 (fontified t) 228 229 (fontified t face (rainbow-delimiters-depth-1-face)) 229 231 (fontified t) 231 237 (fontified t face font-lock-keyword-face) 237 249 (fontified t) 249 251 (fontified t face font-lock-keyword-face) 251 255 (fontified t) 255 256 (fontified t) 256 262 (fontified t face font-lock-keyword-face) 262 281 (fontified t) 281 283 (fontified t face font-lock-keyword-face) 283 294 (fontified t) 294 295 (fontified t face (rainbow-delimiters-depth-1-face)) 295 301 (fontified t face font-lock-string-face) 301 315 (fontified t) 315 316 (fontified t face (rainbow-delimiters-depth-1-face)) 316 317 (fontified t) 317 323 (fontified t) 323 324 (fontified t face (rainbow-delimiters-depth-1-face)) 324 331 (fontified t face font-lock-string-face) 331 345 (fontified t) 345 346 (fontified t face (rainbow-delimiters-depth-1-face)) 346 353 (fontified t) 353 354 (fontified t face (rainbow-delimiters-depth-1-face)) 354 361 (fontified t face font-lock-string-face) 361 375 (fontified t) 375 376 (fontified t face (rainbow-delimiters-depth-1-face)) 376 378 (fontified t) 378 380 (fontified t face font-lock-comment-delimiter-face) 380 405 (fontified t face font-lock-comment-face) 405 406 (fontified t face font-lock-comment-face) 406 422 (fontified t face font-lock-variable-name-face) 422 425 (fontified t) 425 428 (fontified t face font-lock-string-face) 428 429 (fontified t) 429 439 (fontified t face font-lock-variable-name-face) 439 442 (fontified t) 442 447 (fontified t face font-lock-string-face) 447 448 (fontified t) 448 459 (fontified t face font-lock-variable-name-face) 459 474 (fontified t) 474 475 (fontified t face (rainbow-delimiters-depth-1-face)) 475 485 (fontified t) 485 486 (fontified t) 486 493 (fontified t) 493 501 (fontified t face font-lock-string-face) 501 503 (fontified t) 503 513 (fontified t) 513 514 (fontified t face (rainbow-delimiters-depth-1-face)) 514 515 (fontified t) 515 522 (fontified t) 522 526 (fontified t) 526 527 (fontified t face (rainbow-delimiters-depth-1-face)) 527 549 (fontified t) 549 553 (fontified t face font-lock-constant-face) 553 554 (fontified t face (rainbow-delimiters-depth-1-face)) 554 555 (fontified t) 555 556 (fontified t) 556 557 (fontified t face font-lock-keyword-face) 557 559 (fontified t face font-lock-keyword-face) 559 560 (fontified t) 560 568 (fontified t face font-lock-function-name-face) 568 569 (fontified t face (rainbow-delimiters-depth-1-face)) 569 590 (fontified t) 590 594 (fontified t face font-lock-constant-face) 594 610 (fontified t) 610 615 (fontified t face font-lock-string-face) 615 629 (fontified t) 629 631 (fontified t) 631 632 (fontified t face (rainbow-delimiters-depth-1-face)) 632 634 (fontified t) 634 638 (fontified t) 638 642 (fontified t face font-lock-variable-name-face) 642 657 (fontified t) 657 658 (fontified t face (rainbow-delimiters-depth-1-face)) 658 678 (fontified t) 678 680 (fontified t) 680 683 (fontified t face font-lock-string-face) 683 699 (fontified t) 699 700 (fontified t face (rainbow-delimiters-depth-1-face)) 700 701 (fontified t) 701 705 (fontified t) 705 710 (fontified t face font-lock-keyword-face) 710 711 (fontified t face (rainbow-delimiters-depth-1-face)) 711 726 (fontified t face font-lock-string-face) 726 731 (fontified t) 731 734 (fontified t) 734 735 (fontified t face (rainbow-delimiters-depth-1-face)) 735 736 (fontified t) 736 740 (fontified t) 740 742 (fontified t face font-lock-keyword-face) 742 756 (fontified t) 756 757 (fontified t) 757 781 (fontified t) 781 782 (fontified t face (rainbow-delimiters-depth-1-face)) 782 783 (fontified t face (rainbow-delimiters-depth-1-face)) 783 799 (fontified t) 799 800 (fontified t face (rainbow-delimiters-depth-1-face)) 800 806 (fontified t) 806 812 (fontified t face font-lock-builtin-face) 812 842 (fontified t) 842 843 (fontified t face (rainbow-delimiters-depth-1-face)) 843 846 (fontified t) 846 848 (fontified t face font-lock-comment-delimiter-face) 848 861 (fontified t face font-lock-comment-face) 861 862 (fontified t) 862 864 (fontified t face font-lock-comment-delimiter-face) 864 888 (fontified t face font-lock-comment-face) 888 889 (fontified t) 889 891 (fontified t face font-lock-comment-delimiter-face) 891 898 (fontified t face font-lock-comment-face) 898 900 (fontified t) 900 903 (fontified t face font-lock-keyword-face) 903 904 (fontified t) 904 924 (fontified t face font-lock-function-name-face) 924 925 (fontified t face (rainbow-delimiters-depth-1-face)) 925 944 (fontified t) 944 945 (fontified t face (rainbow-delimiters-depth-1-face)) 945 951 (fontified t) 951 956 (fontified t face font-lock-variable-name-face) 956 958 (fontified t) 958 963 (fontified t face font-lock-variable-name-face) 963 965 (fontified t) 965 973 (fontified t face font-lock-variable-name-face) 973 975 (fontified t) 975 983 (fontified t face font-lock-variable-name-face) 983 1000 (fontified t) 1000 1001 (fontified t face (rainbow-delimiters-depth-1-face)) 1001 1015 (fontified t) 1015 1017 (fontified t) 1017 1018 (fontified t face (rainbow-delimiters-depth-1-face)) 1018 1019 (fontified t) 1019 1023 (fontified t) 1023 1027 (fontified t face font-lock-variable-name-face) 1027 1041 (fontified t) 1041 1042 (fontified t face (rainbow-delimiters-depth-1-face)) 1042 1055 (fontified t) 1055 1056 (fontified t face (rainbow-delimiters-depth-1-face)) 1056 1057 (fontified t) 1057 1061 (fontified t) 1061 1067 (fontified t face font-lock-variable-name-face) 1067 1082 (fontified t) 1082 1083 (fontified t face (rainbow-delimiters-depth-1-face)) 1083 1084 (fontified t face (rainbow-delimiters-depth-2-face)) 1084 1099 (fontified t) 1099 1100 (fontified t face (rainbow-delimiters-depth-2-face)) 1100 1103 (fontified t) 1103 1104 (fontified t face (rainbow-delimiters-depth-2-face)) 1104 1119 (fontified t) 1119 1120 (fontified t face (rainbow-delimiters-depth-2-face)) 1120 1121 (fontified t face (rainbow-delimiters-depth-1-face)) 1121 1123 (fontified t) 1123 1127 (fontified t face font-lock-comment-delimiter-face) 1127 1134 (fontified t face font-lock-comment-face) 1134 1138 (fontified t) 1138 1144 (fontified t face font-lock-variable-name-face) 1144 1160 (fontified t) 1160 1161 (fontified t face (rainbow-delimiters-depth-1-face)) 1161 1162 (fontified t face (rainbow-delimiters-depth-2-face)) 1162 1177 (fontified t) 1177 1178 (fontified t face (rainbow-delimiters-depth-2-face)) 1178 1181 (fontified t) 1181 1182 (fontified t face (rainbow-delimiters-depth-2-face)) 1182 1197 (fontified t) 1197 1198 (fontified t face (rainbow-delimiters-depth-2-face)) 1198 1199 (fontified t face (rainbow-delimiters-depth-1-face)) 1199 1200 (fontified t) 1200 1201 (fontified t face font-lock-comment-delimiter-face) 1201 1202 (fontified t face font-lock-comment-delimiter-face) 1202 1211 (fontified t face font-lock-comment-face) 1211 1215 (fontified t) 1215 1221 (fontified t face font-lock-variable-name-face) 1221 1231 (fontified t) 1231 1232 (fontified t face (rainbow-delimiters-depth-1-face)) 1232 1236 (fontified t) 1236 1246 (fontified t) 1246 1247 (fontified t face (rainbow-delimiters-depth-2-face)) 1247 1257 (fontified t) 1257 1266 (fontified t) 1266 1267 (face (rainbow-delimiters-depth-2-face) fontified t) 1267 1273 (fontified t) 1273 1274 (face (rainbow-delimiters-depth-1-face) fontified t) 1274 1277 (fontified t) 1277 1279 (face font-lock-comment-delimiter-face fontified t) 1279 1287 (face font-lock-comment-face fontified t)) . 1) (undo-tree-id57 . -231) (undo-tree-id58 . -231) (undo-tree-id59 . 42612) (undo-tree-id60 . -23) (undo-tree-id61 . -23) (undo-tree-id62 . -23) (undo-tree-id63 . -23) (undo-tree-id64 . -23) (undo-tree-id65 . -23) (undo-tree-id66 . -23) (undo-tree-id67 . -23) (undo-tree-id68 . -23) (undo-tree-id69 . -23) (undo-tree-id70 . -23) (undo-tree-id71 . -23) (undo-tree-id72 . -23) (undo-tree-id73 . -23) (undo-tree-id74 . -23) (undo-tree-id75 . -23) (undo-tree-id76 . -23) (undo-tree-id77 . -23) (undo-tree-id78 . -23) (undo-tree-id79 . -23) (undo-tree-id80 . -23) (undo-tree-id81 . -23) (undo-tree-id82 . -23) (undo-tree-id83 . -23) (undo-tree-id84 . -23) (undo-tree-id85 . -23) (undo-tree-id86 . -23) (undo-tree-id87 . -23) (undo-tree-id88 . -23) (undo-tree-id89 . -23) (undo-tree-id90 . -23) (undo-tree-id91 . -23) (undo-tree-id92 . -23) (undo-tree-id93 . -23) (undo-tree-id94 . -23) (undo-tree-id95 . -23) (undo-tree-id96 . -23) (undo-tree-id97 . -23) (undo-tree-id98 . -23) (undo-tree-id99 . -23) (undo-tree-id100 . -23) (undo-tree-id101 . -23) (undo-tree-id102 . -23) (undo-tree-id103 . -23) (undo-tree-id104 . -23) (undo-tree-id105 . -23) (undo-tree-id106 . -23) (undo-tree-id107 . -23) (undo-tree-id108 . -23) (undo-tree-id109 . -23) (undo-tree-id110 . -38) (undo-tree-id111 . -38) (undo-tree-id112 . -91) (undo-tree-id113 . -91) (undo-tree-id114 . -91) (undo-tree-id115 . -91) (undo-tree-id116 . -91) (undo-tree-id117 . -91) (undo-tree-id118 . -91) (undo-tree-id119 . -91) (undo-tree-id120 . -91) (undo-tree-id121 . -91) (undo-tree-id122 . -231) (undo-tree-id123 . -231) (undo-tree-id124 . -231) (undo-tree-id125 . -231) (undo-tree-id126 . -288) (undo-tree-id127 . -288) (undo-tree-id128 . -317) (undo-tree-id129 . -317) (undo-tree-id130 . -347) (undo-tree-id131 . -347) (undo-tree-id132 . -23) (undo-tree-id133 . -23) (undo-tree-id134 . -23) (undo-tree-id135 . -23) (undo-tree-id136 . -23) (undo-tree-id137 . -23) (undo-tree-id138 . -23) (undo-tree-id139 . -23) (undo-tree-id140 . -23) (undo-tree-id141 . -23) (undo-tree-id142 . -23) (undo-tree-id143 . -23) (undo-tree-id144 . -23) (undo-tree-id145 . -23) (undo-tree-id146 . -23) (undo-tree-id147 . -23) (undo-tree-id148 . -23) (undo-tree-id149 . -23) (undo-tree-id150 . -23) (undo-tree-id151 . -23) (undo-tree-id152 . -23) (undo-tree-id153 . -23) (undo-tree-id154 . -23) (undo-tree-id155 . -23) (undo-tree-id156 . -23) (undo-tree-id157 . -23) (undo-tree-id158 . -23) (undo-tree-id159 . -23) (undo-tree-id160 . -23) (undo-tree-id161 . -23) (undo-tree-id162 . -23) (undo-tree-id163 . -23) (undo-tree-id164 . -23) (undo-tree-id165 . -23) (undo-tree-id166 . -23) (undo-tree-id167 . -23) (undo-tree-id168 . -23) (undo-tree-id169 . -29) (undo-tree-id170 . -38) (undo-tree-id171 . -44) (undo-tree-id172 . -62) (undo-tree-id173 . -66) (undo-tree-id174 . -91) (undo-tree-id175 . -91) (undo-tree-id176 . -91) (undo-tree-id177 . -91) (undo-tree-id178 . -91) (undo-tree-id179 . -97) (undo-tree-id180 . -110) (undo-tree-id181 . -110) (undo-tree-id182 . -110) (undo-tree-id183 . -114) (undo-tree-id184 . -231) (undo-tree-id185 . -231) (undo-tree-id186 . -231) (undo-tree-id187 . -237) (undo-tree-id188 . -256) (undo-tree-id189 . -262) (undo-tree-id190 . -556) (undo-tree-id191 . -559) (undo-tree-id192 . -1123) (undo-tree-id193 . -1124) (undo-tree-id194 . -1199) (undo-tree-id195 . -1200) (undo-tree-id196 . -1762) (undo-tree-id197 . -1768) (undo-tree-id198 . -2284) (undo-tree-id199 . -2287) (undo-tree-id200 . -2494) (undo-tree-id201 . -2495) (undo-tree-id202 . -2666) (undo-tree-id203 . -2675) (undo-tree-id204 . -3715) (undo-tree-id205 . -3719) (undo-tree-id206 . -3925) (undo-tree-id207 . -3945) (undo-tree-id208 . -6235) (undo-tree-id209 . -6236) (undo-tree-id210 . -6817) (undo-tree-id211 . -6823) (undo-tree-id212 . -6905) (undo-tree-id213 . -6906) (undo-tree-id214 . -7004) (undo-tree-id215 . -7027) (undo-tree-id216 . -7170) (undo-tree-id217 . -7180) (undo-tree-id218 . -7938) (undo-tree-id219 . -7944) (undo-tree-id220 . -8014) (undo-tree-id221 . -8015) (undo-tree-id222 . -8051) (undo-tree-id223 . -8052) (undo-tree-id224 . -9230) (undo-tree-id225 . -9234) (undo-tree-id226 . -10339) (undo-tree-id227 . -10342) (undo-tree-id228 . -10454) (undo-tree-id229 . -10459) (undo-tree-id230 . -10533) (undo-tree-id231 . -10540) (undo-tree-id232 . -11538) (undo-tree-id233 . -11542) (undo-tree-id234 . -12061) (undo-tree-id235 . -12064) (undo-tree-id236 . -12315) (undo-tree-id237 . -12318) (undo-tree-id238 . -13402) (undo-tree-id239 . -13405) (undo-tree-id240 . -13564) (undo-tree-id241 . -13565) (undo-tree-id242 . -13571) (undo-tree-id243 . -13572) (undo-tree-id244 . -13936) (undo-tree-id245 . -13942) (undo-tree-id246 . -16629) (undo-tree-id247 . -16630) (undo-tree-id248 . -17049) (undo-tree-id249 . -17050) (undo-tree-id250 . -17062) (undo-tree-id251 . -17063) (undo-tree-id252 . -18924) (undo-tree-id253 . -18929) (undo-tree-id254 . -19277) (undo-tree-id255 . -19280) (undo-tree-id256 . -19989) (undo-tree-id257 . -19990) (undo-tree-id258 . -20020) (undo-tree-id259 . -20021) (undo-tree-id260 . -20052) (undo-tree-id261 . -20053) (undo-tree-id262 . -20086) (undo-tree-id263 . -20087) (undo-tree-id264 . -20629) (undo-tree-id265 . -20630) (undo-tree-id266 . -20968) (undo-tree-id267 . -20969) (undo-tree-id268 . -21546) (undo-tree-id269 . -21548) (undo-tree-id270 . -21650) (undo-tree-id271 . -21653) (undo-tree-id272 . -22357) (undo-tree-id273 . -22365) (undo-tree-id274 . -22451) (undo-tree-id275 . -22452) (undo-tree-id276 . -22642) (undo-tree-id277 . -22643) (undo-tree-id278 . -24562) (undo-tree-id279 . -24563) (undo-tree-id280 . -24944) (undo-tree-id281 . -24947) (undo-tree-id282 . -25204) (undo-tree-id283 . -25211) (undo-tree-id284 . -25329) (undo-tree-id285 . -25332) (undo-tree-id286 . -25836) (undo-tree-id287 . -25842) (undo-tree-id288 . -25846) (undo-tree-id289 . -25863) (undo-tree-id290 . -27273) (undo-tree-id291 . -27274) (undo-tree-id292 . -27717) (undo-tree-id293 . -27722) (undo-tree-id294 . -28625) (undo-tree-id295 . -28626) (undo-tree-id296 . -28628) (undo-tree-id297 . -28629) (undo-tree-id298 . -28718) (undo-tree-id299 . -28730) (undo-tree-id300 . -29247) (undo-tree-id301 . -29253) (undo-tree-id302 . -29268) (undo-tree-id303 . -29271) (undo-tree-id304 . -29376) (undo-tree-id305 . -29390) (undo-tree-id306 . -29618) (undo-tree-id307 . -29621) (undo-tree-id308 . -30010) (undo-tree-id309 . -30020) (undo-tree-id310 . -30204) (undo-tree-id311 . -30208) (undo-tree-id312 . -30239) (undo-tree-id313 . -30242) (undo-tree-id314 . -30474) (undo-tree-id315 . -30477) (undo-tree-id316 . -30565) (undo-tree-id317 . -30566) (undo-tree-id318 . -31158) (undo-tree-id319 . -31161) (undo-tree-id320 . -31286) (undo-tree-id321 . -31287) (undo-tree-id322 . -31493) (undo-tree-id323 . -31494) (undo-tree-id324 . -31637) (undo-tree-id325 . -31640) (undo-tree-id326 . -31715) (undo-tree-id327 . -31719) (undo-tree-id328 . -31970) (undo-tree-id329 . -31977) (undo-tree-id330 . -32020) (undo-tree-id331 . -32027) (undo-tree-id332 . -32271) (undo-tree-id333 . -32274) (undo-tree-id334 . -33047) (undo-tree-id335 . -33048) (undo-tree-id336 . -33122) (undo-tree-id337 . -33132) (undo-tree-id338 . -33198) (undo-tree-id339 . -33199) (undo-tree-id340 . -33274) (undo-tree-id341 . -33275) (undo-tree-id342 . -33352) (undo-tree-id343 . -33357) (undo-tree-id344 . -33625) (undo-tree-id345 . -33626) (undo-tree-id346 . -33693) (undo-tree-id347 . -33696) (undo-tree-id348 . -33782) (undo-tree-id349 . -33783) (undo-tree-id350 . -33791) (undo-tree-id351 . -33797) (undo-tree-id352 . -33833) (undo-tree-id353 . -33834) (undo-tree-id354 . -33856) (undo-tree-id355 . -33859) (undo-tree-id356 . -34233) (undo-tree-id357 . -34237) (undo-tree-id358 . -34975) (undo-tree-id359 . -34976) (undo-tree-id360 . -35054) (undo-tree-id361 . -35059) (undo-tree-id362 . -35784) (undo-tree-id363 . -35792) (undo-tree-id364 . -36092) (undo-tree-id365 . -36096) (undo-tree-id366 . -36552) (undo-tree-id367 . -36553) (undo-tree-id368 . -36672) (undo-tree-id369 . -36673) (undo-tree-id370 . -36809) (undo-tree-id371 . -36810) (undo-tree-id372 . -36946) (undo-tree-id373 . -36947) (undo-tree-id374 . -37499) (undo-tree-id375 . -37504) (undo-tree-id376 . -37797) (undo-tree-id377 . -37798) (undo-tree-id378 . -38012) (undo-tree-id379 . -38013) (undo-tree-id380 . -38305) (undo-tree-id381 . -38306) (undo-tree-id382 . -38643) (undo-tree-id383 . -38645) (undo-tree-id384 . -38929) (undo-tree-id385 . -38930) (undo-tree-id386 . -39317) (undo-tree-id387 . -39318) (undo-tree-id388 . -39574) (undo-tree-id389 . -39582) (undo-tree-id390 . -39864) (undo-tree-id391 . -39869) (undo-tree-id392 . -40211) (undo-tree-id393 . -40212) (undo-tree-id394 . -40291) (undo-tree-id395 . -40298) (undo-tree-id396 . -41570) (undo-tree-id397 . -41573) (undo-tree-id398 . -41774) (undo-tree-id399 . -41775) (undo-tree-id400 . -41851) (undo-tree-id401 . -41864) (undo-tree-id402 . -41994) (undo-tree-id403 . -41995) (undo-tree-id404 . -42150) (undo-tree-id405 . -42151) (undo-tree-id406 . -42313) (undo-tree-id407 . -42314) (undo-tree-id408 . -42454) (undo-tree-id409 . -42462) (undo-tree-id410 . -42632) (undo-tree-id411 . -42633) (undo-tree-id412 . -23) (undo-tree-id413 . -23) (undo-tree-id414 . -23) (undo-tree-id415 . -23) (undo-tree-id416 . -23) (undo-tree-id417 . -23) (undo-tree-id418 . -23) (undo-tree-id419 . -23) (undo-tree-id420 . -23) (undo-tree-id421 . -23) (undo-tree-id422 . -23) (undo-tree-id423 . -23) (undo-tree-id424 . -23) (undo-tree-id425 . -23) (undo-tree-id426 . -23) (undo-tree-id427 . -23) (undo-tree-id428 . -38) (undo-tree-id429 . -38) (undo-tree-id430 . -91) (undo-tree-id431 . -91) (undo-tree-id432 . -91) (undo-tree-id433 . -91) (undo-tree-id434 . -91) (undo-tree-id435 . -91) (undo-tree-id436 . -91) (undo-tree-id437 . -91) (undo-tree-id438 . -91) (undo-tree-id439 . -91) (undo-tree-id440 . -231) (undo-tree-id441 . -231) (undo-tree-id442 . -231) (undo-tree-id443 . -231) (undo-tree-id444 . -288) (undo-tree-id445 . -288) (undo-tree-id446 . -317) (undo-tree-id447 . -317) (undo-tree-id448 . -347) (undo-tree-id449 . -347) (undo-tree-id450 . -23) (undo-tree-id451 . -23) (undo-tree-id452 . -23) (undo-tree-id453 . -23) (undo-tree-id454 . -23) (undo-tree-id455 . -23) (undo-tree-id456 . -23) (undo-tree-id457 . -23) (undo-tree-id458 . -23) (undo-tree-id459 . -23) (undo-tree-id460 . -23) (undo-tree-id461 . -23) (undo-tree-id462 . -23) (undo-tree-id463 . -23) (undo-tree-id464 . -23) (undo-tree-id465 . -23) (undo-tree-id466 . -23) (undo-tree-id467 . -23) (undo-tree-id468 . -23) (undo-tree-id469 . -23) (undo-tree-id470 . -23) (undo-tree-id471 . -23) (undo-tree-id472 . -23) (undo-tree-id473 . -23) (undo-tree-id474 . -23) (undo-tree-id475 . -23) (undo-tree-id476 . -23) (undo-tree-id477 . -23) (undo-tree-id478 . -23) (undo-tree-id479 . -23) (undo-tree-id480 . -23) (undo-tree-id481 . -23) (undo-tree-id482 . -23) (undo-tree-id483 . -23) (undo-tree-id484 . -23) (undo-tree-id485 . -23) (undo-tree-id486 . -23) (undo-tree-id487 . -23) (undo-tree-id488 . -23) (undo-tree-id489 . -23) (undo-tree-id490 . -23) (undo-tree-id491 . -23) (undo-tree-id492 . -23) (undo-tree-id493 . -23) (undo-tree-id494 . -23) (undo-tree-id495 . -23) (undo-tree-id496 . -23) (undo-tree-id497 . -23) (undo-tree-id498 . -23) (undo-tree-id499 . -23) (undo-tree-id500 . -23) (undo-tree-id501 . -23) (undo-tree-id502 . -23) (undo-tree-id503 . -23) (undo-tree-id504 . -23) (undo-tree-id505 . -23) (undo-tree-id506 . -23) (undo-tree-id507 . -23) (undo-tree-id508 . -23) (undo-tree-id509 . -23) (undo-tree-id510 . -23) (undo-tree-id511 . -23) (undo-tree-id512 . -23) (undo-tree-id513 . -23) (undo-tree-id514 . -23) (undo-tree-id515 . -23) (undo-tree-id516 . -23) (undo-tree-id517 . -23) (undo-tree-id518 . -23) (undo-tree-id519 . -23) (undo-tree-id520 . -23) (undo-tree-id521 . -23) (undo-tree-id522 . -23) (undo-tree-id523 . -23) (undo-tree-id524 . -23) (undo-tree-id525 . -23) (undo-tree-id526 . -23) (undo-tree-id527 . -23) (undo-tree-id528 . -23) (undo-tree-id529 . -23) (undo-tree-id530 . -23) (undo-tree-id531 . -23) (undo-tree-id532 . -23) (undo-tree-id533 . -23) (undo-tree-id534 . -23) (undo-tree-id535 . -23) (undo-tree-id536 . -23) (undo-tree-id537 . -23) (undo-tree-id538 . -23) (undo-tree-id539 . -23) (undo-tree-id540 . -23) (undo-tree-id541 . -23) (undo-tree-id542 . -23) (undo-tree-id543 . -23) (undo-tree-id544 . -23) (undo-tree-id545 . -23) (undo-tree-id546 . -23) (undo-tree-id547 . -23) (undo-tree-id548 . -23) (undo-tree-id549 . -23) (undo-tree-id550 . -23) (undo-tree-id551 . -23) (undo-tree-id552 . -23) (undo-tree-id553 . -23) (undo-tree-id554 . -23) (undo-tree-id555 . -23) (undo-tree-id556 . -23) (undo-tree-id557 . -23) (undo-tree-id558 . -23) (undo-tree-id559 . -23) (undo-tree-id560 . -23) (undo-tree-id561 . -23) (undo-tree-id562 . -23) (undo-tree-id563 . -23) (undo-tree-id564 . -23) (undo-tree-id565 . -23) (undo-tree-id566 . -23) (undo-tree-id567 . -23) (undo-tree-id568 . -23) (undo-tree-id569 . -23) (undo-tree-id570 . -23) (undo-tree-id571 . -38) (undo-tree-id572 . -38) (undo-tree-id573 . -91) (undo-tree-id574 . -91) (undo-tree-id575 . -91) (undo-tree-id576 . -91) (undo-tree-id577 . -91) (undo-tree-id578 . -91) (undo-tree-id579 . -91) (undo-tree-id580 . -91) (undo-tree-id581 . -91) (undo-tree-id582 . -91) (undo-tree-id583 . -231) (undo-tree-id584 . -231) (undo-tree-id585 . -231) (undo-tree-id586 . -231) (undo-tree-id587 . -288) (undo-tree-id588 . -288) (undo-tree-id589 . -317) (undo-tree-id590 . -317) (undo-tree-id591 . -347) (undo-tree-id592 . -347) (undo-tree-id593 . -406) (undo-tree-id594 . -406) (undo-tree-id595 . -425) (undo-tree-id596 . -429) (undo-tree-id597 . -429) (undo-tree-id598 . -442) (undo-tree-id599 . -448) (undo-tree-id600 . -448) (undo-tree-id601 . -462) (undo-tree-id602 . -23) (undo-tree-id603 . -23) (undo-tree-id604 . -23) (undo-tree-id605 . -23) (undo-tree-id606 . -23) (undo-tree-id607 . -23) (undo-tree-id608 . -23) (undo-tree-id609 . -23) (undo-tree-id610 . -23) (undo-tree-id611 . -23) (undo-tree-id612 . -23) (undo-tree-id613 . -37) (undo-tree-id614 . -23) (undo-tree-id615 . -23) (undo-tree-id616 . -23) (undo-tree-id617 . -23) (undo-tree-id618 . -23) (undo-tree-id619 . -23) (undo-tree-id620 . -23) (undo-tree-id621 . -23) (undo-tree-id622 . -23) (undo-tree-id623 . -23) (undo-tree-id624 . -23) (undo-tree-id625 . -23) (undo-tree-id626 . -23) (undo-tree-id627 . -23) (undo-tree-id628 . -23) (undo-tree-id629 . -23) (undo-tree-id630 . -23) (undo-tree-id631 . -23) (undo-tree-id632 . -23) (undo-tree-id633 . -23) (undo-tree-id634 . -23) (undo-tree-id635 . -23) (undo-tree-id636 . -23) (undo-tree-id637 . -23) (undo-tree-id638 . -23) (undo-tree-id639 . -23) (undo-tree-id640 . -23) (undo-tree-id641 . -23) (undo-tree-id642 . -23) (undo-tree-id643 . -23) (undo-tree-id644 . -23) (undo-tree-id645 . -23) (undo-tree-id646 . -23) (undo-tree-id647 . -23) (undo-tree-id648 . -23) (undo-tree-id649 . -23) (undo-tree-id650 . -23) (undo-tree-id651 . -23) (undo-tree-id652 . -23) (undo-tree-id653 . -23) (undo-tree-id654 . -23) (undo-tree-id655 . -23) (undo-tree-id656 . -23) (undo-tree-id657 . -23) (undo-tree-id658 . -38) (undo-tree-id659 . -38) (undo-tree-id660 . -38) (undo-tree-id661 . -38) (undo-tree-id662 . -38) (undo-tree-id663 . -38) (undo-tree-id664 . -38) (undo-tree-id665 . -38) (undo-tree-id666 . -38) (undo-tree-id667 . -38) (undo-tree-id668 . -38) (undo-tree-id669 . -38) (undo-tree-id670 . -38) (undo-tree-id671 . -38) (undo-tree-id672 . -38) (undo-tree-id673 . -38) (undo-tree-id674 . -38) (undo-tree-id675 . -38) (undo-tree-id676 . -38) (undo-tree-id677 . -38) (undo-tree-id678 . -38) (undo-tree-id679 . -38) (undo-tree-id680 . -38) (undo-tree-id681 . -38) (undo-tree-id682 . -38) (undo-tree-id683 . -38) (undo-tree-id684 . -91) (undo-tree-id685 . -91) (undo-tree-id686 . -91) (undo-tree-id687 . -91) (undo-tree-id688 . -91) (undo-tree-id689 . -91) (undo-tree-id690 . -91) (undo-tree-id691 . -91) (undo-tree-id692 . -91) (undo-tree-id693 . -91) (undo-tree-id694 . -231) (undo-tree-id695 . -231) (undo-tree-id696 . -231) (undo-tree-id697 . -231) (undo-tree-id698 . -288) (undo-tree-id699 . -288) (undo-tree-id700 . -317) (undo-tree-id701 . -317) (undo-tree-id702 . -347) (undo-tree-id703 . -347) (undo-tree-id704 . -406) (undo-tree-id705 . -406) (undo-tree-id706 . -425) (undo-tree-id707 . -429) (undo-tree-id708 . -429) (undo-tree-id709 . -442) (undo-tree-id710 . -448) (undo-tree-id711 . -448) (undo-tree-id712 . -462) (undo-tree-id713 . -38) (undo-tree-id714 . -38) (undo-tree-id715 . -38) (undo-tree-id716 . -38) (undo-tree-id717 . -38) (undo-tree-id718 . -38) (undo-tree-id719 . -38) (undo-tree-id720 . -38) (undo-tree-id721 . -38) (undo-tree-id722 . -38) (undo-tree-id723 . -38) (undo-tree-id724 . -38) (undo-tree-id725 . -38) (undo-tree-id726 . -38) (undo-tree-id727 . -38) (undo-tree-id728 . -38) (undo-tree-id729 . -38) (undo-tree-id730 . -38) (undo-tree-id731 . -38) (undo-tree-id732 . -38) (undo-tree-id733 . -38) (undo-tree-id734 . -38) (undo-tree-id735 . -38) (undo-tree-id736 . -38) (undo-tree-id737 . -38) (undo-tree-id738 . -38) (undo-tree-id739 . -38) (undo-tree-id740 . -38) (undo-tree-id741 . -38) (undo-tree-id742 . -38) (undo-tree-id743 . -61) (undo-tree-id744 . -38) (undo-tree-id745 . -38) (undo-tree-id746 . -38) (undo-tree-id747 . -38) (undo-tree-id748 . -38) (undo-tree-id749 . -38) (undo-tree-id750 . -38) (undo-tree-id751 . -38) (undo-tree-id752 . -38) (undo-tree-id753 . -38) (undo-tree-id754 . -38) (undo-tree-id755 . -38) (undo-tree-id756 . -38) (undo-tree-id757 . -38) (undo-tree-id758 . -38) (undo-tree-id759 . -38) (undo-tree-id760 . -38) (undo-tree-id761 . -38) (undo-tree-id762 . -38) (undo-tree-id763 . -38) (undo-tree-id764 . -38) (undo-tree-id765 . -38) (undo-tree-id766 . -38) (undo-tree-id767 . -38) (undo-tree-id768 . -38) (undo-tree-id769 . -91) (undo-tree-id770 . -91) (undo-tree-id771 . -91) (undo-tree-id772 . -91) (undo-tree-id773 . -91) (undo-tree-id774 . -91) (undo-tree-id775 . -91) (undo-tree-id776 . -91) (undo-tree-id777 . -91) (undo-tree-id778 . -91) (undo-tree-id779 . -231) (undo-tree-id780 . -231) (undo-tree-id781 . -231) (undo-tree-id782 . -231) (undo-tree-id783 . -288) (undo-tree-id784 . -288) (undo-tree-id785 . -317) (undo-tree-id786 . -317) (undo-tree-id787 . -347) (undo-tree-id788 . -347) (undo-tree-id789 . -406) (undo-tree-id790 . -406) (undo-tree-id791 . -425) (undo-tree-id792 . -429) (undo-tree-id793 . -429) (undo-tree-id794 . -442) (undo-tree-id795 . -448) (undo-tree-id796 . -448) (undo-tree-id797 . -462) (undo-tree-id798 . -556) (undo-tree-id799 . -556) (undo-tree-id800 . -38) (undo-tree-id801 . -38) (undo-tree-id802 . -38) (undo-tree-id803 . -38) (undo-tree-id804 . -38) (undo-tree-id805 . -38) (undo-tree-id806 . -38) (undo-tree-id807 . -38) (undo-tree-id808 . -38) (undo-tree-id809 . -38) (undo-tree-id810 . -38) (undo-tree-id811 . -61) (undo-tree-id812 . -38) (undo-tree-id813 . -38) (undo-tree-id814 . -38) (undo-tree-id815 . -38) (undo-tree-id816 . -38) (undo-tree-id817 . -38) (undo-tree-id818 . -38) (undo-tree-id819 . -38) (undo-tree-id820 . -38) (undo-tree-id821 . -38) (undo-tree-id822 . -38) (undo-tree-id823 . -38) (undo-tree-id824 . -38) (undo-tree-id825 . -38) (undo-tree-id826 . -38) (undo-tree-id827 . -38) (undo-tree-id828 . -38) (undo-tree-id829 . -38) (undo-tree-id830 . -38) (undo-tree-id831 . -91) (undo-tree-id832 . -91) (undo-tree-id833 . -91) (undo-tree-id834 . -91) (undo-tree-id835 . -91) (undo-tree-id836 . -91) (undo-tree-id837 . -91) (undo-tree-id838 . -91) (undo-tree-id839 . -91) (undo-tree-id840 . -91) (undo-tree-id841 . -231) (undo-tree-id842 . -231) (undo-tree-id843 . -231) (undo-tree-id844 . -231) (undo-tree-id845 . -288) (undo-tree-id846 . -288) (undo-tree-id847 . -317) (undo-tree-id848 . -317) (undo-tree-id849 . -347) (undo-tree-id850 . -347) (undo-tree-id851 . -406) (undo-tree-id852 . -406) (undo-tree-id853 . -425) (undo-tree-id854 . -429) (undo-tree-id855 . -429) (undo-tree-id856 . -442) (undo-tree-id857 . -448) (undo-tree-id858 . -448) (undo-tree-id859 . -462) (undo-tree-id860 . -556) (undo-tree-id861 . -556) (undo-tree-id862 . -38) (undo-tree-id863 . -38) (undo-tree-id864 . -38) (undo-tree-id865 . -38) (undo-tree-id866 . -38) (undo-tree-id867 . -38) (undo-tree-id868 . -38) (undo-tree-id869 . -38) (undo-tree-id870 . -38) (undo-tree-id871 . -38) (undo-tree-id872 . -38) (undo-tree-id873 . -38) (undo-tree-id874 . -38) (undo-tree-id875 . -38) (undo-tree-id876 . -38) (undo-tree-id877 . -38) (undo-tree-id878 . -38) (undo-tree-id879 . -38) (undo-tree-id880 . -38) (undo-tree-id881 . -38) (undo-tree-id882 . -38) (undo-tree-id883 . -38) (undo-tree-id884 . -38) (undo-tree-id885 . -38) (undo-tree-id886 . -38) (undo-tree-id887 . -38) (undo-tree-id888 . -38) (undo-tree-id889 . -38) (undo-tree-id890 . -38) (undo-tree-id891 . -38) (undo-tree-id892 . -38) (undo-tree-id893 . -38) (undo-tree-id894 . -38) (undo-tree-id895 . -38) (undo-tree-id896 . -38) (undo-tree-id897 . -38) (undo-tree-id898 . -38) (undo-tree-id899 . -38) (undo-tree-id900 . -38) (undo-tree-id901 . -38) (undo-tree-id902 . -38) (undo-tree-id903 . -38) (undo-tree-id904 . -38) (undo-tree-id905 . -38) (undo-tree-id906 . -38) (undo-tree-id907 . -38) (undo-tree-id908 . -38) (undo-tree-id909 . -38) (undo-tree-id910 . -38) (undo-tree-id911 . -38) (undo-tree-id912 . -38) (undo-tree-id913 . -38) (undo-tree-id914 . -38) (undo-tree-id915 . -38) (undo-tree-id916 . -38) (undo-tree-id917 . -38) (undo-tree-id918 . -38) (undo-tree-id919 . -38) (undo-tree-id920 . -38) (undo-tree-id921 . -38) (undo-tree-id922 . -38) (undo-tree-id923 . -38) (undo-tree-id924 . -38) (undo-tree-id925 . -38) (undo-tree-id926 . -38) (undo-tree-id927 . -38) (undo-tree-id928 . -38) (undo-tree-id929 . -38) (undo-tree-id930 . -38) (undo-tree-id931 . -38) (undo-tree-id932 . -38) (undo-tree-id933 . -38) (undo-tree-id934 . -61) (undo-tree-id935 . -38) (undo-tree-id936 . -38) (undo-tree-id937 . -38) (undo-tree-id938 . -38) (undo-tree-id939 . -38) (undo-tree-id940 . -38) (undo-tree-id941 . -38) (undo-tree-id942 . -38) (undo-tree-id943 . -38) (undo-tree-id944 . -38) (undo-tree-id945 . -38) (undo-tree-id946 . -38) (undo-tree-id947 . -38) (undo-tree-id948 . -38) (undo-tree-id949 . -38) (undo-tree-id950 . -38) (undo-tree-id951 . -38) (undo-tree-id952 . -62) (undo-tree-id953 . -62) (undo-tree-id954 . -62) (undo-tree-id955 . -62) (undo-tree-id956 . -62) (undo-tree-id957 . -62) (undo-tree-id958 . -62) (undo-tree-id959 . -62) (undo-tree-id960 . -62) (undo-tree-id961 . -62) (undo-tree-id962 . -62) (undo-tree-id963 . -62) (undo-tree-id964 . -62) (undo-tree-id965 . -62) (undo-tree-id966 . -62) (undo-tree-id967 . -91) (undo-tree-id968 . -91) (undo-tree-id969 . -91) (undo-tree-id970 . -91) (undo-tree-id971 . -91) (undo-tree-id972 . -91) (undo-tree-id973 . -91) (undo-tree-id974 . -91) (undo-tree-id975 . -91) (undo-tree-id976 . -91) (undo-tree-id977 . -231) (undo-tree-id978 . -231) (undo-tree-id979 . -231) (undo-tree-id980 . -231) (undo-tree-id981 . -288) (undo-tree-id982 . -288) (undo-tree-id983 . -317) (undo-tree-id984 . -317) (undo-tree-id985 . -347) (undo-tree-id986 . -347) (undo-tree-id987 . -406) (undo-tree-id988 . -406) (undo-tree-id989 . -425) (undo-tree-id990 . -429) (undo-tree-id991 . -429) (undo-tree-id992 . -442) (undo-tree-id993 . -448) (undo-tree-id994 . -448) (undo-tree-id995 . -462) (undo-tree-id996 . -556) (undo-tree-id997 . -556) (undo-tree-id998 . -62) (undo-tree-id999 . -62) (undo-tree-id1000 . -62) (undo-tree-id1001 . -62) (undo-tree-id1002 . -62) (undo-tree-id1003 . -62) (undo-tree-id1004 . -62) (undo-tree-id1005 . -62) (undo-tree-id1006 . -62) (undo-tree-id1007 . -62) (undo-tree-id1008 . -62) (undo-tree-id1009 . -62) (undo-tree-id1010 . -62) (undo-tree-id1011 . -62) (undo-tree-id1012 . -62) (undo-tree-id1013 . -62) (undo-tree-id1014 . -62) (undo-tree-id1015 . -62) (undo-tree-id1016 . -62) (undo-tree-id1017 . -62) (undo-tree-id1018 . -62) (undo-tree-id1019 . -62) (undo-tree-id1020 . -62) (undo-tree-id1021 . -62) (undo-tree-id1022 . -62) (undo-tree-id1023 . -62) (undo-tree-id1024 . -62) (undo-tree-id1025 . -62) (undo-tree-id1026 . -91) (undo-tree-id1027 . -91) (undo-tree-id1028 . -91) (undo-tree-id1029 . -91) (undo-tree-id1030 . -91) (undo-tree-id1031 . -91) (undo-tree-id1032 . -91) (undo-tree-id1033 . -91) (undo-tree-id1034 . -91) (undo-tree-id1035 . -91) (undo-tree-id1036 . -91) (undo-tree-id1037 . -91) (undo-tree-id1038 . -91) (undo-tree-id1039 . -91) (undo-tree-id1040 . -91) (undo-tree-id1041 . -91) (undo-tree-id1042 . -91) (undo-tree-id1043 . -91) (undo-tree-id1044 . -91) (undo-tree-id1045 . -91) (undo-tree-id1046 . -91) (undo-tree-id1047 . -91) (undo-tree-id1048 . -91) (undo-tree-id1049 . -91) (undo-tree-id1050 . -91) (undo-tree-id1051 . -91) (undo-tree-id1052 . -91) (undo-tree-id1053 . -91) (undo-tree-id1054 . -91) (undo-tree-id1055 . -91) (undo-tree-id1056 . -91) (undo-tree-id1057 . -91) (undo-tree-id1058 . -91) (undo-tree-id1059 . -91) (undo-tree-id1060 . -91) (undo-tree-id1061 . -91) (undo-tree-id1062 . -91) (undo-tree-id1063 . -91) (undo-tree-id1064 . -91) (undo-tree-id1065 . -91) (undo-tree-id1066 . -91) (undo-tree-id1067 . -91) (undo-tree-id1068 . -91) (undo-tree-id1069 . -91) (undo-tree-id1070 . -91) (undo-tree-id1071 . -91) (undo-tree-id1072 . -91) (undo-tree-id1073 . -91) (undo-tree-id1074 . -91) (undo-tree-id1075 . -91) (undo-tree-id1076 . -91) (undo-tree-id1077 . -91) (undo-tree-id1078 . -91) (undo-tree-id1079 . -91) (undo-tree-id1080 . -91) (undo-tree-id1081 . -91) (undo-tree-id1082 . -91) (undo-tree-id1083 . -91) (undo-tree-id1084 . -91) (undo-tree-id1085 . -91) (undo-tree-id1086 . -91) (undo-tree-id1087 . -91) (undo-tree-id1088 . -91) (undo-tree-id1089 . -91) (undo-tree-id1090 . -91) (undo-tree-id1091 . -91) (undo-tree-id1092 . -91) (undo-tree-id1093 . -91) (undo-tree-id1094 . -91) (undo-tree-id1095 . -91) (undo-tree-id1096 . -231) (undo-tree-id1097 . -231) (undo-tree-id1098 . -231) (undo-tree-id1099 . -231) (undo-tree-id1100 . -288) (undo-tree-id1101 . -288) (undo-tree-id1102 . -317) (undo-tree-id1103 . -317) (undo-tree-id1104 . -347) (undo-tree-id1105 . -347) (undo-tree-id1106 . -406) (undo-tree-id1107 . -406) (undo-tree-id1108 . -425) (undo-tree-id1109 . -429) (undo-tree-id1110 . -429) (undo-tree-id1111 . -442) (undo-tree-id1112 . -448) (undo-tree-id1113 . -448) (undo-tree-id1114 . -462) (undo-tree-id1115 . -556) (undo-tree-id1116 . -556) (undo-tree-id1117 . -638) (undo-tree-id1118 . -638) (undo-tree-id1119 . -645) (undo-tree-id1120 . -91) (undo-tree-id1121 . -91) (undo-tree-id1122 . -91) (undo-tree-id1123 . -91) (undo-tree-id1124 . -91) (undo-tree-id1125 . -91) (undo-tree-id1126 . -91) (undo-tree-id1127 . -91) (undo-tree-id1128 . -91) (undo-tree-id1129 . -91) (undo-tree-id1130 . -91) (undo-tree-id1131 . -91) (undo-tree-id1132 . -91) (undo-tree-id1133 . -91) (undo-tree-id1134 . -91) (undo-tree-id1135 . -91) (undo-tree-id1136 . -91) (undo-tree-id1137 . -91) (undo-tree-id1138 . -91) (undo-tree-id1139 . -91) (undo-tree-id1140 . -91) (undo-tree-id1141 . -91) (undo-tree-id1142 . -91) (undo-tree-id1143 . -91) (undo-tree-id1144 . -91) (undo-tree-id1145 . -91) (undo-tree-id1146 . -91) (undo-tree-id1147 . -91) (undo-tree-id1148 . -91) (undo-tree-id1149 . -91) (undo-tree-id1150 . -91) (undo-tree-id1151 . -91) (undo-tree-id1152 . -91) (undo-tree-id1153 . -91) (undo-tree-id1154 . -91) (undo-tree-id1155 . -91) (undo-tree-id1156 . -91) (undo-tree-id1157 . -91) (undo-tree-id1158 . -91) (undo-tree-id1159 . -91) (undo-tree-id1160 . -91) (undo-tree-id1161 . -91) (undo-tree-id1162 . -91) (undo-tree-id1163 . -91) (undo-tree-id1164 . -91) (undo-tree-id1165 . -91) (undo-tree-id1166 . -91) (undo-tree-id1167 . -91) (undo-tree-id1168 . -91) (undo-tree-id1169 . -91) (undo-tree-id1170 . -91) (undo-tree-id1171 . -91) (undo-tree-id1172 . -91) (undo-tree-id1173 . -91) (undo-tree-id1174 . -91) (undo-tree-id1175 . -91) (undo-tree-id1176 . -91) (undo-tree-id1177 . -91) (undo-tree-id1178 . -91) (undo-tree-id1179 . -91) (undo-tree-id1180 . -91) (undo-tree-id1181 . -91) (undo-tree-id1182 . -91) (undo-tree-id1183 . -91) (undo-tree-id1184 . -91) (undo-tree-id1185 . -91) (undo-tree-id1186 . -91) (undo-tree-id1187 . -91) (undo-tree-id1188 . -91) (undo-tree-id1189 . -91) (undo-tree-id1190 . -91) (undo-tree-id1191 . -91) (undo-tree-id1192 . -91) (undo-tree-id1193 . -91) (undo-tree-id1194 . -91) (undo-tree-id1195 . -91) (undo-tree-id1196 . -91) (undo-tree-id1197 . -91) (undo-tree-id1198 . -91) (undo-tree-id1199 . -91) (undo-tree-id1200 . -91) (undo-tree-id1201 . -91) (undo-tree-id1202 . -91) (undo-tree-id1203 . -91) (undo-tree-id1204 . -91) (undo-tree-id1205 . -91) (undo-tree-id1206 . -91) (undo-tree-id1207 . -91) (undo-tree-id1208 . -91) (undo-tree-id1209 . -91) (undo-tree-id1210 . -91) (undo-tree-id1211 . -91) (undo-tree-id1212 . -91) (undo-tree-id1213 . -91) (undo-tree-id1214 . -91) (undo-tree-id1215 . -91) (undo-tree-id1216 . -91) (undo-tree-id1217 . -91) (undo-tree-id1218 . -91) (undo-tree-id1219 . -91) (undo-tree-id1220 . -91) (undo-tree-id1221 . -91) (undo-tree-id1222 . -91) (undo-tree-id1223 . -91) (undo-tree-id1224 . -91) (undo-tree-id1225 . -91) (undo-tree-id1226 . -91) (undo-tree-id1227 . -91) (undo-tree-id1228 . -91) (undo-tree-id1229 . -91) (undo-tree-id1230 . -91) (undo-tree-id1231 . -91) (undo-tree-id1232 . -91) (undo-tree-id1233 . -91) (undo-tree-id1234 . -91) (undo-tree-id1235 . -91) (undo-tree-id1236 . -91) (undo-tree-id1237 . -91) (undo-tree-id1238 . -705) (undo-tree-id1239 . -705) (undo-tree-id1240 . -91) (undo-tree-id1241 . -91) (undo-tree-id1242 . -91) (undo-tree-id1243 . -91) (undo-tree-id1244 . -91) (undo-tree-id1245 . -91) (undo-tree-id1246 . -91) (undo-tree-id1247 . -91) (undo-tree-id1248 . -91) (undo-tree-id1249 . -91) (undo-tree-id1250 . -91) (undo-tree-id1251 . -91) (undo-tree-id1252 . -91) (undo-tree-id1253 . -91) (undo-tree-id1254 . -91) (undo-tree-id1255 . -91) (undo-tree-id1256 . -91) (undo-tree-id1257 . -91) (undo-tree-id1258 . -91) (undo-tree-id1259 . -91) (undo-tree-id1260 . -91) (undo-tree-id1261 . -91) (undo-tree-id1262 . -91) (undo-tree-id1263 . -91) (undo-tree-id1264 . -231) (undo-tree-id1265 . -231) (undo-tree-id1266 . -231) (undo-tree-id1267 . -231) (undo-tree-id1268 . -288) (undo-tree-id1269 . -288) (undo-tree-id1270 . -317) (undo-tree-id1271 . -317) (undo-tree-id1272 . -347) (undo-tree-id1273 . -347) (undo-tree-id1274 . -406) (undo-tree-id1275 . -406) (undo-tree-id1276 . -425) (undo-tree-id1277 . -429) (undo-tree-id1278 . -429) (undo-tree-id1279 . -442) (undo-tree-id1280 . -448) (undo-tree-id1281 . -448) (undo-tree-id1282 . -462) (undo-tree-id1283 . -556) (undo-tree-id1284 . -556) (undo-tree-id1285 . -638) (undo-tree-id1286 . -638) (undo-tree-id1287 . -645) (undo-tree-id1288 . -705) (undo-tree-id1289 . -705) (undo-tree-id1290 . -91) (undo-tree-id1291 . -91) (undo-tree-id1292 . -91) (undo-tree-id1293 . -91) (undo-tree-id1294 . -91) (undo-tree-id1295 . -91) (undo-tree-id1296 . -91) (undo-tree-id1297 . -91) (undo-tree-id1298 . -91) (undo-tree-id1299 . -91) (undo-tree-id1300 . -91) (undo-tree-id1301 . -91) (undo-tree-id1302 . -91) (undo-tree-id1303 . -91) (undo-tree-id1304 . -91) (undo-tree-id1305 . -91) (undo-tree-id1306 . -91) (undo-tree-id1307 . -91) (undo-tree-id1308 . -91) (undo-tree-id1309 . -91) (undo-tree-id1310 . -91) (undo-tree-id1311 . -91) (undo-tree-id1312 . -91) (undo-tree-id1313 . -91) (undo-tree-id1314 . -91) (undo-tree-id1315 . -91) (undo-tree-id1316 . -91) (undo-tree-id1317 . -91) (undo-tree-id1318 . -91) (undo-tree-id1319 . -91) (undo-tree-id1320 . -91) (undo-tree-id1321 . -91) (undo-tree-id1322 . -91) (undo-tree-id1323 . -91) (undo-tree-id1324 . -91) (undo-tree-id1325 . -91) (undo-tree-id1326 . -91) (undo-tree-id1327 . -91) (undo-tree-id1328 . -231) (undo-tree-id1329 . -231) (undo-tree-id1330 . -231) (undo-tree-id1331 . -231) (undo-tree-id1332 . -288) (undo-tree-id1333 . -288) (undo-tree-id1334 . -317) (undo-tree-id1335 . -317) (undo-tree-id1336 . -347) (undo-tree-id1337 . -347) (undo-tree-id1338 . -406) (undo-tree-id1339 . -406) (undo-tree-id1340 . -425) (undo-tree-id1341 . -429) (undo-tree-id1342 . -429) (undo-tree-id1343 . -442) (undo-tree-id1344 . -448) (undo-tree-id1345 . -448) (undo-tree-id1346 . -462) (undo-tree-id1347 . -556) (undo-tree-id1348 . -556) (undo-tree-id1349 . -638) (undo-tree-id1350 . -638) (undo-tree-id1351 . -645) (undo-tree-id1352 . -705) (undo-tree-id1353 . -705) (undo-tree-id1354 . -91) (undo-tree-id1355 . -91) (undo-tree-id1356 . -91) (undo-tree-id1357 . -91) (undo-tree-id1358 . -91) (undo-tree-id1359 . -91) (undo-tree-id1360 . -91) (undo-tree-id1361 . -91) (undo-tree-id1362 . -91) (undo-tree-id1363 . -91) (undo-tree-id1364 . -91) (undo-tree-id1365 . -91) (undo-tree-id1366 . -91) (undo-tree-id1367 . -91) (undo-tree-id1368 . -91) (undo-tree-id1369 . -91) (undo-tree-id1370 . -91) (undo-tree-id1371 . -91) (undo-tree-id1372 . -91) (undo-tree-id1373 . -91) (undo-tree-id1374 . -91) (undo-tree-id1375 . -91) (undo-tree-id1376 . -91) (undo-tree-id1377 . -91) (undo-tree-id1378 . -91) (undo-tree-id1379 . -91) (undo-tree-id1380 . -91) (undo-tree-id1381 . -91) (undo-tree-id1382 . -91) (undo-tree-id1383 . -91) (undo-tree-id1384 . -91) (undo-tree-id1385 . -91) (undo-tree-id1386 . -91) (undo-tree-id1387 . -91) (undo-tree-id1388 . -91) (undo-tree-id1389 . -91) (undo-tree-id1390 . -91) (undo-tree-id1391 . -91) (undo-tree-id1392 . -91) (undo-tree-id1393 . -91) (undo-tree-id1394 . -91) (undo-tree-id1395 . -91) (undo-tree-id1396 . -91) (undo-tree-id1397 . -91) (undo-tree-id1398 . -91) (undo-tree-id1399 . -91) (undo-tree-id1400 . -91) (undo-tree-id1401 . -91) (undo-tree-id1402 . -91) (undo-tree-id1403 . -231) (undo-tree-id1404 . -231) (undo-tree-id1405 . -231) (undo-tree-id1406 . -231) (undo-tree-id1407 . -288) (undo-tree-id1408 . -288) (undo-tree-id1409 . -317) (undo-tree-id1410 . -317) (undo-tree-id1411 . -347) (undo-tree-id1412 . -347) (undo-tree-id1413 . -406) (undo-tree-id1414 . -406) (undo-tree-id1415 . -425) (undo-tree-id1416 . -429) (undo-tree-id1417 . -429) (undo-tree-id1418 . -442) (undo-tree-id1419 . -448) (undo-tree-id1420 . -448) (undo-tree-id1421 . -462) (undo-tree-id1422 . -556) (undo-tree-id1423 . -556) (undo-tree-id1424 . -638) (undo-tree-id1425 . -638) (undo-tree-id1426 . -645) (undo-tree-id1427 . -705) (undo-tree-id1428 . -705) (undo-tree-id1429 . -91) (undo-tree-id1430 . -91) (undo-tree-id1431 . -91) (undo-tree-id1432 . -91) (undo-tree-id1433 . -91) (undo-tree-id1434 . -91) (undo-tree-id1435 . -91) (undo-tree-id1436 . -91) (undo-tree-id1437 . -91) (undo-tree-id1438 . -91) (undo-tree-id1439 . -91) (undo-tree-id1440 . -109) (undo-tree-id1441 . -91) (undo-tree-id1442 . -91) (undo-tree-id1443 . -91) (undo-tree-id1444 . -91) (undo-tree-id1445 . -91) (undo-tree-id1446 . -91) (undo-tree-id1447 . -91) (undo-tree-id1448 . -91) (undo-tree-id1449 . -91) (undo-tree-id1450 . -91) (undo-tree-id1451 . -91) (undo-tree-id1452 . -91) (undo-tree-id1453 . -91) (undo-tree-id1454 . -91) (undo-tree-id1455 . -91) (undo-tree-id1456 . -91) (undo-tree-id1457 . -91) (undo-tree-id1458 . -91) (undo-tree-id1459 . -91) (undo-tree-id1460 . -91) (undo-tree-id1461 . -91) (undo-tree-id1462 . -91) (undo-tree-id1463 . -91) (undo-tree-id1464 . -91) (undo-tree-id1465 . -91) (undo-tree-id1466 . -91) (undo-tree-id1467 . -91) (undo-tree-id1468 . -91) (undo-tree-id1469 . -91) (undo-tree-id1470 . -91) (undo-tree-id1471 . -91) (undo-tree-id1472 . -91) (undo-tree-id1473 . -91) (undo-tree-id1474 . -91) (undo-tree-id1475 . -91) (undo-tree-id1476 . -91) (undo-tree-id1477 . -91) (undo-tree-id1478 . -91) (undo-tree-id1479 . -91) (undo-tree-id1480 . -91) (undo-tree-id1481 . -91) (undo-tree-id1482 . -91) (undo-tree-id1483 . -91) (undo-tree-id1484 . -91) (undo-tree-id1485 . -91) (undo-tree-id1486 . -91) (undo-tree-id1487 . -91) (undo-tree-id1488 . -91) (undo-tree-id1489 . -91) (undo-tree-id1490 . -91) (undo-tree-id1491 . -91) (undo-tree-id1492 . -91) (undo-tree-id1493 . -91) (undo-tree-id1494 . -91) (undo-tree-id1495 . -91) (undo-tree-id1496 . -91) (undo-tree-id1497 . -91) (undo-tree-id1498 . -91) (undo-tree-id1499 . -91) (undo-tree-id1500 . -91) (undo-tree-id1501 . -91) (undo-tree-id1502 . -91) (undo-tree-id1503 . -91) (undo-tree-id1504 . -109) (undo-tree-id1505 . -91) (undo-tree-id1506 . -91) (undo-tree-id1507 . -91) (undo-tree-id1508 . -91) (undo-tree-id1509 . -91) (undo-tree-id1510 . -91) (undo-tree-id1511 . -91) (undo-tree-id1512 . -91) (undo-tree-id1513 . -91) (undo-tree-id1514 . -91) (undo-tree-id1515 . -91) (undo-tree-id1516 . -91) (undo-tree-id1517 . -91) (undo-tree-id1518 . -91) (undo-tree-id1519 . -91) (undo-tree-id1520 . -91) (undo-tree-id1521 . -91) (undo-tree-id1522 . -91) (undo-tree-id1523 . -91) (undo-tree-id1524 . -91) (undo-tree-id1525 . -91) (undo-tree-id1526 . -91) (undo-tree-id1527 . -91) (undo-tree-id1528 . -91) (undo-tree-id1529 . -91) (undo-tree-id1530 . -91) (undo-tree-id1531 . -91) (undo-tree-id1532 . -91) (undo-tree-id1533 . -91) (undo-tree-id1534 . -91) (undo-tree-id1535 . -91) (undo-tree-id1536 . -91) (undo-tree-id1537 . -91) (undo-tree-id1538 . -91) (undo-tree-id1539 . -91) (undo-tree-id1540 . -110) (undo-tree-id1541 . -110) (undo-tree-id1542 . -110) (undo-tree-id1543 . -110) (undo-tree-id1544 . -110) (undo-tree-id1545 . -110) (undo-tree-id1546 . -110) (undo-tree-id1547 . -110) (undo-tree-id1548 . -110) (undo-tree-id1549 . -110) (undo-tree-id1550 . -110) (undo-tree-id1551 . -110) (undo-tree-id1552 . -110) (undo-tree-id1553 . -110) (undo-tree-id1554 . -110) (undo-tree-id1555 . -231) (undo-tree-id1556 . -231) (undo-tree-id1557 . -231) (undo-tree-id1558 . -231) (undo-tree-id1559 . -288) (undo-tree-id1560 . -288) (undo-tree-id1561 . -317) (undo-tree-id1562 . -317) (undo-tree-id1563 . -347) (undo-tree-id1564 . -347) (undo-tree-id1565 . -406) (undo-tree-id1566 . -406) (undo-tree-id1567 . -425) (undo-tree-id1568 . -429) (undo-tree-id1569 . -429) (undo-tree-id1570 . -442) (undo-tree-id1571 . -448) (undo-tree-id1572 . -448) (undo-tree-id1573 . -462) (undo-tree-id1574 . -556) (undo-tree-id1575 . -556) (undo-tree-id1576 . -638) (undo-tree-id1577 . -638) (undo-tree-id1578 . -645) (undo-tree-id1579 . -705) (undo-tree-id1580 . -705) (undo-tree-id1581 . -110) (undo-tree-id1582 . -110) (undo-tree-id1583 . -110) (undo-tree-id1584 . -110) (undo-tree-id1585 . -110) (undo-tree-id1586 . -110) (undo-tree-id1587 . -110) (undo-tree-id1588 . -110) (undo-tree-id1589 . -110) (undo-tree-id1590 . -110) (undo-tree-id1591 . -110) (undo-tree-id1592 . -110) (undo-tree-id1593 . -110) (undo-tree-id1594 . -110) (undo-tree-id1595 . -110) (undo-tree-id1596 . -110) (undo-tree-id1597 . -110) (undo-tree-id1598 . -110) (undo-tree-id1599 . -110) (undo-tree-id1600 . -110) (undo-tree-id1601 . -110) (undo-tree-id1602 . -110) (undo-tree-id1603 . -110) (undo-tree-id1604 . -110) (undo-tree-id1605 . -110) (undo-tree-id1606 . -110) (undo-tree-id1607 . -110) (undo-tree-id1608 . -110) (undo-tree-id1609 . -110) (undo-tree-id1610 . -110) (undo-tree-id1611 . -134) (undo-tree-id1612 . -110) (undo-tree-id1613 . -110) (undo-tree-id1614 . -110) (undo-tree-id1615 . -110) (undo-tree-id1616 . -110) (undo-tree-id1617 . -110) (undo-tree-id1618 . -110) (undo-tree-id1619 . -110) (undo-tree-id1620 . -110) (undo-tree-id1621 . -110) (undo-tree-id1622 . -231) (undo-tree-id1623 . -231) (undo-tree-id1624 . -231) (undo-tree-id1625 . -231) (undo-tree-id1626 . -288) (undo-tree-id1627 . -288) (undo-tree-id1628 . -317) (undo-tree-id1629 . -317) (undo-tree-id1630 . -347) (undo-tree-id1631 . -347) (undo-tree-id1632 . -406) (undo-tree-id1633 . -406) (undo-tree-id1634 . -425) (undo-tree-id1635 . -429) (undo-tree-id1636 . -429) (undo-tree-id1637 . -442) (undo-tree-id1638 . -448) (undo-tree-id1639 . -448) (undo-tree-id1640 . -462) (undo-tree-id1641 . -556) (undo-tree-id1642 . -556) (undo-tree-id1643 . -638) (undo-tree-id1644 . -638) (undo-tree-id1645 . -645) (undo-tree-id1646 . -705) (undo-tree-id1647 . -705) (undo-tree-id1648 . -110) (undo-tree-id1649 . -110) (undo-tree-id1650 . -110) (undo-tree-id1651 . -110) (undo-tree-id1652 . -110) (undo-tree-id1653 . -110) (undo-tree-id1654 . -110) (undo-tree-id1655 . -110) (undo-tree-id1656 . -110) (undo-tree-id1657 . -110) (undo-tree-id1658 . -110) (undo-tree-id1659 . -110) (undo-tree-id1660 . -110) (undo-tree-id1661 . -110) (undo-tree-id1662 . -110) (undo-tree-id1663 . -110) (undo-tree-id1664 . -110) (undo-tree-id1665 . -110) (undo-tree-id1666 . -110) (undo-tree-id1667 . -110) (undo-tree-id1668 . -110) (undo-tree-id1669 . -110) (undo-tree-id1670 . -110) (undo-tree-id1671 . -110) (undo-tree-id1672 . -110) (undo-tree-id1673 . -110) (undo-tree-id1674 . -110) (undo-tree-id1675 . -110) (undo-tree-id1676 . -110) (undo-tree-id1677 . -110) (undo-tree-id1678 . -110) (undo-tree-id1679 . -110) (undo-tree-id1680 . -110) (undo-tree-id1681 . -110) (undo-tree-id1682 . -110) (undo-tree-id1683 . -135) (undo-tree-id1684 . -135) (undo-tree-id1685 . -135) (undo-tree-id1686 . -135) (undo-tree-id1687 . -135) (undo-tree-id1688 . -135) (undo-tree-id1689 . -135) (undo-tree-id1690 . -135) (undo-tree-id1691 . -135) (undo-tree-id1692 . -136) (undo-tree-id1693 . -136) (undo-tree-id1694 . -136) (undo-tree-id1695 . -136) (undo-tree-id1696 . -136) (undo-tree-id1697 . -136) (undo-tree-id1698 . -136) (undo-tree-id1699 . -136) (undo-tree-id1700 . -136) (undo-tree-id1701 . -136) (undo-tree-id1702 . -136) (undo-tree-id1703 . -136) (undo-tree-id1704 . -136) (undo-tree-id1705 . -136) (undo-tree-id1706 . -136) (undo-tree-id1707 . -136) (undo-tree-id1708 . -136) (undo-tree-id1709 . -136) (undo-tree-id1710 . -136) (undo-tree-id1711 . -136) (undo-tree-id1712 . -136) (undo-tree-id1713 . -136) (undo-tree-id1714 . -136) (undo-tree-id1715 . -136) (undo-tree-id1716 . -136) (undo-tree-id1717 . -136) (undo-tree-id1718 . -136) (undo-tree-id1719 . -188) (undo-tree-id1720 . -188) (undo-tree-id1721 . -188) (undo-tree-id1722 . -188) (undo-tree-id1723 . -188) (undo-tree-id1724 . -188) (undo-tree-id1725 . -188) (undo-tree-id1726 . -188) (undo-tree-id1727 . -207) (undo-tree-id1728 . -207) (undo-tree-id1729 . -207) (undo-tree-id1730 . -207) (undo-tree-id1731 . -207) (undo-tree-id1732 . -207) (undo-tree-id1733 . -207) (undo-tree-id1734 . -207) (undo-tree-id1735 . -230) (undo-tree-id1736 . -230) (undo-tree-id1737 . -230) (undo-tree-id1738 . -230) (undo-tree-id1739 . -230) (undo-tree-id1740 . -230) (undo-tree-id1741 . -230) (undo-tree-id1742 . -230) (undo-tree-id1743 . -231) (undo-tree-id1744 . -231) (undo-tree-id1745 . -231) (undo-tree-id1746 . -231) (undo-tree-id1747 . -231) (undo-tree-id1748 . -231) (undo-tree-id1749 . -231) (undo-tree-id1750 . -231) (undo-tree-id1751 . -231) (undo-tree-id1752 . -231) (undo-tree-id1753 . -231) (undo-tree-id1754 . -231) (undo-tree-id1755 . -231) (undo-tree-id1756 . -231) (undo-tree-id1757 . -231) (undo-tree-id1758 . -231) (undo-tree-id1759 . -231) (undo-tree-id1760 . -231) (undo-tree-id1761 . -231) (undo-tree-id1762 . -231) (undo-tree-id1763 . -231) (undo-tree-id1764 . -231) (undo-tree-id1765 . -231) (undo-tree-id1766 . -231) (undo-tree-id1767 . -231) (undo-tree-id1768 . -231) (undo-tree-id1769 . -231) (undo-tree-id1770 . -231) (undo-tree-id1771 . -231) (undo-tree-id1772 . -231) (undo-tree-id1773 . -231) (undo-tree-id1774 . -231) (undo-tree-id1775 . -231) (undo-tree-id1776 . -231) (undo-tree-id1777 . -231) (undo-tree-id1778 . -231) (undo-tree-id1779 . -231) (undo-tree-id1780 . -231) (undo-tree-id1781 . -231) (undo-tree-id1782 . -231) (undo-tree-id1783 . -231) (undo-tree-id1784 . -231) (undo-tree-id1785 . -231) (undo-tree-id1786 . -231) (undo-tree-id1787 . -231) (undo-tree-id1788 . -231) (undo-tree-id1789 . -231) (undo-tree-id1790 . -231) (undo-tree-id1791 . -231) (undo-tree-id1792 . -231) (undo-tree-id1793 . -231) (undo-tree-id1794 . -231) (undo-tree-id1795 . -288) (undo-tree-id1796 . -288) (undo-tree-id1797 . -317) (undo-tree-id1798 . -317) (undo-tree-id1799 . -347) (undo-tree-id1800 . -347) (undo-tree-id1801 . -406) (undo-tree-id1802 . -406) (undo-tree-id1803 . -425) (undo-tree-id1804 . -429) (undo-tree-id1805 . -429) (undo-tree-id1806 . -442) (undo-tree-id1807 . -448) (undo-tree-id1808 . -448) (undo-tree-id1809 . -462) (undo-tree-id1810 . -556) (undo-tree-id1811 . -556) (undo-tree-id1812 . -638) (undo-tree-id1813 . -638) (undo-tree-id1814 . -645) (undo-tree-id1815 . -705) (undo-tree-id1816 . -705) (undo-tree-id1817 . -231) (undo-tree-id1818 . -231) (undo-tree-id1819 . -231) (undo-tree-id1820 . -231) (undo-tree-id1821 . -231) (undo-tree-id1822 . -231) (undo-tree-id1823 . -231) (undo-tree-id1824 . -231) (undo-tree-id1825 . -231) (undo-tree-id1826 . -231) (undo-tree-id1827 . -231) (undo-tree-id1828 . -231) (undo-tree-id1829 . -231) (undo-tree-id1830 . -231) (undo-tree-id1831 . -231) (undo-tree-id1832 . -231) (undo-tree-id1833 . -231) (undo-tree-id1834 . -231) (undo-tree-id1835 . -231) (undo-tree-id1836 . -231) (undo-tree-id1837 . -231) (undo-tree-id1838 . -231) (undo-tree-id1839 . -231) (undo-tree-id1840 . -231) (undo-tree-id1841 . -231) (undo-tree-id1842 . -231) (undo-tree-id1843 . -231) (undo-tree-id1844 . -231) (undo-tree-id1845 . -231) (undo-tree-id1846 . -231) (undo-tree-id1847 . -231) (undo-tree-id1848 . -231) (undo-tree-id1849 . -231) (undo-tree-id1850 . -231) (undo-tree-id1851 . -231) (undo-tree-id1852 . -231) (undo-tree-id1853 . -231) (undo-tree-id1854 . -231) (undo-tree-id1855 . -231) (undo-tree-id1856 . -231) (undo-tree-id1857 . -231) (undo-tree-id1858 . -231) (undo-tree-id1859 . -231) (undo-tree-id1860 . -231) (undo-tree-id1861 . -231) (undo-tree-id1862 . -255) (undo-tree-id1863 . -231) (undo-tree-id1864 . -231) (undo-tree-id1865 . -231) (undo-tree-id1866 . -231) (undo-tree-id1867 . -231) (undo-tree-id1868 . -231) (undo-tree-id1869 . -231) (undo-tree-id1870 . -231) (undo-tree-id1871 . -231) (undo-tree-id1872 . -231) (undo-tree-id1873 . -231) (undo-tree-id1874 . -231) (undo-tree-id1875 . -231) (undo-tree-id1876 . -231) (undo-tree-id1877 . -231) (undo-tree-id1878 . -231) (undo-tree-id1879 . -231) (undo-tree-id1880 . -231) (undo-tree-id1881 . -231) (undo-tree-id1882 . -231) (undo-tree-id1883 . -231) (undo-tree-id1884 . -231) (undo-tree-id1885 . -231) (undo-tree-id1886 . -231) (undo-tree-id1887 . -231) (undo-tree-id1888 . -231) (undo-tree-id1889 . -231) (undo-tree-id1890 . -231) (undo-tree-id1891 . -231) (undo-tree-id1892 . -231) (undo-tree-id1893 . -231) (undo-tree-id1894 . -231) (undo-tree-id1895 . -231) (undo-tree-id1896 . -231) (undo-tree-id1897 . -231) (undo-tree-id1898 . -230) (undo-tree-id1899 . -230) (undo-tree-id1900 . -230) (undo-tree-id1901 . -230) (undo-tree-id1902 . -230) (undo-tree-id1903 . -230) (undo-tree-id1904 . -230) (undo-tree-id1905 . -230) (undo-tree-id1906 . -230) (undo-tree-id1907 . -288) (undo-tree-id1908 . -288) (undo-tree-id1909 . -317) (undo-tree-id1910 . -317) (undo-tree-id1911 . -347) (undo-tree-id1912 . -347) (undo-tree-id1913 . -406) (undo-tree-id1914 . -406) (undo-tree-id1915 . -425) (undo-tree-id1916 . -429) (undo-tree-id1917 . -429) (undo-tree-id1918 . -442) (undo-tree-id1919 . -448) (undo-tree-id1920 . -448) (undo-tree-id1921 . -462) (undo-tree-id1922 . -556) (undo-tree-id1923 . -556) (undo-tree-id1924 . -638) (undo-tree-id1925 . -638) (undo-tree-id1926 . -645) (undo-tree-id1927 . -705) (undo-tree-id1928 . -705) (undo-tree-id1929 . -230) (undo-tree-id1930 . -230) (undo-tree-id1931 . -230) (undo-tree-id1932 . -230) (undo-tree-id1933 . -230) (undo-tree-id1934 . -230) (undo-tree-id1935 . -230) (undo-tree-id1936 . -230) (undo-tree-id1937 . -230) (undo-tree-id1938 . -230) (undo-tree-id1939 . -230) (undo-tree-id1940 . -230) (undo-tree-id1941 . -230) (undo-tree-id1942 . -230) (undo-tree-id1943 . -230) (undo-tree-id1944 . -230) (undo-tree-id1945 . -230) (undo-tree-id1946 . -230) (undo-tree-id1947 . -230) (undo-tree-id1948 . -230) (undo-tree-id1949 . -230) (undo-tree-id1950 . -230) (undo-tree-id1951 . -230) (undo-tree-id1952 . -230) (undo-tree-id1953 . -230) (undo-tree-id1954 . -230) (undo-tree-id1955 . -230) (undo-tree-id1956 . -230) (undo-tree-id1957 . -230) (undo-tree-id1958 . -230) (undo-tree-id1959 . -230) (undo-tree-id1960 . -230) (undo-tree-id1961 . -230) (undo-tree-id1962 . -230)) nil (25760 29817 770064 781000) 0 nil])
([nil nil ((#("# Where to save the figures
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 28 (fontified t face font-lock-comment-face)) . 380) (undo-tree-id2758 . -27) (undo-tree-id2759 . -28) (t 25760 29817 812781 706000)) nil (25760 29832 837842 59000) 0 nil])
([nil nil ((#("PROJECT_ROOT_DIR = \".\"
" 0 16 (fontified t face font-lock-variable-name-face) 16 19 (fontified t) 19 22 (fontified t face font-lock-string-face) 22 23 (fontified t)) . 380) (undo-tree-id2754 . -22) (undo-tree-id2755 . -19) (undo-tree-id2756 . -22) (undo-tree-id2757 . -23)) nil (25760 29832 837838 122000) 0 nil])
([nil nil ((#("CHAPTER_ID = \"rnn\"
" 0 10 (fontified t face font-lock-variable-name-face) 10 13 (fontified t) 13 18 (fontified t face font-lock-string-face) 18 19 (fontified t)) . 380) (undo-tree-id2750 . -18) (undo-tree-id2751 . -13) (undo-tree-id2752 . -18) (undo-tree-id2753 . -19)) nil (25760 29832 837424 595000) 0 nil])
([nil nil ((#("IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)
" 0 11 (fontified t face font-lock-variable-name-face) 11 26 (fontified t) 26 27 (fontified t face (rainbow-delimiters-depth-1-face)) 27 45 (fontified t) 45 51 (fontified t face font-lock-string-face) 51 53 (fontified t face font-lock-string-face) 53 65 (fontified t) 65 66 (fontified t face (rainbow-delimiters-depth-1-face)) 66 67 (fontified t)) . 380) (undo-tree-id2743 . -66) (undo-tree-id2744 . -14) (undo-tree-id2745 . -16) (undo-tree-id2746 . -67) (undo-tree-id2747 . -14) (undo-tree-id2748 . -66) (undo-tree-id2749 . -67)) nil (25760 29832 837419 596000) 0 nil])
([nil nil ((#("os.makedirs(IMAGES_PATH, exist_ok=True)
" 0 11 (fontified t) 11 12 (fontified t face (rainbow-delimiters-depth-1-face)) 12 34 (fontified t) 34 38 (fontified t face font-lock-constant-face) 38 39 (fontified t face (rainbow-delimiters-depth-1-face)) 39 40 (fontified t)) . 380) (undo-tree-id2739 . -39) (undo-tree-id2740 . -2) (undo-tree-id2741 . -39) (undo-tree-id2742 . -40)) nil (25760 29832 837414 404000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2738 . -1)) nil (25760 29832 837411 332000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2737 . -1)) nil (25760 29832 837409 968000) 0 nil])
([nil nil ((#("def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):
" 0 3 (fontified t face font-lock-keyword-face) 3 4 (fontified t) 4 12 (fontified t face font-lock-function-name-face) 12 13 (fontified t face (rainbow-delimiters-depth-1-face)) 13 34 (fontified t) 34 38 (fontified t face font-lock-constant-face) 38 54 (fontified t) 54 59 (fontified t face font-lock-string-face) 59 75 (fontified t) 75 76 (fontified t face (rainbow-delimiters-depth-1-face)) 76 77 (fontified t) 77 78 (fontified t)) . 380) (undo-tree-id2734 . -77) (undo-tree-id2735 . -77) (undo-tree-id2736 . -78)) nil (25760 29832 837408 296000) 0 nil])
([nil nil ((#("    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)
" 0 4 (fontified t) 4 8 (fontified t face font-lock-variable-name-face) 8 23 (fontified t) 23 24 (fontified t face (rainbow-delimiters-depth-1-face)) 24 46 (fontified t) 46 49 (fontified t face font-lock-string-face) 49 65 (fontified t) 65 66 (fontified t face (rainbow-delimiters-depth-1-face)) 66 67 (fontified t)) . 380) (undo-tree-id2726 . -66) (undo-tree-id2727 . -11) (undo-tree-id2728 . -13) (undo-tree-id2729 . -4) (undo-tree-id2730 . -4) (undo-tree-id2731 . -11) (undo-tree-id2732 . -66) (undo-tree-id2733 . -67)) nil (25760 29832 837405 209000) 0 nil])
([nil nil ((#("    print(\"Saving figure\", fig_id)
" 0 4 (fontified t) 4 9 (fontified t face font-lock-keyword-face) 9 10 (fontified t face (rainbow-delimiters-depth-1-face)) 10 25 (fontified t face font-lock-string-face) 25 33 (fontified t) 33 34 (fontified t face (rainbow-delimiters-depth-1-face)) 34 35 (fontified t)) . 380) (undo-tree-id2721 . -34) (undo-tree-id2722 . -4) (undo-tree-id2723 . -4) (undo-tree-id2724 . -34) (undo-tree-id2725 . -35)) nil (25760 29832 837399 552000) 0 nil])
([nil nil ((#("    if tight_layout:
" 0 4 (fontified t) 4 6 (fontified t face font-lock-keyword-face) 6 20 (fontified t) 20 21 (fontified t)) . 380) (undo-tree-id2718 . -20) (undo-tree-id2719 . -20) (undo-tree-id2720 . -21)) nil (25760 29832 837396 1000) 0 nil])
([nil nil ((#("        plt.tight_layout()
" 0 24 (fontified t) 24 25 (fontified t face (rainbow-delimiters-depth-1-face)) 25 26 (fontified t face (rainbow-delimiters-depth-1-face)) 26 27 (fontified t)) . 380) (undo-tree-id2715 . -26) (undo-tree-id2716 . -26) (undo-tree-id2717 . -27)) nil (25760 29832 837393 295000) 0 nil])
([nil nil ((#("    plt.savefig(path, format=fig_extension, dpi=resolution)
" 0 15 (fontified t) 15 16 (fontified t face (rainbow-delimiters-depth-1-face)) 16 22 (fontified t) 22 28 (fontified t face font-lock-builtin-face) 28 58 (fontified t) 58 59 (fontified t face (rainbow-delimiters-depth-1-face)) 59 60 (fontified t)) . 380) (undo-tree-id2712 . -59) (undo-tree-id2713 . -59) (undo-tree-id2714 . -60)) nil (25760 29832 837390 817000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2711 . -1)) nil (25760 29832 837388 185000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2710 . -1)) nil (25760 29832 837386 574000) 0 nil])
([nil nil ((#("# # Basic RNNs
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 14 (fontified t face font-lock-comment-face) 14 15 (fontified t face font-lock-comment-face)) . 380) (undo-tree-id2707 . -14) (undo-tree-id2708 . -14) (undo-tree-id2709 . -15)) nil (25760 29832 837385 9000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2706 . -1)) nil (25760 29832 837382 48000) 0 nil])
([nil nil ((#("# ## Generate the Dataset
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 25 (fontified t face font-lock-comment-face) 25 26 (fontified t face font-lock-comment-face)) . 380) (undo-tree-id2703 . -25) (undo-tree-id2704 . -25) (undo-tree-id2705 . -26)) nil (25760 29832 837380 440000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2702 . -1)) nil (25760 29832 837377 641000) 0 nil])
([nil nil ((#("# In[2]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 380) (undo-tree-id2699 . -8) (undo-tree-id2700 . -8) (undo-tree-id2701 . -9)) nil (25760 29832 837375 56000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 380) (undo-tree-id2698 . -1)) nil (25760 29832 837368 271000) 0 nil])
([nil nil ((#("def generate_time_series(batch_size, n_steps):
    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)
    time = np.linspace(0, 1, n_steps)
    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1
    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))  # + wave 2
    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)  # + noise
    return series[..., np.newaxis].astype(np.float32)


# In[3]:
" 0 3 (fontified t face font-lock-keyword-face) 3 4 (fontified t) 4 24 (fontified t face font-lock-function-name-face) 24 25 (fontified t face (rainbow-delimiters-depth-1-face)) 25 44 (fontified t) 44 45 (fontified t face (rainbow-delimiters-depth-1-face)) 45 51 (fontified t) 51 56 (fontified t face font-lock-variable-name-face) 56 58 (fontified t) 58 63 (fontified t face font-lock-variable-name-face) 63 65 (fontified t) 65 73 (fontified t face font-lock-variable-name-face) 73 75 (fontified t) 75 83 (fontified t face font-lock-variable-name-face) 83 100 (fontified t) 100 101 (fontified t face (rainbow-delimiters-depth-1-face)) 101 114 (fontified t) 114 117 (fontified t) 117 118 (fontified t face (rainbow-delimiters-depth-1-face)) 118 119 (fontified t) 119 123 (fontified t) 123 127 (fontified t face font-lock-variable-name-face) 127 141 (fontified t) 141 142 (fontified t face (rainbow-delimiters-depth-1-face)) 142 153 (fontified t) 153 155 (fontified t) 155 156 (fontified t face (rainbow-delimiters-depth-1-face)) 156 157 (fontified t) 157 161 (fontified t) 161 167 (fontified t face font-lock-variable-name-face) 167 182 (fontified t) 182 183 (fontified t face (rainbow-delimiters-depth-1-face)) 183 184 (fontified t face (rainbow-delimiters-depth-2-face)) 184 199 (fontified t) 199 200 (fontified t face (rainbow-delimiters-depth-2-face)) 200 203 (fontified t) 203 204 (fontified t face (rainbow-delimiters-depth-2-face)) 204 219 (fontified t) 219 220 (fontified t face (rainbow-delimiters-depth-2-face)) 220 221 (fontified t face (rainbow-delimiters-depth-1-face)) 221 223 (fontified t) 223 227 (fontified t face font-lock-comment-delimiter-face) 227 233 (fontified t face font-lock-comment-face) 233 234 (fontified t face font-lock-comment-face) 234 238 (fontified t) 238 244 (fontified t face font-lock-variable-name-face) 244 260 (fontified t) 260 261 (fontified t face (rainbow-delimiters-depth-1-face)) 261 262 (fontified t face (rainbow-delimiters-depth-2-face)) 262 277 (fontified t) 277 278 (fontified t face (rainbow-delimiters-depth-2-face)) 278 281 (fontified t) 281 282 (fontified t face (rainbow-delimiters-depth-2-face)) 282 297 (fontified t) 297 298 (fontified t face (rainbow-delimiters-depth-2-face)) 298 299 (fontified t face (rainbow-delimiters-depth-1-face)) 299 300 (fontified t) 300 301 (fontified t) 301 303 (fontified t face font-lock-comment-delimiter-face) 303 312 (fontified t face font-lock-comment-face) 312 316 (fontified t) 316 322 (fontified t face font-lock-variable-name-face) 322 332 (fontified t) 332 333 (fontified t face (rainbow-delimiters-depth-1-face)) 333 335 (fontified t) 335 347 (fontified t) 347 348 (fontified t face (rainbow-delimiters-depth-2-face)) 348 367 (fontified t) 367 368 (fontified t face (rainbow-delimiters-depth-2-face)) 368 374 (fontified t) 374 375 (fontified t face (rainbow-delimiters-depth-1-face)) 375 377 (fontified t) 377 379 (fontified t face font-lock-comment-delimiter-face) 379 387 (fontified t face font-lock-comment-face) 387 391 (fontified t) 391 397 (fontified t face font-lock-keyword-face) 397 404 (fontified t) 404 405 (fontified t face (rainbow-delimiters-depth-1-face)) 405 420 (fontified t) 420 421 (fontified t face (rainbow-delimiters-depth-1-face)) 421 428 (fontified t) 428 429 (fontified t face (rainbow-delimiters-depth-1-face)) 429 439 (fontified t) 439 440 (fontified t face (rainbow-delimiters-depth-1-face)) 440 443 (fontified t) 443 444 (fontified t face font-lock-comment-delimiter-face) 444 445 (fontified t face font-lock-comment-delimiter-face) 445 452 (fontified t face font-lock-comment-face)) . 381) (undo-tree-id3600 . -451) (undo-tree-id3601 . -223) (undo-tree-id3602 . -224) (undo-tree-id3603 . -4) (undo-tree-id3604 . -12) (undo-tree-id3605 . -13) (undo-tree-id3606 . -17) (undo-tree-id3607 . -18) (undo-tree-id3608 . -24) (undo-tree-id3609 . -24) (undo-tree-id3610 . -24) (undo-tree-id3611 . -24) (undo-tree-id3612 . -24) (undo-tree-id3613 . -24) (undo-tree-id3614 . -24) (undo-tree-id3615 . -24) (undo-tree-id3616 . -24) (undo-tree-id3617 . -24) (undo-tree-id3618 . -24) (undo-tree-id3619 . -24) (undo-tree-id3620 . -24) (undo-tree-id3621 . -24) (undo-tree-id3622 . -24) (undo-tree-id3623 . -24) (undo-tree-id3624 . -24) (undo-tree-id3625 . -24) (undo-tree-id3626 . -24) (undo-tree-id3627 . -24) (undo-tree-id3628 . -24) (undo-tree-id3629 . -24) (undo-tree-id3630 . -24) (undo-tree-id3631 . -24) (undo-tree-id3632 . -24) (undo-tree-id3633 . -24) (undo-tree-id3634 . -24) (undo-tree-id3635 . -24) (undo-tree-id3636 . -24) (undo-tree-id3637 . -24) (undo-tree-id3638 . -24) (undo-tree-id3639 . -24) (undo-tree-id3640 . -24) (undo-tree-id3641 . -24) (undo-tree-id3642 . -24) (undo-tree-id3643 . -24) (undo-tree-id3644 . -24) (undo-tree-id3645 . -24) (undo-tree-id3646 . -24) (undo-tree-id3647 . -24) (undo-tree-id3648 . -24) (undo-tree-id3649 . -24) (undo-tree-id3650 . -24) (undo-tree-id3651 . -24) (undo-tree-id3652 . -24) (undo-tree-id3653 . -24) (undo-tree-id3654 . -24) (undo-tree-id3655 . -24) (undo-tree-id3656 . -24) (undo-tree-id3657 . -24) (undo-tree-id3658 . -24) (undo-tree-id3659 . -24) (undo-tree-id3660 . -24) (undo-tree-id3661 . -24) (undo-tree-id3662 . -24) (undo-tree-id3663 . -24) (undo-tree-id3664 . -24) (undo-tree-id3665 . -24) (undo-tree-id3666 . -24) (undo-tree-id3667 . -24) (undo-tree-id3668 . -24) (undo-tree-id3669 . -24) (undo-tree-id3670 . -24) (undo-tree-id3671 . -443) (undo-tree-id3672 . -24) (undo-tree-id3673 . -24) (undo-tree-id3674 . -24) (undo-tree-id3675 . -24) (undo-tree-id3676 . -24) (undo-tree-id3677 . -24) (undo-tree-id3678 . -24) (undo-tree-id3679 . -24) (undo-tree-id3680 . -24) (undo-tree-id3681 . -24) (undo-tree-id3682 . -24) (undo-tree-id3683 . -24) (undo-tree-id3684 . -24) (undo-tree-id3685 . -24) (undo-tree-id3686 . -24) (undo-tree-id3687 . -24) (undo-tree-id3688 . -24) (undo-tree-id3689 . -24) (undo-tree-id3690 . -24) (undo-tree-id3691 . -24) (undo-tree-id3692 . -24) (undo-tree-id3693 . -24) (undo-tree-id3694 . -24) (undo-tree-id3695 . -24) (undo-tree-id3696 . -24) (undo-tree-id3697 . -443) (undo-tree-id3698 . -443) (undo-tree-id3699 . -452) (undo-tree-id3700 . -443) (undo-tree-id3701 . -47) (undo-tree-id3702 . -47) (undo-tree-id3703 . -47) (undo-tree-id3704 . -47) (undo-tree-id3705 . -47) (undo-tree-id3706 . -47) (undo-tree-id3707 . -47) (undo-tree-id3708 . -47) (undo-tree-id3709 . -47) (undo-tree-id3710 . -47) (undo-tree-id3711 . -47) (undo-tree-id3712 . -47) (undo-tree-id3713 . -47) (undo-tree-id3714 . -47) (undo-tree-id3715 . -47) (undo-tree-id3716 . -47) (undo-tree-id3717 . -47) (undo-tree-id3718 . -47) (undo-tree-id3719 . -47) (undo-tree-id3720 . -47) (undo-tree-id3721 . -47) (undo-tree-id3722 . -47) (undo-tree-id3723 . -47) (undo-tree-id3724 . -47) (undo-tree-id3725 . -47) (undo-tree-id3726 . -47) (undo-tree-id3727 . -47) (undo-tree-id3728 . -47) (undo-tree-id3729 . -47) (undo-tree-id3730 . -47) (undo-tree-id3731 . -47) (undo-tree-id3732 . -47) (undo-tree-id3733 . -47) (undo-tree-id3734 . -47) (undo-tree-id3735 . -47) (undo-tree-id3736 . -47) (undo-tree-id3737 . -47) (undo-tree-id3738 . -47) (undo-tree-id3739 . -47) (undo-tree-id3740 . -47) (undo-tree-id3741 . -47) (undo-tree-id3742 . -47) (undo-tree-id3743 . -47) (undo-tree-id3744 . -47) (undo-tree-id3745 . -47) (undo-tree-id3746 . -47) (undo-tree-id3747 . -47) (undo-tree-id3748 . -47) (undo-tree-id3749 . -47) (undo-tree-id3750 . -47) (undo-tree-id3751 . -47) (undo-tree-id3752 . -47) (undo-tree-id3753 . -47) (undo-tree-id3754 . -47) (undo-tree-id3755 . -115) (undo-tree-id3756 . -115) (undo-tree-id3757 . -115) (undo-tree-id3758 . -115) (undo-tree-id3759 . -115) (undo-tree-id3760 . -115) (undo-tree-id3761 . -115) (undo-tree-id3762 . -115) (undo-tree-id3763 . -115) (undo-tree-id3764 . -115) (undo-tree-id3765 . -115) (undo-tree-id3766 . -115) (undo-tree-id3767 . -115) (undo-tree-id3768 . -115) (undo-tree-id3769 . -115) (undo-tree-id3770 . -119) (undo-tree-id3771 . -119) (undo-tree-id3772 . -119) (undo-tree-id3773 . -119) (undo-tree-id3774 . -119) (undo-tree-id3775 . -119) (undo-tree-id3776 . -119) (undo-tree-id3777 . -119) (undo-tree-id3778 . -157) (undo-tree-id3779 . -157) (undo-tree-id3780 . -157) (undo-tree-id3781 . -157) (undo-tree-id3782 . -157) (undo-tree-id3783 . -157) (undo-tree-id3784 . -157) (undo-tree-id3785 . -157) (undo-tree-id3786 . -157) (undo-tree-id3787 . -157) (undo-tree-id3788 . -157) (undo-tree-id3789 . -157) (undo-tree-id3790 . -157) (undo-tree-id3791 . -157) (undo-tree-id3792 . -157) (undo-tree-id3793 . -225) (undo-tree-id3794 . -225) (undo-tree-id3795 . -225) (undo-tree-id3796 . -225) (undo-tree-id3797 . -225) (undo-tree-id3798 . -225) (undo-tree-id3799 . -225) (undo-tree-id3800 . -225) (undo-tree-id3801 . -225) (undo-tree-id3802 . -225) (undo-tree-id3803 . -225) (undo-tree-id3804 . -225) (undo-tree-id3805 . -225) (undo-tree-id3806 . -225) (undo-tree-id3807 . -225) (undo-tree-id3808 . -234) (undo-tree-id3809 . -234) (undo-tree-id3810 . -234) (undo-tree-id3811 . -234) (undo-tree-id3812 . -234) (undo-tree-id3813 . -234) (undo-tree-id3814 . -234) (undo-tree-id3815 . -234) (undo-tree-id3816 . -234) (undo-tree-id3817 . -234) (undo-tree-id3818 . -234) (undo-tree-id3819 . -234) (undo-tree-id3820 . -234) (undo-tree-id3821 . -234) (undo-tree-id3822 . -234) (undo-tree-id3823 . -234) (undo-tree-id3824 . -234) (undo-tree-id3825 . -234) (undo-tree-id3826 . -234) (undo-tree-id3827 . -234) (undo-tree-id3828 . -234) (undo-tree-id3829 . -234) (undo-tree-id3830 . -234) (undo-tree-id3831 . -234) (undo-tree-id3832 . -234) (undo-tree-id3833 . -234) (undo-tree-id3834 . -234) (undo-tree-id3835 . -234) (undo-tree-id3836 . -234) (undo-tree-id3837 . -302) (undo-tree-id3838 . -302) (undo-tree-id3839 . -302) (undo-tree-id3840 . -302) (undo-tree-id3841 . -302) (undo-tree-id3842 . -302) (undo-tree-id3843 . -302) (undo-tree-id3844 . -302) (undo-tree-id3845 . -302) (undo-tree-id3846 . -302) (undo-tree-id3847 . -302) (undo-tree-id3848 . -302) (undo-tree-id3849 . -302) (undo-tree-id3850 . -302) (undo-tree-id3851 . -302) (undo-tree-id3852 . -302) (undo-tree-id3853 . -302) (undo-tree-id3854 . -302) (undo-tree-id3855 . -302) (undo-tree-id3856 . -302) (undo-tree-id3857 . -302) (undo-tree-id3858 . -302) (undo-tree-id3859 . -302) (undo-tree-id3860 . -302) (undo-tree-id3861 . -302) (undo-tree-id3862 . -302) (undo-tree-id3863 . -302) (undo-tree-id3864 . -302) (undo-tree-id3865 . -302) (undo-tree-id3866 . -312) (undo-tree-id3867 . -312) (undo-tree-id3868 . -312) (undo-tree-id3869 . -312) (undo-tree-id3870 . -312) (undo-tree-id3871 . -312) (undo-tree-id3872 . -312) (undo-tree-id3873 . -312) (undo-tree-id3874 . -312) (undo-tree-id3875 . -312) (undo-tree-id3876 . -312) (undo-tree-id3877 . -312) (undo-tree-id3878 . -312) (undo-tree-id3879 . -312) (undo-tree-id3880 . -312) (undo-tree-id3881 . -312) (undo-tree-id3882 . -312) (undo-tree-id3883 . -312) (undo-tree-id3884 . -312) (undo-tree-id3885 . -312) (undo-tree-id3886 . -312) (undo-tree-id3887 . -312) (undo-tree-id3888 . -312) (undo-tree-id3889 . -312) (undo-tree-id3890 . -312) (undo-tree-id3891 . -312) (undo-tree-id3892 . -312) (undo-tree-id3893 . -312) (undo-tree-id3894 . -312) (undo-tree-id3895 . -380) (undo-tree-id3896 . -380) (undo-tree-id3897 . -380) (undo-tree-id3898 . -380) (undo-tree-id3899 . -380) (undo-tree-id3900 . -380) (undo-tree-id3901 . -380) (undo-tree-id3902 . -380) (undo-tree-id3903 . -380) (undo-tree-id3904 . -380) (undo-tree-id3905 . -380) (undo-tree-id3906 . -380) (undo-tree-id3907 . -380) (undo-tree-id3908 . -380) (undo-tree-id3909 . -380) (undo-tree-id3910 . -380) (undo-tree-id3911 . -380) (undo-tree-id3912 . -380) (undo-tree-id3913 . -380) (undo-tree-id3914 . -380) (undo-tree-id3915 . -380) (undo-tree-id3916 . -380) (undo-tree-id3917 . -380) (undo-tree-id3918 . -380) (undo-tree-id3919 . -380) (undo-tree-id3920 . -380) (undo-tree-id3921 . -380) (undo-tree-id3922 . -380) (undo-tree-id3923 . -380) (undo-tree-id3924 . -387) (undo-tree-id3925 . -387) (undo-tree-id3926 . -387) (undo-tree-id3927 . -387) (undo-tree-id3928 . -387) (undo-tree-id3929 . -387) (undo-tree-id3930 . -387) (undo-tree-id3931 . -387) (undo-tree-id3932 . -441) (undo-tree-id3933 . -441) (undo-tree-id3934 . -441) (undo-tree-id3935 . -441) (undo-tree-id3936 . -441) (undo-tree-id3937 . -441) (undo-tree-id3938 . -441) (undo-tree-id3939 . -441) (undo-tree-id3940 . -442) (undo-tree-id3941 . -442) (undo-tree-id3942 . -442) (undo-tree-id3943 . -442) (undo-tree-id3944 . -442) (undo-tree-id3945 . -442) (undo-tree-id3946 . -442) (undo-tree-id3947 . -442) (undo-tree-id3948 . -443) (undo-tree-id3949 . -443) (undo-tree-id3950 . -443) (undo-tree-id3951 . -443) (undo-tree-id3952 . -443) (undo-tree-id3953 . -443) (undo-tree-id3954 . -443) (undo-tree-id3955 . -443) (undo-tree-id3956 . -443) (undo-tree-id3957 . -443) (undo-tree-id3958 . -452) 824 (t 25760 29832 845555 840000)) nil (25760 29848 71923 886000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 381) (undo-tree-id3598 . 1) (undo-tree-id3599 . -1)) nil (25760 29848 71693 369000) 0 nil])
([nil nil ((1 . 41679) (#("#!/usr/bin/env python

import sklearn
import tensorflow as tf
from tensorflow import keras
import numpy as np
from pathlib import Path

# to make this notebook's output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rc(\"axes\", labelsize=14)
mpl.rc(\"xtick\", labelsize=12)
mpl.rc(\"ytick\", labelsize=12)



np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]


# In[4]:


X_train.shape, y_train.shape


# In[5]:


def plot_series(
    series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True
):
    plt.plot(series, \".-\")
    if y is not None:
        plt.plot(n_steps, y, \"bo\", label=\"Target\")
    if y_pred is not None:
        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=\"upper left\")


fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(
        X_valid[col, :, 0],
        y_valid[col, 0],
        y_label=(\"$x(t)$\" if col == 0 else None),
        legend=(col == 0),
    )
save_fig(\"time_series_plot\")
plt.show()


# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.

# ## Computing Some Baselines

# Naive predictions (just predict the last observed value):

# In[6]:


y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))


# In[7]:


plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Linear predictions:

# In[8]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(1)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[9]:


model.evaluate(X_valid, y_valid)


# In[10]:


def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(\"Epochs\")
    plt.ylabel(\"Loss\")
    plt.grid(True)


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[11]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Using a Simple RNN

# In[12]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1])])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=\"mse\", optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[13]:


model.evaluate(X_valid, y_valid)


# In[14]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[15]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Deep RNNs

# In[16]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.SimpleRNN(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[17]:


model.evaluate(X_valid, y_valid)


# In[18]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[19]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Make the second `SimpleRNN` layer return only the last output:

# In[20]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[21]:


model.evaluate(X_valid, y_valid)


# In[22]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[23]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Forecasting Several Steps Ahead

# In[24]:


np.random.seed(43)  # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]


# In[25]:


Y_pred.shape


# In[26]:


def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")
    plt.plot(
        np.arange(n_steps, n_steps + ahead),
        Y_pred[0, :, 0],
        \"rx-\",
        label=\"Forecast\",
        markersize=10,
    )
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)


plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(\"forecast_ahead_plot\")
plt.show()


# Now let's use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.

# In[27]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]


# Now let's predict the next 10 values one by one:

# In[28]:


X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]


# In[29]:


Y_pred.shape


# In[30]:


np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))


# Let's compare this performance with some baselines: naive predictions and a simple linear model:

# In[31]:


Y_naive_pred = np.tile(
    X_valid[:, -1], 10
)  # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))


# In[32]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(10)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Now let's create an RNN that predicts all 10 next values at once:

# In[33]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(10),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[34]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]


# In[35]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# Now let's create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.

# In[36]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead : step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]


# In[37]:


X_train.shape, Y_train.shape


# In[38]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)


def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])


model.compile(
    loss=\"mse\",
    optimizer=keras.optimizers.Adam(learning_rate=0.01),
    metrics=[last_time_step_mse],
)
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[39]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[40]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # Deep RNN with Batch Norm

# In[41]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.BatchNormalization(),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.BatchNormalization(),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Deep RNNs with Layer Norm

# In[42]:


from tensorflow.keras.layers import LayerNormalization


# In[43]:


class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]

    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]


# In[44]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.RNN(
            LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]
        ),
        keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Creating a Custom RNN Class

# In[45]:


class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, \"get_initial_state\", self.fallback_initial_state
        )

    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]

    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0)
        )
        outputs = tf.zeros(
            shape=[batch_size, self.cell.output_size], dtype=inputs.dtype
        )
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs


# In[46]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        MyRNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),
        MyRNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # LSTMs

# In[47]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.LSTM(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[48]:


model.evaluate(X_valid, Y_valid)


# In[49]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[50]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[51]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # GRUs

# In[52]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[53]:


model.evaluate(X_valid, Y_valid)


# In[54]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[55]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[56]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# ## Using One-Dimensional Convolutional Layers to Process Sequences

# ```
# 1D conv layer with kernel size 4, stride 2, VALID padding:
#
#               |-----2-----|     |-----5---...------|     |-----23----|
#         |-----1-----|     |-----4-----|   ...      |-----22----|
#   |-----0----|      |-----3-----|     |---...|-----21----|
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 42 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 43 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 52 53 54 55 56 57 58 59
#
# Output:
#
# X:     0/3   2/5   4/7   6/9   8/11 10/13 .../43 42/45 44/47 46/49
# Y:     4/13  6/15  8/17 10/19 12/21 14/23 .../53 46/55 48/57 50/59
# ```

# In[57]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.Conv1D(
            filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]
        ),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(
    X_train, Y_train[:, 3::2], epochs=20, validation_data=(X_valid, Y_valid[:, 3::2])
)


# ## WaveNet

# ```
# C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\.../\\ /\\ /\\ /\\ /\\ /\\
#    \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\       /  \\  /  \\  /  \\
#      /    \\      /    \\      /    \\                 /    \\
# C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /.../\\ /\\ /\\ /\\ /\\ /\\ /\\
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 53 54 55 56 57 58 59
# ```

# In[58]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(
        keras.layers.Conv1D(
            filters=20,
            kernel_size=2,
            padding=\"causal\",
            activation=\"relu\",
            dilation_rate=rate,
        )
    )
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:

# In[59]:


class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)

    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate


# In[60]:


def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(
        2 * n_filters, kernel_size=2, padding=\"causal\", dilation_rate=dilation_rate
    )(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z


# In[61]:


keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3  # 10 in the paper
n_blocks = 1  # 3 in the paper
n_filters = 32  # 128 in the paper
n_outputs = 10  # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)
skip_to_last = []
for dilation_rate in [2 ** i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])


# In[62]:


model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_valid, Y_valid))


# In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.

# # Exercise solutions

# ## 1. to 8.

# See Appendix A.

# ## 9. Tackling the SketchRNN Dataset

# _Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets._

# The dataset is not available in TFDS yet, the [pull request](https://github.com/tensorflow/datasets/pull/361) is still work in progress. Luckily, the data is conveniently available as TFRecords, so let's download it (it might take a while, as it's about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):

# In[63]:


DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"
FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"
filepath = keras.utils.get_file(
    FILENAME, DOWNLOAD_ROOT + FILENAME, cache_subdir=\"datasets/quickdraw\", extract=True
)


# In[64]:


quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])


# In[65]:


train_files


# In[66]:


eval_files


# In[67]:


with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:
    test_classes = test_classes_file.readlines()

with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:
    train_classes = train_classes_file.readlines()


# In[68]:


assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]


# In[69]:


sorted(class_names)


# In[70]:


def parse(data_batch):
    feature_descriptions = {
        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),
        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),
        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64),
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[\"shape\"][:, 0]
    labels = examples[\"class_index\"][:, 0]
    return sketches, lengths, labels


# In[71]:


def quickdraw_dataset(
    filepaths,
    batch_size=32,
    shuffle_buffer_size=None,
    n_parse_threads=5,
    n_read_threads=5,
    cache=False,
):
    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)


# In[72]:


train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])


# In[73]:


for sketches, lengths, labels in train_set.take(1):
    print(\"sketches =\", sketches)
    print(\"lengths =\", lengths)
    print(\"labels =\", labels)


# In[74]:


def draw_sketch(sketch, label=None):
    origin = np.array([[0.0, 0.0, 0.0]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1] == 1.0)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else \"Try to guess\"
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")
    plt.axis(\"off\")


def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(
        range(n_sketches), sketches, lengths, labels
    ):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()


for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)


# Most sketches are composed of less than 100 points:

# In[75]:


lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(\"length\")
plt.ylabel(\"density\")
plt.show()


# In[76]:


def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))


cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)


# In[77]:


model = keras.models.Sequential(
    [
        keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(128, return_sequences=True),
        keras.layers.LSTM(128),
        keras.layers.Dense(len(class_names), activation=\"softmax\"),
    ]
)
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.0)
model.compile(
    loss=\"sparse_categorical_crossentropy\",
    optimizer=optimizer,
    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],
)
history = model.fit(cropped_train_set, epochs=2, validation_data=cropped_valid_set)


# In[78]:


y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)


# In[79]:


np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))


# In[80]:


n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(\"Top-5 predictions:\".format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))
    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))


# In[81]:


model.save(\"my_sketchrnn\")


# ## 10. Bach Chorales
# _Exercise: Download the [Bach chorales](https://homl.info/bach) dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out [Google's Coconet model](https://homl.info/coconet), which was used for a nice [Google doodle about Bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)._
#
#

# In[82]:


DOWNLOAD_ROOT = (
    \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"
)
FILENAME = \"jsb_chorales.tgz\"
filepath = keras.utils.get_file(
    FILENAME,
    DOWNLOAD_ROOT + FILENAME,
    cache_subdir=\"datasets/jsb_chorales\",
    extract=True,
)


# In[83]:


jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))
valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))
test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))


# In[84]:


import pandas as pd


def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]


train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)


# In[85]:


train_chorales[0]


# Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:

# In[86]:


notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81


# Let's write a few functions to listen to these chorales (you don't need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):

# In[87]:


from IPython.display import Audio


def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440


def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo  # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 9.0).reshape(-1, 1)
    return sine_waves.reshape(-1)


def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]]  # make last note a bit longer
    merged = np.mean(
        [frequencies_to_samples(melody, tempo, sample_rate) for melody in freqs.T],
        axis=0,
    )
    n_fade_out_samples = sample_rate * 60 // tempo  # fade out last note
    fade_out = np.linspace(1.0, 0.0, n_fade_out_samples) ** 2
    merged[-n_fade_out_samples:] *= fade_out
    return merged


def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile

        samples = (2 ** 15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))


# Now let's listen to a few chorales:

# In[88]:


for index in range(3):
    play_chords(train_chorales[index])


# Divine! :)

# In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don't go very well together (believe me, I tried). It's much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.
#
# We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).
#
# And we will train the model on windows of 128 notes (i.e., 32 chords).
#
# Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).

# In[89]:


def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:]  # predict next note in each arpegio, at each step
    return X, Y


def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1)  # shift values
    return tf.reshape(window, [-1])  # convert to arpegio


def bach_dataset(
    chorales,
    batch_size=32,
    shuffle_buffer_size=None,
    window_size=32,
    window_shift=16,
    cache=True,
):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)


# Now let's create the training set, the validation set and the test set:

# In[90]:


train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)


# Now let's create the model:
#
# * We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C\\#3, it's very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an `Embedding` layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of `[batch_size, window_size, 5]`.
# * We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 `Conv1D` layers with doubling dilation rates. We will intersperse these layers with `BatchNormalization` layers for faster better convergence.
# * Then one `LSTM` layer to try to capture long-term patterns.
# * And finally a `Dense` layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be `[batch_size, window_size, 47]`.

# In[91]:


n_embedding_dims = 5

model = keras.models.Sequential(
    [
        keras.layers.Embedding(
            input_dim=n_notes, output_dim=n_embedding_dims, input_shape=[None]
        ),
        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8
        ),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(256, return_sequences=True),
        keras.layers.Dense(n_notes, activation=\"softmax\"),
    ]
)

model.summary()


# Now we're ready to compile and train the model!

# In[92]:


optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(
    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]
)
model.fit(train_set, epochs=20, validation_data=valid_set)


# I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the `LSTM` layer and replacing it with `Conv1D` layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.

# Once you're satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:

# In[93]:


model.save(\"my_bach_model.h5\")
model.evaluate(test_set)


# **Note:** There's no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.

# Now let's write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.

# **Warning**: `model.predict_classes(X)` is deprecated. It is replaced with `np.argmax(model.predict(X), axis=-1)`.

# In[94]:


def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            # next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# To test this function, we need some seed chords. Let's use the first 8 chords of one of the test chorales (it's actually just 2 different chords, each played 4 times):

# In[95]:


seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)


# Now we are ready to generate our first chorale! Let's ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):

# In[96]:


new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)


# This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.
#
# So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a `temperature` parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.

# In[97]:


def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# Let's generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!
#
# **Please share your most beautiful generated chorale with me on Twitter @aureliengeron, I would really appreciate it! :))**

# In[98]:


new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")


# In[99]:


new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")


# In[100]:


new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")


# Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!

# In[101]:


play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")
" 0 1 (fontified t face font-lock-comment-delimiter-face) 1 22 (fontified t face font-lock-comment-face) 22 23 (fontified t) 23 29 (fontified t face font-lock-keyword-face) 29 38 (fontified t) 38 44 (fontified t face font-lock-keyword-face) 44 56 (fontified t) 56 58 (fontified t face font-lock-keyword-face) 58 62 (fontified t) 62 66 (fontified t face font-lock-keyword-face) 66 78 (fontified t) 78 84 (fontified t face font-lock-keyword-face) 84 91 (fontified t) 91 97 (fontified t face font-lock-keyword-face) 97 104 (fontified t) 104 106 (fontified t face font-lock-keyword-face) 106 110 (fontified t) 110 114 (fontified t face font-lock-keyword-face) 114 123 (fontified t) 123 129 (fontified t face font-lock-keyword-face) 129 136 (fontified t) 136 138 (fontified t face font-lock-comment-delimiter-face) 138 188 (fontified t face font-lock-comment-face) 188 202 (fontified t) 202 203 (fontified t face (rainbow-delimiters-depth-1-face)) 203 205 (fontified t) 205 206 (fontified t face (rainbow-delimiters-depth-1-face)) 206 225 (fontified t) 225 226 (fontified t face (rainbow-delimiters-depth-1-face)) 226 228 (fontified t) 228 229 (fontified t face (rainbow-delimiters-depth-1-face)) 229 231 (fontified t) 231 237 (fontified t face font-lock-keyword-face) 237 249 (fontified t) 249 251 (fontified t face font-lock-keyword-face) 251 256 (fontified t) 256 262 (fontified t face font-lock-keyword-face) 262 281 (fontified t) 281 283 (fontified t face font-lock-keyword-face) 283 295 (fontified t) 295 296 (fontified t face (rainbow-delimiters-depth-1-face)) 296 302 (fontified t face font-lock-string-face) 302 316 (fontified t) 316 317 (fontified t face (rainbow-delimiters-depth-1-face)) 317 324 (fontified t) 324 325 (fontified t face (rainbow-delimiters-depth-1-face)) 325 332 (fontified t face font-lock-string-face) 332 346 (fontified t) 346 347 (fontified t face (rainbow-delimiters-depth-1-face)) 347 354 (fontified t) 354 355 (fontified t face (rainbow-delimiters-depth-1-face)) 355 362 (fontified t face font-lock-string-face) 362 376 (fontified t) 376 377 (fontified t face (rainbow-delimiters-depth-1-face)) 377 379 (fontified t) 379 380 (fontified t) 380 381 (fontified t) 381 387 (fontified t) 387 388 (fontified t) 388 395 (fontified t) 395 396 (fontified t face (rainbow-delimiters-depth-1-face)) 396 398 (fontified t) 398 399 (fontified t face (rainbow-delimiters-depth-1-face)) 399 400 (fontified t) 400 401 (fontified t) 401 408 (fontified t face font-lock-variable-name-face) 408 414 (fontified t) 414 415 (fontified t face font-lock-variable-name-face) 415 416 (fontified t face font-lock-variable-name-face) 416 420 (fontified t face font-lock-variable-name-face) 420 426 (fontified t) 426 427 (fontified t) 427 443 (fontified t) 443 444 (fontified t face (rainbow-delimiters-depth-1-face)) 444 462 (fontified t) 462 463 (fontified t face (rainbow-delimiters-depth-1-face)) 463 464 (fontified t) 464 471 (fontified t face font-lock-variable-name-face) 471 473 (fontified t) 473 480 (fontified t face font-lock-variable-name-face) 480 489 (fontified t) 489 490 (fontified t face (rainbow-delimiters-depth-1-face)) 490 505 (fontified t) 505 506 (fontified t face (rainbow-delimiters-depth-1-face)) 506 514 (fontified t) 514 515 (fontified t face (rainbow-delimiters-depth-1-face)) 515 524 (fontified t) 524 525 (fontified t face (rainbow-delimiters-depth-1-face)) 525 526 (fontified t) 526 533 (fontified t face font-lock-variable-name-face) 533 535 (fontified t) 535 542 (fontified t face font-lock-variable-name-face) 542 551 (fontified t) 551 552 (fontified t face (rainbow-delimiters-depth-1-face)) 552 571 (fontified t) 571 572 (fontified t face (rainbow-delimiters-depth-1-face)) 572 580 (fontified t) 580 581 (fontified t face (rainbow-delimiters-depth-1-face)) 581 594 (fontified t) 594 595 (fontified t face (rainbow-delimiters-depth-1-face)) 595 596 (fontified t) 596 602 (fontified t face font-lock-variable-name-face) 602 604 (fontified t) 604 610 (fontified t face font-lock-variable-name-face) 610 619 (fontified t) 619 620 (fontified t face (rainbow-delimiters-depth-1-face)) 620 635 (fontified t) 635 636 (fontified t face (rainbow-delimiters-depth-1-face)) 636 644 (fontified t) 644 645 (fontified t face (rainbow-delimiters-depth-1-face)) 645 654 (fontified t) 654 655 (fontified t face (rainbow-delimiters-depth-1-face)) 655 658 (fontified t) 658 660 (fontified t face font-lock-comment-delimiter-face) 660 667 (fontified t face font-lock-comment-face) 667 700 (fontified t) 700 702 (fontified t face font-lock-comment-delimiter-face) 702 709 (fontified t face font-lock-comment-face) 709 711 (fontified t) 711 714 (fontified t face font-lock-keyword-face) 714 715 (fontified t) 715 726 (fontified t face font-lock-function-name-face) 726 727 (fontified t face (rainbow-delimiters-depth-1-face)) 727 742 (fontified t) 742 746 (fontified t face font-lock-constant-face) 746 755 (fontified t) 755 759 (fontified t face font-lock-constant-face) 759 769 (fontified t) 769 774 (fontified t face font-lock-string-face) 774 784 (fontified t) 784 792 (fontified t face font-lock-string-face) 792 801 (fontified t) 801 805 (fontified t face font-lock-constant-face) 805 806 (fontified t) 806 807 (fontified t face (rainbow-delimiters-depth-1-face)) 807 821 (fontified t) 821 822 (fontified t face (rainbow-delimiters-depth-1-face)) 822 830 (fontified t) 830 834 (fontified t face font-lock-string-face) 834 835 (fontified t face (rainbow-delimiters-depth-1-face)) 835 840 (fontified t) 840 842 (fontified t face font-lock-keyword-face) 842 845 (fontified t) 845 847 (fontified t face font-lock-keyword-face) 847 848 (fontified t) 848 851 (fontified t face font-lock-keyword-face) 851 852 (fontified t) 852 856 (fontified t face font-lock-constant-face) 856 874 (fontified t) 874 875 (fontified t face (rainbow-delimiters-depth-1-face)) 875 879 (fontified t) 879 880 (fontified t) 880 881 (fontified t) 881 887 (fontified t) 887 891 (face font-lock-string-face fontified t) 891 899 (fontified t) 899 907 (face font-lock-string-face fontified t) 907 908 (face (rainbow-delimiters-depth-1-face) fontified t) 908 909 (fontified t)) . 1) (undo-tree-id2760 . -380) (undo-tree-id2761 . -380) (undo-tree-id2762 . -379) (undo-tree-id2763 . -379) (undo-tree-id2764 . -379) (undo-tree-id2765 . -379) (undo-tree-id2766 . -379) (undo-tree-id2767 . -379) (undo-tree-id2768 . -379) (undo-tree-id2769 . -379) (undo-tree-id2770 . -379) (undo-tree-id2771 . -379) (undo-tree-id2772 . -379) (undo-tree-id2773 . -379) (undo-tree-id2774 . -379) (undo-tree-id2775 . -379) (undo-tree-id2776 . -379) (undo-tree-id2777 . -379) (undo-tree-id2778 . -379) (undo-tree-id2779 . -379) (undo-tree-id2780 . -379) (undo-tree-id2781 . -379) (undo-tree-id2782 . -379) (undo-tree-id2783 . -379) (undo-tree-id2784 . -379) (undo-tree-id2785 . -379) (undo-tree-id2786 . -379) (undo-tree-id2787 . -379) (undo-tree-id2788 . -379) (undo-tree-id2789 . -379) (undo-tree-id2790 . -379) (undo-tree-id2791 . -379) (undo-tree-id2792 . -379) (undo-tree-id2793 . -379) (undo-tree-id2794 . -380) (undo-tree-id2795 . -380) (undo-tree-id2796 . -380) (undo-tree-id2797 . -380) (undo-tree-id2798 . -380) (undo-tree-id2799 . -380) (undo-tree-id2800 . -380) (undo-tree-id2801 . -23) (undo-tree-id2802 . -29) (undo-tree-id2803 . -231) (undo-tree-id2804 . -237) (undo-tree-id2805 . -256) (undo-tree-id2806 . -262) (undo-tree-id2807 . -380) (undo-tree-id2808 . -380) (undo-tree-id2809 . -1588) (undo-tree-id2810 . -1596) (undo-tree-id2811 . -1709) (undo-tree-id2812 . -1718) (undo-tree-id2813 . -2467) (undo-tree-id2814 . -2474) (undo-tree-id2815 . -2734) (undo-tree-id2816 . -2738) (undo-tree-id2817 . -3308) (undo-tree-id2818 . -3309) (undo-tree-id2819 . -3491) (undo-tree-id2820 . -3498) (undo-tree-id2821 . -3955) (undo-tree-id2822 . -3956) (undo-tree-id2823 . -4180) (undo-tree-id2824 . -4187) (undo-tree-id2825 . -4694) (undo-tree-id2826 . -4695) (undo-tree-id2827 . -4892) (undo-tree-id2828 . -4899) (undo-tree-id2829 . -5294) (undo-tree-id2830 . -5297) (undo-tree-id2831 . -5818) (undo-tree-id2832 . -5824) (undo-tree-id2833 . -6099) (undo-tree-id2834 . -6107) (undo-tree-id2835 . -6219) (undo-tree-id2836 . -6229) (undo-tree-id2837 . -6987) (undo-tree-id2838 . -6993) (undo-tree-id2839 . -7476) (undo-tree-id2840 . -7483) (undo-tree-id2841 . -7730) (undo-tree-id2842 . -7731) (undo-tree-id2843 . -7929) (undo-tree-id2844 . -7936) (undo-tree-id2845 . -8265) (undo-tree-id2846 . -8269) (undo-tree-id2847 . -8960) (undo-tree-id2848 . -8961) (undo-tree-id2849 . -9266) (undo-tree-id2850 . -9267) (undo-tree-id2851 . -9715) (undo-tree-id2852 . -9722) (undo-tree-id2853 . -10183) (undo-tree-id2854 . -10184) (undo-tree-id2855 . -10551) (undo-tree-id2856 . -10558) (undo-tree-id2857 . -10606) (undo-tree-id2858 . -10610) (undo-tree-id2859 . -10954) (undo-tree-id2860 . -10958) (undo-tree-id2861 . -12036) (undo-tree-id2862 . -12043) (undo-tree-id2863 . -12590) (undo-tree-id2864 . -12591) (undo-tree-id2865 . -13521) (undo-tree-id2866 . -13522) (undo-tree-id2867 . -13803) (undo-tree-id2868 . -13810) (undo-tree-id2869 . -14271) (undo-tree-id2870 . -14278) (undo-tree-id2871 . -15136) (undo-tree-id2872 . -15143) (undo-tree-id2873 . -16465) (undo-tree-id2874 . -16466) (undo-tree-id2875 . -16837) (undo-tree-id2876 . -16838) (undo-tree-id2877 . -17930) (undo-tree-id2878 . -17937) (undo-tree-id2879 . -18020) (undo-tree-id2880 . -18025) (undo-tree-id2881 . -18799) (undo-tree-id2882 . -18812) (undo-tree-id2883 . -19718) (undo-tree-id2884 . -19719) (undo-tree-id2885 . -19946) (undo-tree-id2886 . -19953) (undo-tree-id2887 . -20037) (undo-tree-id2888 . -20038) (undo-tree-id2889 . -20615) (undo-tree-id2890 . -20617) (undo-tree-id2891 . -20719) (undo-tree-id2892 . -20722) (undo-tree-id2893 . -21196) (undo-tree-id2894 . -21203) (undo-tree-id2895 . -21336) (undo-tree-id2896 . -21344) (undo-tree-id2897 . -21430) (undo-tree-id2898 . -21431) (undo-tree-id2899 . -22707) (undo-tree-id2900 . -22721) (undo-tree-id2901 . -24801) (undo-tree-id2902 . -24807) (undo-tree-id2903 . -25821) (undo-tree-id2904 . -25838) (undo-tree-id2905 . -26254) (undo-tree-id2906 . -26255) (undo-tree-id2907 . -26698) (undo-tree-id2908 . -26703) (undo-tree-id2909 . -28157) (undo-tree-id2910 . -28163) (undo-tree-id2911 . -28530) (undo-tree-id2912 . -28533) (undo-tree-id2913 . -28922) (undo-tree-id2914 . -28932) (undo-tree-id2915 . -29116) (undo-tree-id2916 . -29120) (undo-tree-id2917 . -30336) (undo-tree-id2918 . -30337) (undo-tree-id2919 . -30641) (undo-tree-id2920 . -30645) (undo-tree-id2921 . -30899) (undo-tree-id2922 . -30906) (undo-tree-id2923 . -30949) (undo-tree-id2924 . -30956) (undo-tree-id2925 . -31200) (undo-tree-id2926 . -31203) (undo-tree-id2927 . -32050) (undo-tree-id2928 . -32060) (undo-tree-id2929 . -32278) (undo-tree-id2930 . -32283) (undo-tree-id2931 . -32720) (undo-tree-id2932 . -32726) (undo-tree-id2933 . -33174) (undo-tree-id2934 . -33178) (undo-tree-id2935 . -33994) (undo-tree-id2936 . -33999) (undo-tree-id2937 . -34724) (undo-tree-id2938 . -34732) (undo-tree-id2939 . -35032) (undo-tree-id2940 . -35036) (undo-tree-id2941 . -35494) (undo-tree-id2942 . -35498) (undo-tree-id2943 . -35642) (undo-tree-id2944 . -35655) (undo-tree-id2945 . -35809) (undo-tree-id2946 . -35822) (undo-tree-id2947 . -35976) (undo-tree-id2948 . -35989) (undo-tree-id2949 . -36395) (undo-tree-id2950 . -36403) (undo-tree-id2951 . -36547) (undo-tree-id2952 . -36552) (undo-tree-id2953 . -36845) (undo-tree-id2954 . -36846) (undo-tree-id2955 . -37060) (undo-tree-id2956 . -37061) (undo-tree-id2957 . -37353) (undo-tree-id2958 . -37354) (undo-tree-id2959 . -37691) (undo-tree-id2960 . -37693) (undo-tree-id2961 . -38366) (undo-tree-id2962 . -38367) (undo-tree-id2963 . -38623) (undo-tree-id2964 . -38631) (undo-tree-id2965 . -38913) (undo-tree-id2966 . -38918) (undo-tree-id2967 . -39339) (undo-tree-id2968 . -39346) (undo-tree-id2969 . -40618) (undo-tree-id2970 . -40621) (undo-tree-id2971 . -40898) (undo-tree-id2972 . -40911) (undo-tree-id2973 . -41041) (undo-tree-id2974 . -41042) (undo-tree-id2975 . -41197) (undo-tree-id2976 . -41198) (undo-tree-id2977 . -41360) (undo-tree-id2978 . -41361) (undo-tree-id2979 . -41501) (undo-tree-id2980 . -41509) (undo-tree-id2981 . -380) (undo-tree-id2982 . -380) (undo-tree-id2983 . -380) (undo-tree-id2984 . -380) (undo-tree-id2985 . -380) (undo-tree-id2986 . -380) (undo-tree-id2987 . -380) (undo-tree-id2988 . -380) (undo-tree-id2989 . -380) (undo-tree-id2990 . -380) (undo-tree-id2991 . -380) (undo-tree-id2992 . -380) (undo-tree-id2993 . -380) (undo-tree-id2994 . -380) (undo-tree-id2995 . -380) (undo-tree-id2996 . -380) (undo-tree-id2997 . -380) (undo-tree-id2998 . -380) (undo-tree-id2999 . -380) (undo-tree-id3000 . -380) (undo-tree-id3001 . -380) (undo-tree-id3002 . -380) (undo-tree-id3003 . -380) (undo-tree-id3004 . -380) (undo-tree-id3005 . -380) (undo-tree-id3006 . -380) (undo-tree-id3007 . -380) (undo-tree-id3008 . -380) (undo-tree-id3009 . -380) (undo-tree-id3010 . -380) (undo-tree-id3011 . -380) (undo-tree-id3012 . -380) (undo-tree-id3013 . -380) (undo-tree-id3014 . -380) (undo-tree-id3015 . -380) (undo-tree-id3016 . -380) (undo-tree-id3017 . -380) (undo-tree-id3018 . -380) (undo-tree-id3019 . -380) (undo-tree-id3020 . -380) (undo-tree-id3021 . -380) (undo-tree-id3022 . -380) (undo-tree-id3023 . -380) (undo-tree-id3024 . -380) (undo-tree-id3025 . -380) (undo-tree-id3026 . -380) (undo-tree-id3027 . -380) (undo-tree-id3028 . -380) (undo-tree-id3029 . -380) (undo-tree-id3030 . -380) (undo-tree-id3031 . -380) (undo-tree-id3032 . -380) (undo-tree-id3033 . -380) (undo-tree-id3034 . -380) (undo-tree-id3035 . -380) (undo-tree-id3036 . -380) (undo-tree-id3037 . -380) (undo-tree-id3038 . -380) (undo-tree-id3039 . -380) (undo-tree-id3040 . -380) (undo-tree-id3041 . -380) (undo-tree-id3042 . -380) (undo-tree-id3043 . -380) (undo-tree-id3044 . -380) (undo-tree-id3045 . -380) (undo-tree-id3046 . -380) (undo-tree-id3047 . -380) (undo-tree-id3048 . -380) (undo-tree-id3049 . -380) (undo-tree-id3050 . -380) (undo-tree-id3051 . -380) (undo-tree-id3052 . -380) (undo-tree-id3053 . -380) (undo-tree-id3054 . -380) (undo-tree-id3055 . -380) (undo-tree-id3056 . -380) (undo-tree-id3057 . -380) (undo-tree-id3058 . -380) (undo-tree-id3059 . -380) (undo-tree-id3060 . -380) (undo-tree-id3061 . -380) (undo-tree-id3062 . -380) (undo-tree-id3063 . -380) (undo-tree-id3064 . -380) (undo-tree-id3065 . -380) (undo-tree-id3066 . -380) (undo-tree-id3067 . -380) (undo-tree-id3068 . -380) (undo-tree-id3069 . -380) (undo-tree-id3070 . -380) (undo-tree-id3071 . -380) (undo-tree-id3072 . -380) (undo-tree-id3073 . -380) (undo-tree-id3074 . -380) (undo-tree-id3075 . -380) (undo-tree-id3076 . -380) (undo-tree-id3077 . -380) (undo-tree-id3078 . -380) (undo-tree-id3079 . -380) (undo-tree-id3080 . -380) (undo-tree-id3081 . -380) (undo-tree-id3082 . -380) (undo-tree-id3083 . -380) (undo-tree-id3084 . -380) (undo-tree-id3085 . -380) (undo-tree-id3086 . -380) (undo-tree-id3087 . -380) (undo-tree-id3088 . -380) (undo-tree-id3089 . -380) (undo-tree-id3090 . -380) (undo-tree-id3091 . -380) (undo-tree-id3092 . -380) (undo-tree-id3093 . -380) (undo-tree-id3094 . -380) (undo-tree-id3095 . -380) (undo-tree-id3096 . -380) (undo-tree-id3097 . -380) (undo-tree-id3098 . -380) (undo-tree-id3099 . -380) (undo-tree-id3100 . -380) (undo-tree-id3101 . -380) (undo-tree-id3102 . -380) (undo-tree-id3103 . -380) (undo-tree-id3104 . -380) (undo-tree-id3105 . -380) (undo-tree-id3106 . -380) (undo-tree-id3107 . -380) (undo-tree-id3108 . -380) (undo-tree-id3109 . -380) (undo-tree-id3110 . -380) (undo-tree-id3111 . -380) (undo-tree-id3112 . -380) (undo-tree-id3113 . -380) (undo-tree-id3114 . -380) (undo-tree-id3115 . -380) (undo-tree-id3116 . -380) (undo-tree-id3117 . -380) (undo-tree-id3118 . -380) (undo-tree-id3119 . -380) (undo-tree-id3120 . -380) (undo-tree-id3121 . -380) (undo-tree-id3122 . -380) (undo-tree-id3123 . -380) (undo-tree-id3124 . -380) (undo-tree-id3125 . -379) (undo-tree-id3126 . -379) (undo-tree-id3127 . -379) (undo-tree-id3128 . -379) (undo-tree-id3129 . -379) (undo-tree-id3130 . -379) (undo-tree-id3131 . -379) (undo-tree-id3132 . -379) (undo-tree-id3133 . -379) (undo-tree-id3134 . -379) (undo-tree-id3135 . -379) (undo-tree-id3136 . -379) (undo-tree-id3137 . -379) (undo-tree-id3138 . -379) (undo-tree-id3139 . -379) (undo-tree-id3140 . -380) (undo-tree-id3141 . -380) (undo-tree-id3142 . -380) (undo-tree-id3143 . -380) (undo-tree-id3144 . -380) (undo-tree-id3145 . -380) (undo-tree-id3146 . -380) (undo-tree-id3147 . -380) (undo-tree-id3148 . -380) (undo-tree-id3149 . -380) (undo-tree-id3150 . -380) (undo-tree-id3151 . -380) (undo-tree-id3152 . -380) (undo-tree-id3153 . -380) (undo-tree-id3154 . -380) (undo-tree-id3155 . -380) (undo-tree-id3156 . -380) (undo-tree-id3157 . -380) (undo-tree-id3158 . -380) (undo-tree-id3159 . -380) (undo-tree-id3160 . -380) (undo-tree-id3161 . -380) (undo-tree-id3162 . -380) (undo-tree-id3163 . -380) (undo-tree-id3164 . -380) (undo-tree-id3165 . -380) (undo-tree-id3166 . -380) (undo-tree-id3167 . -380) (undo-tree-id3168 . -380) (undo-tree-id3169 . -380) (undo-tree-id3170 . -380) (undo-tree-id3171 . -380) (undo-tree-id3172 . -380) (undo-tree-id3173 . -380) (undo-tree-id3174 . -380) (undo-tree-id3175 . -380) (undo-tree-id3176 . -380) (undo-tree-id3177 . -380) (undo-tree-id3178 . 41299) (undo-tree-id3179 . -380) (undo-tree-id3180 . -380) (undo-tree-id3181 . -380) (undo-tree-id3182 . -380) (undo-tree-id3183 . -380) (undo-tree-id3184 . -380) (undo-tree-id3185 . -380) (undo-tree-id3186 . -380) (undo-tree-id3187 . -380) (undo-tree-id3188 . -380) (undo-tree-id3189 . -380) (undo-tree-id3190 . -380) (undo-tree-id3191 . -380) (undo-tree-id3192 . -380) (undo-tree-id3193 . -380) (undo-tree-id3194 . -380) (undo-tree-id3195 . -380) (undo-tree-id3196 . -380) (undo-tree-id3197 . -380) (undo-tree-id3198 . -380) (undo-tree-id3199 . -380) (undo-tree-id3200 . -380) (undo-tree-id3201 . -380) (undo-tree-id3202 . -380) (undo-tree-id3203 . -380) (undo-tree-id3204 . -380) (undo-tree-id3205 . -380) (undo-tree-id3206 . -380) (undo-tree-id3207 . -380) (undo-tree-id3208 . -380) (undo-tree-id3209 . -380) (undo-tree-id3210 . -380) (undo-tree-id3211 . -380) (undo-tree-id3212 . -380) (undo-tree-id3213 . -380) (undo-tree-id3214 . -380) (undo-tree-id3215 . -380) (undo-tree-id3216 . -380) (undo-tree-id3217 . -380) (undo-tree-id3218 . -380) (undo-tree-id3219 . -380) (undo-tree-id3220 . -380) (undo-tree-id3221 . -380) (undo-tree-id3222 . -380) (undo-tree-id3223 . -380) (undo-tree-id3224 . -380) (undo-tree-id3225 . -380) (undo-tree-id3226 . -380) (undo-tree-id3227 . -380) (undo-tree-id3228 . -380) (undo-tree-id3229 . -380) (undo-tree-id3230 . -380) (undo-tree-id3231 . -380) (undo-tree-id3232 . -380) (undo-tree-id3233 . -380) (undo-tree-id3234 . -380) (undo-tree-id3235 . -380) (undo-tree-id3236 . -380) (undo-tree-id3237 . -380) (undo-tree-id3238 . -380) (undo-tree-id3239 . -380) (undo-tree-id3240 . -380) (undo-tree-id3241 . -380) (undo-tree-id3242 . -380) (undo-tree-id3243 . -380) (undo-tree-id3244 . -380) (undo-tree-id3245 . -380) (undo-tree-id3246 . -380) (undo-tree-id3247 . -380) (undo-tree-id3248 . -380) (undo-tree-id3249 . -380) (undo-tree-id3250 . -380) (undo-tree-id3251 . -380) (undo-tree-id3252 . -380) (undo-tree-id3253 . -380) (undo-tree-id3254 . -380) (undo-tree-id3255 . -380) (undo-tree-id3256 . -380) (undo-tree-id3257 . -380) (undo-tree-id3258 . -380) (undo-tree-id3259 . -380) (undo-tree-id3260 . -380) (undo-tree-id3261 . -380) (undo-tree-id3262 . -380) (undo-tree-id3263 . -380) (undo-tree-id3264 . -380) (undo-tree-id3265 . -380) (undo-tree-id3266 . -380) (undo-tree-id3267 . -380) (undo-tree-id3268 . -380) (undo-tree-id3269 . -380) (undo-tree-id3270 . -380) (undo-tree-id3271 . -380) (undo-tree-id3272 . -380) (undo-tree-id3273 . -380) (undo-tree-id3274 . -380) (undo-tree-id3275 . -380) (undo-tree-id3276 . -380) (undo-tree-id3277 . -380) (undo-tree-id3278 . -380) (undo-tree-id3279 . -380) (undo-tree-id3280 . -380) (undo-tree-id3281 . -380) (undo-tree-id3282 . -380) (undo-tree-id3283 . -380) (undo-tree-id3284 . -380) (undo-tree-id3285 . -380) (undo-tree-id3286 . -380) (undo-tree-id3287 . -380) (undo-tree-id3288 . -380) (undo-tree-id3289 . -380) (undo-tree-id3290 . -380) (undo-tree-id3291 . -380) (undo-tree-id3292 . -380) (undo-tree-id3293 . -380) (undo-tree-id3294 . -380) (undo-tree-id3295 . -380) (undo-tree-id3296 . -380) (undo-tree-id3297 . -380) (undo-tree-id3298 . -380) (undo-tree-id3299 . -380) (undo-tree-id3300 . -380) (undo-tree-id3301 . -380) (undo-tree-id3302 . -380) (undo-tree-id3303 . -380) (undo-tree-id3304 . -380) (undo-tree-id3305 . -380) (undo-tree-id3306 . -380) (undo-tree-id3307 . -380) (undo-tree-id3308 . -380) (undo-tree-id3309 . -380) (undo-tree-id3310 . -380) (undo-tree-id3311 . -380) (undo-tree-id3312 . -380) (undo-tree-id3313 . -380) (undo-tree-id3314 . -380) (undo-tree-id3315 . -380) (undo-tree-id3316 . -380) (undo-tree-id3317 . -380) (undo-tree-id3318 . -380) (undo-tree-id3319 . -380) (undo-tree-id3320 . -380) (undo-tree-id3321 . -380) (undo-tree-id3322 . -380) (undo-tree-id3323 . -380) (undo-tree-id3324 . -380) (undo-tree-id3325 . -380) (undo-tree-id3326 . -380) (undo-tree-id3327 . -380) (undo-tree-id3328 . -380) (undo-tree-id3329 . -380) (undo-tree-id3330 . -380) (undo-tree-id3331 . -380) (undo-tree-id3332 . -380) (undo-tree-id3333 . -380) (undo-tree-id3334 . -380) (undo-tree-id3335 . -380) (undo-tree-id3336 . -380) (undo-tree-id3337 . -380) (undo-tree-id3338 . -380) (undo-tree-id3339 . -380) (undo-tree-id3340 . -380) (undo-tree-id3341 . -380) (undo-tree-id3342 . -380) (undo-tree-id3343 . -380) (undo-tree-id3344 . -380) (undo-tree-id3345 . -380) (undo-tree-id3346 . -380) (undo-tree-id3347 . -380) (undo-tree-id3348 . -380) (undo-tree-id3349 . -380) (undo-tree-id3350 . -380) (undo-tree-id3351 . -380) (undo-tree-id3352 . -380) (undo-tree-id3353 . -380) (undo-tree-id3354 . -380) (undo-tree-id3355 . -380) (undo-tree-id3356 . -380) (undo-tree-id3357 . -380) (undo-tree-id3358 . -380) (undo-tree-id3359 . -380) (undo-tree-id3360 . -380) (undo-tree-id3361 . -380) (undo-tree-id3362 . -380) (undo-tree-id3363 . -380) (undo-tree-id3364 . -380) (undo-tree-id3365 . -380) (undo-tree-id3366 . -380) (undo-tree-id3367 . -380) (undo-tree-id3368 . -380) (undo-tree-id3369 . -380) (undo-tree-id3370 . -380) (undo-tree-id3371 . -380) (undo-tree-id3372 . -380) (undo-tree-id3373 . -380) (undo-tree-id3374 . -380) (undo-tree-id3375 . -380) (undo-tree-id3376 . -380) (undo-tree-id3377 . -380) (undo-tree-id3378 . -380) (undo-tree-id3379 . -380) (undo-tree-id3380 . -380) (undo-tree-id3381 . -380) (undo-tree-id3382 . -380) (undo-tree-id3383 . -380) (undo-tree-id3384 . -380) (undo-tree-id3385 . -380) (undo-tree-id3386 . -380) (undo-tree-id3387 . -380) (undo-tree-id3388 . -380) (undo-tree-id3389 . -380) (undo-tree-id3390 . -380) (undo-tree-id3391 . -380) (undo-tree-id3392 . -380) (undo-tree-id3393 . -380) (undo-tree-id3394 . -380) (undo-tree-id3395 . -380) (undo-tree-id3396 . -380) (undo-tree-id3397 . -380) (undo-tree-id3398 . -380) (undo-tree-id3399 . -380) (undo-tree-id3400 . -380) (undo-tree-id3401 . -380) (undo-tree-id3402 . -380) (undo-tree-id3403 . -380) (undo-tree-id3404 . -380) (undo-tree-id3405 . -380) (undo-tree-id3406 . -380) (undo-tree-id3407 . -380) (undo-tree-id3408 . -380) (undo-tree-id3409 . -380) (undo-tree-id3410 . -380) (undo-tree-id3411 . -380) (undo-tree-id3412 . -380) (undo-tree-id3413 . -380) (undo-tree-id3414 . -380) (undo-tree-id3415 . -380) (undo-tree-id3416 . -380) (undo-tree-id3417 . -380) (undo-tree-id3418 . -380) (undo-tree-id3419 . -380) (undo-tree-id3420 . -380) (undo-tree-id3421 . -380) (undo-tree-id3422 . -380) (undo-tree-id3423 . -380) (undo-tree-id3424 . -380) (undo-tree-id3425 . -380) (undo-tree-id3426 . -380) (undo-tree-id3427 . -380) (undo-tree-id3428 . -380) (undo-tree-id3429 . -380) (undo-tree-id3430 . -380) (undo-tree-id3431 . -380) (undo-tree-id3432 . -380) (undo-tree-id3433 . -380) (undo-tree-id3434 . -380) (undo-tree-id3435 . -380) (undo-tree-id3436 . -380) (undo-tree-id3437 . -380) (undo-tree-id3438 . -380) (undo-tree-id3439 . -380) (undo-tree-id3440 . -380) (undo-tree-id3441 . -380) (undo-tree-id3442 . -380) (undo-tree-id3443 . -380) (undo-tree-id3444 . -380) (undo-tree-id3445 . -380) (undo-tree-id3446 . -380) (undo-tree-id3447 . -380) (undo-tree-id3448 . -380) (undo-tree-id3449 . -380) (undo-tree-id3450 . -380) (undo-tree-id3451 . -380) (undo-tree-id3452 . -380) (undo-tree-id3453 . -380) (undo-tree-id3454 . -380) (undo-tree-id3455 . -380) (undo-tree-id3456 . -380) (undo-tree-id3457 . -380) (undo-tree-id3458 . -380) (undo-tree-id3459 . -380) (undo-tree-id3460 . -380) (undo-tree-id3461 . -380) (undo-tree-id3462 . -380) (undo-tree-id3463 . -380) (undo-tree-id3464 . -380) (undo-tree-id3465 . -380) (undo-tree-id3466 . -380) (undo-tree-id3467 . -380) (undo-tree-id3468 . -380) (undo-tree-id3469 . -380) (undo-tree-id3470 . -380) (undo-tree-id3471 . -711) (undo-tree-id3472 . -711) (undo-tree-id3473 . -711) (undo-tree-id3474 . -711) (undo-tree-id3475 . -711) (undo-tree-id3476 . -711) (undo-tree-id3477 . -813) (undo-tree-id3478 . -813) (undo-tree-id3479 . -866) (undo-tree-id3480 . -866) (undo-tree-id3481 . -866) (undo-tree-id3482 . -866) (undo-tree-id3483 . -380) (undo-tree-id3484 . -380) (undo-tree-id3485 . -380) (undo-tree-id3486 . -380) (undo-tree-id3487 . -380) (undo-tree-id3488 . -380) (undo-tree-id3489 . -380) (undo-tree-id3490 . -380) (undo-tree-id3491 . -380) (undo-tree-id3492 . -379) (undo-tree-id3493 . -379) (undo-tree-id3494 . -380) (undo-tree-id3495 . -380) (undo-tree-id3496 . -380) (undo-tree-id3497 . -380) (undo-tree-id3498 . -380) (undo-tree-id3499 . -380) (undo-tree-id3500 . -380) (undo-tree-id3501 . -380) (undo-tree-id3502 . -711) (undo-tree-id3503 . -711) (undo-tree-id3504 . -711) (undo-tree-id3505 . -711) (undo-tree-id3506 . -711) (undo-tree-id3507 . -711) (undo-tree-id3508 . -813) (undo-tree-id3509 . -813) (undo-tree-id3510 . -866) (undo-tree-id3511 . -866) (undo-tree-id3512 . -866) (undo-tree-id3513 . -866) (undo-tree-id3514 . -380) (undo-tree-id3515 . -380) (undo-tree-id3516 . -380) (undo-tree-id3517 . -380) (undo-tree-id3518 . -380) (undo-tree-id3519 . -380) (undo-tree-id3520 . -380) (undo-tree-id3521 . -380) (undo-tree-id3522 . -380) (undo-tree-id3523 . -380) (undo-tree-id3524 . -380) (undo-tree-id3525 . -380) (undo-tree-id3526 . -380) (undo-tree-id3527 . -380) (undo-tree-id3528 . -380) (undo-tree-id3529 . -380) (undo-tree-id3530 . -380) (undo-tree-id3531 . -380) (undo-tree-id3532 . -380) (undo-tree-id3533 . -380) (undo-tree-id3534 . -380) (undo-tree-id3535 . -380) (undo-tree-id3536 . -380) (undo-tree-id3537 . -380) (undo-tree-id3538 . -380) (undo-tree-id3539 . -380) (undo-tree-id3540 . -380) (undo-tree-id3541 . -380) (undo-tree-id3542 . -380) (undo-tree-id3543 . -380) (undo-tree-id3544 . -380) (undo-tree-id3545 . -380) (undo-tree-id3546 . -380) (undo-tree-id3547 . -380) (undo-tree-id3548 . -380) (undo-tree-id3549 . -380) (undo-tree-id3550 . -380) (undo-tree-id3551 . -380) (undo-tree-id3552 . -711) (undo-tree-id3553 . -711) (undo-tree-id3554 . -711) (undo-tree-id3555 . -711) (undo-tree-id3556 . -711) (undo-tree-id3557 . -711) (undo-tree-id3558 . -813) (undo-tree-id3559 . -813) (undo-tree-id3560 . -866) (undo-tree-id3561 . -866) (undo-tree-id3562 . -866) (undo-tree-id3563 . -866) (undo-tree-id3564 . -380) (undo-tree-id3565 . -380) (undo-tree-id3566 . -380) (undo-tree-id3567 . -380) (undo-tree-id3568 . -380) (undo-tree-id3569 . -380) (undo-tree-id3570 . -380) (undo-tree-id3571 . -380) (undo-tree-id3572 . -380) (undo-tree-id3573 . -380) (undo-tree-id3574 . -380) (undo-tree-id3575 . -380) (undo-tree-id3576 . -380) (undo-tree-id3577 . -380) (undo-tree-id3578 . -380) (undo-tree-id3579 . -380) (undo-tree-id3580 . -380) (undo-tree-id3581 . -380) (undo-tree-id3582 . -380) (undo-tree-id3583 . -380) (undo-tree-id3584 . -380) (undo-tree-id3585 . -380) (undo-tree-id3586 . -380) (undo-tree-id3587 . -380) (undo-tree-id3588 . -380) (undo-tree-id3589 . -380) (undo-tree-id3590 . -380) (undo-tree-id3591 . -380) (undo-tree-id3592 . -380) (undo-tree-id3593 . -380) (undo-tree-id3594 . -380) (undo-tree-id3595 . -380) (undo-tree-id3596 . -380) (undo-tree-id3597 . -380)) nil (25760 29848 71651 212000) 0 nil])
([nil nil ((#("np.random.seed(42)
" 0 14 (fontified t) 14 15 (fontified t face (rainbow-delimiters-depth-1-face)) 15 17 (fontified t) 17 18 (fontified t face (rainbow-delimiters-depth-1-face)) 18 19 (fontified t)) . 381) (undo-tree-id4284 . -18) (undo-tree-id4285 . -2) (undo-tree-id4286 . -19) (t 25760 29848 130333 591000)) nil (25760 29853 200104 418000) 0 nil])
([nil nil ((1 . 41659) (#("#!/usr/bin/env python

import sklearn
import tensorflow as tf
from tensorflow import keras
import numpy as np
from pathlib import Path

# to make this notebook's output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rc(\"axes\", labelsize=14)
mpl.rc(\"xtick\", labelsize=12)
mpl.rc(\"ytick\", labelsize=12)



n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]


# In[4]:


X_train.shape, y_train.shape


# In[5]:


def plot_series(
    series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True
):
    plt.plot(series, \".-\")
    if y is not None:
        plt.plot(n_steps, y, \"bo\", label=\"Target\")
    if y_pred is not None:
        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=\"upper left\")


fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(
        X_valid[col, :, 0],
        y_valid[col, 0],
        y_label=(\"$x(t)$\" if col == 0 else None),
        legend=(col == 0),
    )
save_fig(\"time_series_plot\")
plt.show()


# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.

# ## Computing Some Baselines

# Naive predictions (just predict the last observed value):

# In[6]:


y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))


# In[7]:


plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Linear predictions:

# In[8]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(1)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[9]:


model.evaluate(X_valid, y_valid)


# In[10]:


def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(\"Epochs\")
    plt.ylabel(\"Loss\")
    plt.grid(True)


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[11]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Using a Simple RNN

# In[12]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1])])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=\"mse\", optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[13]:


model.evaluate(X_valid, y_valid)


# In[14]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[15]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Deep RNNs

# In[16]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.SimpleRNN(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[17]:


model.evaluate(X_valid, y_valid)


# In[18]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[19]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Make the second `SimpleRNN` layer return only the last output:

# In[20]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[21]:


model.evaluate(X_valid, y_valid)


# In[22]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[23]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Forecasting Several Steps Ahead

# In[24]:


np.random.seed(43)  # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]


# In[25]:


Y_pred.shape


# In[26]:


def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")
    plt.plot(
        np.arange(n_steps, n_steps + ahead),
        Y_pred[0, :, 0],
        \"rx-\",
        label=\"Forecast\",
        markersize=10,
    )
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)


plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(\"forecast_ahead_plot\")
plt.show()


# Now let's use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.

# In[27]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]


# Now let's predict the next 10 values one by one:

# In[28]:


X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]


# In[29]:


Y_pred.shape


# In[30]:


np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))


# Let's compare this performance with some baselines: naive predictions and a simple linear model:

# In[31]:


Y_naive_pred = np.tile(
    X_valid[:, -1], 10
)  # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))


# In[32]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(10)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Now let's create an RNN that predicts all 10 next values at once:

# In[33]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(10),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[34]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]


# In[35]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# Now let's create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.

# In[36]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead : step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]


# In[37]:


X_train.shape, Y_train.shape


# In[38]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)


def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])


model.compile(
    loss=\"mse\",
    optimizer=keras.optimizers.Adam(learning_rate=0.01),
    metrics=[last_time_step_mse],
)
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[39]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[40]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # Deep RNN with Batch Norm

# In[41]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.BatchNormalization(),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.BatchNormalization(),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Deep RNNs with Layer Norm

# In[42]:


from tensorflow.keras.layers import LayerNormalization


# In[43]:


class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]

    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]


# In[44]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.RNN(
            LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]
        ),
        keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Creating a Custom RNN Class

# In[45]:


class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, \"get_initial_state\", self.fallback_initial_state
        )

    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]

    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0)
        )
        outputs = tf.zeros(
            shape=[batch_size, self.cell.output_size], dtype=inputs.dtype
        )
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs


# In[46]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        MyRNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),
        MyRNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # LSTMs

# In[47]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.LSTM(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[48]:


model.evaluate(X_valid, Y_valid)


# In[49]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[50]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[51]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # GRUs

# In[52]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[53]:


model.evaluate(X_valid, Y_valid)


# In[54]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[55]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[56]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# ## Using One-Dimensional Convolutional Layers to Process Sequences

# ```
# 1D conv layer with kernel size 4, stride 2, VALID padding:
#
#               |-----2-----|     |-----5---...------|     |-----23----|
#         |-----1-----|     |-----4-----|   ...      |-----22----|
#   |-----0----|      |-----3-----|     |---...|-----21----|
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 42 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 43 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 52 53 54 55 56 57 58 59
#
# Output:
#
# X:     0/3   2/5   4/7   6/9   8/11 10/13 .../43 42/45 44/47 46/49
# Y:     4/13  6/15  8/17 10/19 12/21 14/23 .../53 46/55 48/57 50/59
# ```

# In[57]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.Conv1D(
            filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]
        ),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(
    X_train, Y_train[:, 3::2], epochs=20, validation_data=(X_valid, Y_valid[:, 3::2])
)


# ## WaveNet

# ```
# C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\.../\\ /\\ /\\ /\\ /\\ /\\
#    \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\       /  \\  /  \\  /  \\
#      /    \\      /    \\      /    \\                 /    \\
# C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /.../\\ /\\ /\\ /\\ /\\ /\\ /\\
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 53 54 55 56 57 58 59
# ```

# In[58]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(
        keras.layers.Conv1D(
            filters=20,
            kernel_size=2,
            padding=\"causal\",
            activation=\"relu\",
            dilation_rate=rate,
        )
    )
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:

# In[59]:


class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)

    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate


# In[60]:


def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(
        2 * n_filters, kernel_size=2, padding=\"causal\", dilation_rate=dilation_rate
    )(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z


# In[61]:


keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3  # 10 in the paper
n_blocks = 1  # 3 in the paper
n_filters = 32  # 128 in the paper
n_outputs = 10  # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)
skip_to_last = []
for dilation_rate in [2 ** i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])


# In[62]:


model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_valid, Y_valid))


# In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.

# # Exercise solutions

# ## 1. to 8.

# See Appendix A.

# ## 9. Tackling the SketchRNN Dataset

# _Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets._

# The dataset is not available in TFDS yet, the [pull request](https://github.com/tensorflow/datasets/pull/361) is still work in progress. Luckily, the data is conveniently available as TFRecords, so let's download it (it might take a while, as it's about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):

# In[63]:


DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"
FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"
filepath = keras.utils.get_file(
    FILENAME, DOWNLOAD_ROOT + FILENAME, cache_subdir=\"datasets/quickdraw\", extract=True
)


# In[64]:


quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])


# In[65]:


train_files


# In[66]:


eval_files


# In[67]:


with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:
    test_classes = test_classes_file.readlines()

with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:
    train_classes = train_classes_file.readlines()


# In[68]:


assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]


# In[69]:


sorted(class_names)


# In[70]:


def parse(data_batch):
    feature_descriptions = {
        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),
        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),
        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64),
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[\"shape\"][:, 0]
    labels = examples[\"class_index\"][:, 0]
    return sketches, lengths, labels


# In[71]:


def quickdraw_dataset(
    filepaths,
    batch_size=32,
    shuffle_buffer_size=None,
    n_parse_threads=5,
    n_read_threads=5,
    cache=False,
):
    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)


# In[72]:


train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])


# In[73]:


for sketches, lengths, labels in train_set.take(1):
    print(\"sketches =\", sketches)
    print(\"lengths =\", lengths)
    print(\"labels =\", labels)


# In[74]:


def draw_sketch(sketch, label=None):
    origin = np.array([[0.0, 0.0, 0.0]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1] == 1.0)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else \"Try to guess\"
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")
    plt.axis(\"off\")


def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(
        range(n_sketches), sketches, lengths, labels
    ):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()


for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)


# Most sketches are composed of less than 100 points:

# In[75]:


lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(\"length\")
plt.ylabel(\"density\")
plt.show()


# In[76]:


def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))


cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)


# In[77]:


model = keras.models.Sequential(
    [
        keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(128, return_sequences=True),
        keras.layers.LSTM(128),
        keras.layers.Dense(len(class_names), activation=\"softmax\"),
    ]
)
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.0)
model.compile(
    loss=\"sparse_categorical_crossentropy\",
    optimizer=optimizer,
    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],
)
history = model.fit(cropped_train_set, epochs=2, validation_data=cropped_valid_set)


# In[78]:


y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)


# In[79]:


np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))


# In[80]:


n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(\"Top-5 predictions:\".format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))
    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))


# In[81]:


model.save(\"my_sketchrnn\")


# ## 10. Bach Chorales
# _Exercise: Download the [Bach chorales](https://homl.info/bach) dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out [Google's Coconet model](https://homl.info/coconet), which was used for a nice [Google doodle about Bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)._
#
#

# In[82]:


DOWNLOAD_ROOT = (
    \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"
)
FILENAME = \"jsb_chorales.tgz\"
filepath = keras.utils.get_file(
    FILENAME,
    DOWNLOAD_ROOT + FILENAME,
    cache_subdir=\"datasets/jsb_chorales\",
    extract=True,
)


# In[83]:


jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))
valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))
test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))


# In[84]:


import pandas as pd


def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]


train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)


# In[85]:


train_chorales[0]


# Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:

# In[86]:


notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81


# Let's write a few functions to listen to these chorales (you don't need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):

# In[87]:


from IPython.display import Audio


def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440


def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo  # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 9.0).reshape(-1, 1)
    return sine_waves.reshape(-1)


def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]]  # make last note a bit longer
    merged = np.mean(
        [frequencies_to_samples(melody, tempo, sample_rate) for melody in freqs.T],
        axis=0,
    )
    n_fade_out_samples = sample_rate * 60 // tempo  # fade out last note
    fade_out = np.linspace(1.0, 0.0, n_fade_out_samples) ** 2
    merged[-n_fade_out_samples:] *= fade_out
    return merged


def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile

        samples = (2 ** 15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))


# Now let's listen to a few chorales:

# In[88]:


for index in range(3):
    play_chords(train_chorales[index])


# Divine! :)

# In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don't go very well together (believe me, I tried). It's much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.
#
# We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).
#
# And we will train the model on windows of 128 notes (i.e., 32 chords).
#
# Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).

# In[89]:


def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:]  # predict next note in each arpegio, at each step
    return X, Y


def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1)  # shift values
    return tf.reshape(window, [-1])  # convert to arpegio


def bach_dataset(
    chorales,
    batch_size=32,
    shuffle_buffer_size=None,
    window_size=32,
    window_shift=16,
    cache=True,
):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)


# Now let's create the training set, the validation set and the test set:

# In[90]:


train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)


# Now let's create the model:
#
# * We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C\\#3, it's very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an `Embedding` layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of `[batch_size, window_size, 5]`.
# * We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 `Conv1D` layers with doubling dilation rates. We will intersperse these layers with `BatchNormalization` layers for faster better convergence.
# * Then one `LSTM` layer to try to capture long-term patterns.
# * And finally a `Dense` layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be `[batch_size, window_size, 47]`.

# In[91]:


n_embedding_dims = 5

model = keras.models.Sequential(
    [
        keras.layers.Embedding(
            input_dim=n_notes, output_dim=n_embedding_dims, input_shape=[None]
        ),
        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8
        ),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(256, return_sequences=True),
        keras.layers.Dense(n_notes, activation=\"softmax\"),
    ]
)

model.summary()


# Now we're ready to compile and train the model!

# In[92]:


optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(
    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]
)
model.fit(train_set, epochs=20, validation_data=valid_set)


# I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the `LSTM` layer and replacing it with `Conv1D` layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.

# Once you're satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:

# In[93]:


model.save(\"my_bach_model.h5\")
model.evaluate(test_set)


# **Note:** There's no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.

# Now let's write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.

# **Warning**: `model.predict_classes(X)` is deprecated. It is replaced with `np.argmax(model.predict(X), axis=-1)`.

# In[94]:


def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            # next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# To test this function, we need some seed chords. Let's use the first 8 chords of one of the test chorales (it's actually just 2 different chords, each played 4 times):

# In[95]:


seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)


# Now we are ready to generate our first chorale! Let's ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):

# In[96]:


new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)


# This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.
#
# So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a `temperature` parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.

# In[97]:


def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# Let's generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!
#
# **Please share your most beautiful generated chorale with me on Twitter @aureliengeron, I would really appreciate it! :))**

# In[98]:


new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")


# In[99]:


new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")


# In[100]:


new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")


# Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!

# In[101]:


play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")
" 0 1 (fontified t face font-lock-comment-delimiter-face) 1 22 (fontified t face font-lock-comment-face) 22 23 (fontified t) 23 29 (fontified t face font-lock-keyword-face) 29 38 (fontified t) 38 44 (fontified t face font-lock-keyword-face) 44 56 (fontified t) 56 58 (fontified t face font-lock-keyword-face) 58 62 (fontified t) 62 66 (fontified t face font-lock-keyword-face) 66 78 (fontified t) 78 84 (fontified t face font-lock-keyword-face) 84 91 (fontified t) 91 97 (fontified t face font-lock-keyword-face) 97 104 (fontified t) 104 106 (fontified t face font-lock-keyword-face) 106 110 (fontified t) 110 114 (fontified t face font-lock-keyword-face) 114 123 (fontified t) 123 129 (fontified t face font-lock-keyword-face) 129 136 (fontified t) 136 138 (fontified t face font-lock-comment-delimiter-face) 138 188 (fontified t face font-lock-comment-face) 188 202 (fontified t) 202 203 (fontified t face (rainbow-delimiters-depth-1-face)) 203 205 (fontified t) 205 206 (fontified t face (rainbow-delimiters-depth-1-face)) 206 225 (fontified t) 225 226 (fontified t face (rainbow-delimiters-depth-1-face)) 226 228 (fontified t) 228 229 (fontified t face (rainbow-delimiters-depth-1-face)) 229 231 (fontified t) 231 237 (fontified t face font-lock-keyword-face) 237 249 (fontified t) 249 251 (fontified t face font-lock-keyword-face) 251 256 (fontified t) 256 262 (fontified t face font-lock-keyword-face) 262 281 (fontified t) 281 283 (fontified t face font-lock-keyword-face) 283 295 (fontified t) 295 296 (fontified t face (rainbow-delimiters-depth-1-face)) 296 302 (fontified t face font-lock-string-face) 302 316 (fontified t) 316 317 (fontified t face (rainbow-delimiters-depth-1-face)) 317 324 (fontified t) 324 325 (fontified t face (rainbow-delimiters-depth-1-face)) 325 332 (fontified t face font-lock-string-face) 332 346 (fontified t) 346 347 (fontified t face (rainbow-delimiters-depth-1-face)) 347 354 (fontified t) 354 355 (fontified t face (rainbow-delimiters-depth-1-face)) 355 362 (fontified t face font-lock-string-face) 362 376 (fontified t) 376 377 (fontified t face (rainbow-delimiters-depth-1-face)) 377 380 (fontified t) 380 381 (fontified t) 381 388 (fontified t face font-lock-variable-name-face) 388 394 (fontified t) 394 400 (fontified t face font-lock-variable-name-face) 400 423 (fontified t) 423 424 (fontified t face (rainbow-delimiters-depth-1-face)) 424 442 (fontified t) 442 443 (fontified t face (rainbow-delimiters-depth-1-face)) 443 444 (fontified t) 444 451 (fontified t face font-lock-variable-name-face) 451 453 (fontified t) 453 460 (fontified t face font-lock-variable-name-face) 460 469 (fontified t) 469 470 (fontified t face (rainbow-delimiters-depth-1-face)) 470 481 (fontified t) 481 485 (fontified t) 485 486 (fontified t face (rainbow-delimiters-depth-1-face)) 486 494 (fontified t) 494 495 (fontified t face (rainbow-delimiters-depth-1-face)) 495 504 (fontified t) 504 505 (fontified t face (rainbow-delimiters-depth-1-face)) 505 506 (fontified t) 506 513 (fontified t face font-lock-variable-name-face) 513 515 (fontified t) 515 522 (fontified t face font-lock-variable-name-face) 522 531 (fontified t) 531 532 (fontified t face (rainbow-delimiters-depth-1-face)) 532 551 (fontified t) 551 552 (fontified t face (rainbow-delimiters-depth-1-face)) 552 560 (fontified t) 560 561 (fontified t face (rainbow-delimiters-depth-1-face)) 561 574 (fontified t) 574 575 (fontified t face (rainbow-delimiters-depth-1-face)) 575 576 (fontified t) 576 582 (fontified t face font-lock-variable-name-face) 582 584 (fontified t) 584 590 (fontified t face font-lock-variable-name-face) 590 599 (fontified t) 599 600 (fontified t face (rainbow-delimiters-depth-1-face)) 600 615 (fontified t) 615 616 (fontified t face (rainbow-delimiters-depth-1-face)) 616 624 (fontified t) 624 625 (fontified t face (rainbow-delimiters-depth-1-face)) 625 634 (fontified t) 634 635 (fontified t face (rainbow-delimiters-depth-1-face)) 635 638 (fontified t) 638 640 (fontified t face font-lock-comment-delimiter-face) 640 647 (fontified t face font-lock-comment-face) 647 680 (fontified t) 680 682 (fontified t face font-lock-comment-delimiter-face) 682 689 (fontified t face font-lock-comment-face) 689 691 (fontified t) 691 694 (fontified t face font-lock-keyword-face) 694 695 (fontified t) 695 706 (fontified t face font-lock-function-name-face) 706 707 (fontified t face (rainbow-delimiters-depth-1-face)) 707 722 (fontified t) 722 726 (fontified t face font-lock-constant-face) 726 735 (fontified t) 735 739 (fontified t face font-lock-constant-face) 739 749 (fontified t) 749 754 (fontified t face font-lock-string-face) 754 764 (fontified t) 764 772 (fontified t face font-lock-string-face) 772 781 (fontified t) 781 785 (fontified t face font-lock-constant-face) 785 786 (fontified t) 786 787 (fontified t face (rainbow-delimiters-depth-1-face)) 787 801 (fontified t) 801 802 (fontified t face (rainbow-delimiters-depth-1-face)) 802 810 (fontified t) 810 814 (fontified t face font-lock-string-face) 814 815 (fontified t face (rainbow-delimiters-depth-1-face)) 815 820 (fontified t) 820 822 (fontified t face font-lock-keyword-face) 822 825 (fontified t) 825 827 (fontified t face font-lock-keyword-face) 827 828 (fontified t) 828 831 (fontified t face font-lock-keyword-face) 831 832 (fontified t) 832 836 (fontified t face font-lock-constant-face) 836 854 (fontified t) 854 855 (fontified t face (rainbow-delimiters-depth-1-face)) 855 867 (fontified t) 867 871 (fontified t face font-lock-string-face) 871 879 (fontified t) 879 881 (fontified t face font-lock-string-face) 881 887 (face font-lock-string-face fontified t) 887 888 (face (rainbow-delimiters-depth-1-face) fontified t) 888 889 (fontified t) 893 895 (face font-lock-keyword-face) 903 905 (face font-lock-keyword-face) 906 909 (face font-lock-keyword-face) 910 914 (face font-lock-constant-face) 932 933 (face (rainbow-delimiters-depth-1-face)) 950 954 (face font-lock-string-face) 977 989 (face font-lock-string-face) 989 990 (face (rainbow-delimiters-depth-1-face)) 1003 1004 (face (rainbow-delimiters-depth-1-face)) 1004 1006 (face font-lock-constant-face) 1006 1008 (face font-lock-constant-face) 1008 1009 (face (rainbow-delimiters-depth-1-face))) . 1) (undo-tree-id3959 . -380) (undo-tree-id3960 . -380) (undo-tree-id3961 . -380) (undo-tree-id3962 . -380) (undo-tree-id3963 . -380) (undo-tree-id3964 . -380) (undo-tree-id3965 . -380) (undo-tree-id3966 . -380) (undo-tree-id3967 . -380) (undo-tree-id3968 . -380) (undo-tree-id3969 . -380) (undo-tree-id3970 . -380) (undo-tree-id3971 . -380) (undo-tree-id3972 . -380) (undo-tree-id3973 . -380) (undo-tree-id3974 . -380) (undo-tree-id3975 . -380) (undo-tree-id3976 . -380) (undo-tree-id3977 . -380) (undo-tree-id3978 . -380) (undo-tree-id3979 . -380) (undo-tree-id3980 . -380) (undo-tree-id3981 . -380) (undo-tree-id3982 . -380) (undo-tree-id3983 . -380) (undo-tree-id3984 . -380) (undo-tree-id3985 . -380) (undo-tree-id3986 . -380) (undo-tree-id3987 . -380) (undo-tree-id3988 . -23) (undo-tree-id3989 . -29) (undo-tree-id3990 . -231) (undo-tree-id3991 . -237) (undo-tree-id3992 . -256) (undo-tree-id3993 . -262) (undo-tree-id3994 . -403) (undo-tree-id3995 . -423) (undo-tree-id3996 . -1568) (undo-tree-id3997 . -1576) (undo-tree-id3998 . -1689) (undo-tree-id3999 . -1698) (undo-tree-id4000 . -2447) (undo-tree-id4001 . -2454) (undo-tree-id4002 . -2714) (undo-tree-id4003 . -2718) (undo-tree-id4004 . -3288) (undo-tree-id4005 . -3289) (undo-tree-id4006 . -3471) (undo-tree-id4007 . -3478) (undo-tree-id4008 . -3935) (undo-tree-id4009 . -3936) (undo-tree-id4010 . -4160) (undo-tree-id4011 . -4167) (undo-tree-id4012 . -4674) (undo-tree-id4013 . -4675) (undo-tree-id4014 . -4872) (undo-tree-id4015 . -4879) (undo-tree-id4016 . -5274) (undo-tree-id4017 . -5277) (undo-tree-id4018 . -5288) (undo-tree-id4019 . -5308) (undo-tree-id4020 . -5798) (undo-tree-id4021 . -5804) (undo-tree-id4022 . -6079) (undo-tree-id4023 . -6087) (undo-tree-id4024 . -6199) (undo-tree-id4025 . -6209) (undo-tree-id4026 . -6303) (undo-tree-id4027 . -6323) (undo-tree-id4028 . -6967) (undo-tree-id4029 . -6973) (undo-tree-id4030 . -7456) (undo-tree-id4031 . -7463) (undo-tree-id4032 . -7710) (undo-tree-id4033 . -7711) (undo-tree-id4034 . -7909) (undo-tree-id4035 . -7916) (undo-tree-id4036 . -7962) (undo-tree-id4037 . -7982) (undo-tree-id4038 . -8245) (undo-tree-id4039 . -8249) (undo-tree-id4040 . -8671) (undo-tree-id4041 . -8691) (undo-tree-id4042 . -8940) (undo-tree-id4043 . -8941) (undo-tree-id4044 . -9246) (undo-tree-id4045 . -9247) (undo-tree-id4046 . -9695) (undo-tree-id4047 . -9702) (undo-tree-id4048 . -9748) (undo-tree-id4049 . -9768) (undo-tree-id4050 . -10163) (undo-tree-id4051 . -10164) (undo-tree-id4052 . -10531) (undo-tree-id4053 . -10538) (undo-tree-id4054 . -10586) (undo-tree-id4055 . -10590) (undo-tree-id4056 . -10934) (undo-tree-id4057 . -10938) (undo-tree-id4058 . -12016) (undo-tree-id4059 . -12023) (undo-tree-id4060 . -12570) (undo-tree-id4061 . -12571) (undo-tree-id4062 . -13501) (undo-tree-id4063 . -13502) (undo-tree-id4064 . -13783) (undo-tree-id4065 . -13790) (undo-tree-id4066 . -14251) (undo-tree-id4067 . -14258) (undo-tree-id4068 . -14451) (undo-tree-id4069 . -14471) (undo-tree-id4070 . -15116) (undo-tree-id4071 . -15123) (undo-tree-id4072 . -15316) (undo-tree-id4073 . -15336) (undo-tree-id4074 . -16445) (undo-tree-id4075 . -16446) (undo-tree-id4076 . -16817) (undo-tree-id4077 . -16818) (undo-tree-id4078 . -17910) (undo-tree-id4079 . -17917) (undo-tree-id4080 . -18000) (undo-tree-id4081 . -18005) (undo-tree-id4082 . -18779) (undo-tree-id4083 . -18792) (undo-tree-id4084 . -19698) (undo-tree-id4085 . -19699) (undo-tree-id4086 . -19926) (undo-tree-id4087 . -19933) (undo-tree-id4088 . -20017) (undo-tree-id4089 . -20018) (undo-tree-id4090 . -20595) (undo-tree-id4091 . -20597) (undo-tree-id4092 . -20699) (undo-tree-id4093 . -20702) (undo-tree-id4094 . -21176) (undo-tree-id4095 . -21183) (undo-tree-id4096 . -21316) (undo-tree-id4097 . -21324) (undo-tree-id4098 . -21410) (undo-tree-id4099 . -21411) (undo-tree-id4100 . -22687) (undo-tree-id4101 . -22701) (undo-tree-id4102 . -24781) (undo-tree-id4103 . -24787) (undo-tree-id4104 . -25801) (undo-tree-id4105 . -25818) (undo-tree-id4106 . -26234) (undo-tree-id4107 . -26235) (undo-tree-id4108 . -26678) (undo-tree-id4109 . -26683) (undo-tree-id4110 . -28137) (undo-tree-id4111 . -28143) (undo-tree-id4112 . -28510) (undo-tree-id4113 . -28513) (undo-tree-id4114 . -28902) (undo-tree-id4115 . -28912) (undo-tree-id4116 . -29096) (undo-tree-id4117 . -29100) (undo-tree-id4118 . -30316) (undo-tree-id4119 . -30317) (undo-tree-id4120 . -30621) (undo-tree-id4121 . -30625) (undo-tree-id4122 . -30879) (undo-tree-id4123 . -30886) (undo-tree-id4124 . -30929) (undo-tree-id4125 . -30936) (undo-tree-id4126 . -31180) (undo-tree-id4127 . -31183) (undo-tree-id4128 . -32030) (undo-tree-id4129 . -32040) (undo-tree-id4130 . -32258) (undo-tree-id4131 . -32263) (undo-tree-id4132 . -32700) (undo-tree-id4133 . -32706) (undo-tree-id4134 . -33154) (undo-tree-id4135 . -33158) (undo-tree-id4136 . -33974) (undo-tree-id4137 . -33979) (undo-tree-id4138 . -34704) (undo-tree-id4139 . -34712) (undo-tree-id4140 . -35012) (undo-tree-id4141 . -35016) (undo-tree-id4142 . -35474) (undo-tree-id4143 . -35478) (undo-tree-id4144 . -35622) (undo-tree-id4145 . -35635) (undo-tree-id4146 . -35789) (undo-tree-id4147 . -35802) (undo-tree-id4148 . -35956) (undo-tree-id4149 . -35969) (undo-tree-id4150 . -36375) (undo-tree-id4151 . -36383) (undo-tree-id4152 . -36527) (undo-tree-id4153 . -36532) (undo-tree-id4154 . -36825) (undo-tree-id4155 . -36826) (undo-tree-id4156 . -37040) (undo-tree-id4157 . -37041) (undo-tree-id4158 . -37333) (undo-tree-id4159 . -37334) (undo-tree-id4160 . -37671) (undo-tree-id4161 . -37673) (undo-tree-id4162 . -38346) (undo-tree-id4163 . -38347) (undo-tree-id4164 . -38603) (undo-tree-id4165 . -38611) (undo-tree-id4166 . -38893) (undo-tree-id4167 . -38898) (undo-tree-id4168 . -39319) (undo-tree-id4169 . -39326) (undo-tree-id4170 . -40598) (undo-tree-id4171 . -40601) (undo-tree-id4172 . -40878) (undo-tree-id4173 . -40891) (undo-tree-id4174 . -41021) (undo-tree-id4175 . -41022) (undo-tree-id4176 . -41177) (undo-tree-id4177 . -41178) (undo-tree-id4178 . -41340) (undo-tree-id4179 . -41341) (undo-tree-id4180 . -41481) (undo-tree-id4181 . -41489) (undo-tree-id4182 . -380) (undo-tree-id4183 . -380) (undo-tree-id4184 . -380) (undo-tree-id4185 . -380) (undo-tree-id4186 . -380) (undo-tree-id4187 . -380) (undo-tree-id4188 . -380) (undo-tree-id4189 . -380) (undo-tree-id4190 . -380) (undo-tree-id4191 . -380) (undo-tree-id4192 . -380) (undo-tree-id4193 . -380) (undo-tree-id4194 . -380) (undo-tree-id4195 . -380) (undo-tree-id4196 . -380) (undo-tree-id4197 . -380) (undo-tree-id4198 . -380) (undo-tree-id4199 . -380) (undo-tree-id4200 . -380) (undo-tree-id4201 . -380) (undo-tree-id4202 . -380) (undo-tree-id4203 . -380) (undo-tree-id4204 . -380) (undo-tree-id4205 . -380) (undo-tree-id4206 . -380) (undo-tree-id4207 . -380) (undo-tree-id4208 . -380) (undo-tree-id4209 . -380) (undo-tree-id4210 . -380) (undo-tree-id4211 . -380) (undo-tree-id4212 . -380) (undo-tree-id4213 . -380) (undo-tree-id4214 . -380) (undo-tree-id4215 . -380) (undo-tree-id4216 . -380) (undo-tree-id4217 . -380) (undo-tree-id4218 . -380) (undo-tree-id4219 . -380) (undo-tree-id4220 . -380) (undo-tree-id4221 . -380) (undo-tree-id4222 . -380) (undo-tree-id4223 . -380) (undo-tree-id4224 . -380) (undo-tree-id4225 . -380) (undo-tree-id4226 . -380) (undo-tree-id4227 . -380) (undo-tree-id4228 . -380) (undo-tree-id4229 . -380) (undo-tree-id4230 . -380) (undo-tree-id4231 . -380) (undo-tree-id4232 . -380) (undo-tree-id4233 . -380) (undo-tree-id4234 . -380) (undo-tree-id4235 . -380) (undo-tree-id4236 . -380) (undo-tree-id4237 . -380) (undo-tree-id4238 . -691) (undo-tree-id4239 . -691) (undo-tree-id4240 . -691) (undo-tree-id4241 . -691) (undo-tree-id4242 . -691) (undo-tree-id4243 . -691) (undo-tree-id4244 . -793) (undo-tree-id4245 . -793) (undo-tree-id4246 . -846) (undo-tree-id4247 . -846) (undo-tree-id4248 . -846) (undo-tree-id4249 . -846) (undo-tree-id4250 . -380) (undo-tree-id4251 . -380) (undo-tree-id4252 . -380) (undo-tree-id4253 . -380) (undo-tree-id4254 . -380) (undo-tree-id4255 . -380) (undo-tree-id4256 . -380) (undo-tree-id4257 . -380) (undo-tree-id4258 . -380) (undo-tree-id4259 . -380) (undo-tree-id4260 . -380) (undo-tree-id4261 . -380) (undo-tree-id4262 . -380) (undo-tree-id4263 . -380) (undo-tree-id4264 . -380) (undo-tree-id4265 . -380) (undo-tree-id4266 . -380) (undo-tree-id4267 . -380) (undo-tree-id4268 . -380) (undo-tree-id4269 . -380) (undo-tree-id4270 . -380) (undo-tree-id4271 . -380) (undo-tree-id4272 . -380) (undo-tree-id4273 . -380) (undo-tree-id4274 . -380) (undo-tree-id4275 . -380) (undo-tree-id4276 . -380) (undo-tree-id4277 . -380) (undo-tree-id4278 . -380) (undo-tree-id4279 . -380) (undo-tree-id4280 . -380) (undo-tree-id4281 . -380) (undo-tree-id4282 . -380) (undo-tree-id4283 . -380)) nil (25760 29853 200060 956000) 0 nil])
([nil nil ((49 . 52) (43 . 49) (#("i" 0 1 (fontified nil)) . -43) (43 . 44) (#("import" 0 6 (fontified nil)) . -43) (43 . 49) (#("im" 0 2 (fontified t)) . -43) (undo-tree-id5179 . -2) (undo-tree-id5180 . -2) (undo-tree-id5181 . -1) (undo-tree-id5182 . -1) (undo-tree-id5183 . -1) (undo-tree-id5184 . -1) (undo-tree-id5185 . -1) (undo-tree-id5186 . -1) (undo-tree-id5187 . -1) (undo-tree-id5188 . -1) (undo-tree-id5189 . -1) (undo-tree-id5190 . -1) (undo-tree-id5191 . -1) (undo-tree-id5192 . -1) (undo-tree-id5193 . -1) (undo-tree-id5194 . -1) (undo-tree-id5195 . -1) (undo-tree-id5196 . -1) (undo-tree-id5197 . -1) (undo-tree-id5198 . -1) (undo-tree-id5199 . -1) (undo-tree-id5200 . -1) (undo-tree-id5201 . -1) (undo-tree-id5202 . -1) (undo-tree-id5203 . -1) (undo-tree-id5204 . -1) (undo-tree-id5205 . -1) (undo-tree-id5206 . -1) (undo-tree-id5207 . -1) (undo-tree-id5208 . -1) (undo-tree-id5209 . -1) (undo-tree-id5210 . -1) (undo-tree-id5211 . -1) (undo-tree-id5212 . -1) (undo-tree-id5213 . -1) (undo-tree-id5214 . -1) (undo-tree-id5215 . -1) (undo-tree-id5216 . -1) (undo-tree-id5217 . -1) (undo-tree-id5218 . -1) (undo-tree-id5219 . -1) (undo-tree-id5220 . -1) (undo-tree-id5221 . -1) (undo-tree-id5222 . -1) (undo-tree-id5223 . -1) (undo-tree-id5224 . -1) (undo-tree-id5225 . -1) (undo-tree-id5226 . -1) (undo-tree-id5227 . -1) (undo-tree-id5228 . -1) (undo-tree-id5229 . -2) (undo-tree-id5230 . -2) (undo-tree-id5231 . -2) (undo-tree-id5232 . -2) (undo-tree-id5233 . -2) (undo-tree-id5234 . -2) (undo-tree-id5235 . -2) (undo-tree-id5236 . -2) (undo-tree-id5237 . -2) (undo-tree-id5238 . -2) (undo-tree-id5239 . -2) (undo-tree-id5240 . -2) (undo-tree-id5241 . -2) (undo-tree-id5242 . -2) (undo-tree-id5243 . -2) (undo-tree-id5244 . -2) (undo-tree-id5245 . -2) (undo-tree-id5246 . -2) (undo-tree-id5247 . -2) (undo-tree-id5248 . -2) (undo-tree-id5249 . -2) (undo-tree-id5250 . -2) (undo-tree-id5251 . -2) (undo-tree-id5252 . -2) (undo-tree-id5253 . -2) (undo-tree-id5254 . -2) (undo-tree-id5255 . -2) (undo-tree-id5256 . -2) 45 (42 . 45) (29 . 42) (#("cust" 0 4 (fontified nil)) . -29) (29 . 33) (#("custom_functs" 0 13 (fontified nil)) . -29) (29 . 42) (#("custom" 0 6 (fontified t)) . -29) (undo-tree-id5257 . -6) (undo-tree-id5258 . -6) (undo-tree-id5259 . -1) (undo-tree-id5260 . -1) (undo-tree-id5261 . -1) (undo-tree-id5262 . -1) (undo-tree-id5263 . -1) (undo-tree-id5264 . -1) (undo-tree-id5265 . -1) (undo-tree-id5266 . -1) (undo-tree-id5267 . -1) (undo-tree-id5268 . -1) (undo-tree-id5269 . -1) (undo-tree-id5270 . -1) (undo-tree-id5271 . -1) (undo-tree-id5272 . -1) (undo-tree-id5273 . -1) (undo-tree-id5274 . -1) (undo-tree-id5275 . -1) (undo-tree-id5276 . -1) (undo-tree-id5277 . -1) (undo-tree-id5278 . -1) (undo-tree-id5279 . -1) (undo-tree-id5280 . -1) (undo-tree-id5281 . -1) (undo-tree-id5282 . -1) (undo-tree-id5283 . -1) (undo-tree-id5284 . -1) (undo-tree-id5285 . -1) (undo-tree-id5286 . -1) (undo-tree-id5287 . -1) (undo-tree-id5288 . -1) (undo-tree-id5289 . -1) (undo-tree-id5290 . -1) (undo-tree-id5291 . -1) (undo-tree-id5292 . -1) (undo-tree-id5293 . -1) (undo-tree-id5294 . -1) (undo-tree-id5295 . -1) (undo-tree-id5296 . -1) (undo-tree-id5297 . -1) (undo-tree-id5298 . -2) (undo-tree-id5299 . -2) (undo-tree-id5300 . -2) (undo-tree-id5301 . -2) (undo-tree-id5302 . -2) (undo-tree-id5303 . -2) (undo-tree-id5304 . -2) (undo-tree-id5305 . -2) (undo-tree-id5306 . -2) (undo-tree-id5307 . -2) (undo-tree-id5308 . -2) (undo-tree-id5309 . -2) (undo-tree-id5310 . -2) (undo-tree-id5311 . -2) (undo-tree-id5312 . -2) (undo-tree-id5313 . -2) (undo-tree-id5314 . -3) (undo-tree-id5315 . -3) (undo-tree-id5316 . -3) (undo-tree-id5317 . -3) (undo-tree-id5318 . -3) (undo-tree-id5319 . -3) (undo-tree-id5320 . -3) (undo-tree-id5321 . -3) (undo-tree-id5322 . -3) (undo-tree-id5323 . -3) (undo-tree-id5324 . -3) (undo-tree-id5325 . -3) (undo-tree-id5326 . -3) (undo-tree-id5327 . -3) (undo-tree-id5328 . -3) (undo-tree-id5329 . -3) (undo-tree-id5330 . -3) (undo-tree-id5331 . -3) (undo-tree-id5332 . -4) (undo-tree-id5333 . -4) (undo-tree-id5334 . -4) (undo-tree-id5335 . -4) (undo-tree-id5336 . -4) (undo-tree-id5337 . -4) (undo-tree-id5338 . -4) (undo-tree-id5339 . -4) (undo-tree-id5340 . -4) (undo-tree-id5341 . -4) (undo-tree-id5342 . -4) (undo-tree-id5343 . -4) (undo-tree-id5344 . -4) (undo-tree-id5345 . -4) (undo-tree-id5346 . -4) (undo-tree-id5347 . -4) (undo-tree-id5348 . -4) (undo-tree-id5349 . -4) (undo-tree-id5350 . -4) (undo-tree-id5351 . -4) (undo-tree-id5352 . -4) (undo-tree-id5353 . -4) (undo-tree-id5354 . -4) (undo-tree-id5355 . -4) (undo-tree-id5356 . -4) (undo-tree-id5357 . -4) (undo-tree-id5358 . -5) (undo-tree-id5359 . -5) (undo-tree-id5360 . -5) (undo-tree-id5361 . -5) (undo-tree-id5362 . -5) (undo-tree-id5363 . -5) (undo-tree-id5364 . -5) (undo-tree-id5365 . -5) (undo-tree-id5366 . -5) (undo-tree-id5367 . -5) (undo-tree-id5368 . -5) (undo-tree-id5369 . -5) (undo-tree-id5370 . -5) (undo-tree-id5371 . -5) (undo-tree-id5372 . -5) (undo-tree-id5373 . -5) (undo-tree-id5374 . -5) (undo-tree-id5375 . -6) (undo-tree-id5376 . -6) (undo-tree-id5377 . -6) (undo-tree-id5378 . -6) (undo-tree-id5379 . -6) (undo-tree-id5380 . -6) (undo-tree-id5381 . -6) (undo-tree-id5382 . -6) (undo-tree-id5383 . -6) (undo-tree-id5384 . -6) (undo-tree-id5385 . -6) (undo-tree-id5386 . -6) (undo-tree-id5387 . -6) (undo-tree-id5388 . -6) (undo-tree-id5389 . -6) (undo-tree-id5390 . -6) (undo-tree-id5391 . -6) (undo-tree-id5392 . -6) 35 (29 . 35) (28 . 29) (24 . 28) (23 . 24) (t 25760 29853 206589 851000) 23) nil (25760 29866 872055 224000) 0 nil])
([nil nil ((1 . 41687) (#("#!/usr/bin/env python

from custom_functs import * 
import sklearn
import tensorflow as tf
from tensorflow import keras
import numpy as np
from pathlib import Path

# to make this notebook's output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rc(\"axes\", labelsize=14)
mpl.rc(\"xtick\", labelsize=12)
mpl.rc(\"ytick\", labelsize=12)


n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]


# In[4]:


X_train.shape, y_train.shape


# In[5]:


def plot_series(
    series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True
):
    plt.plot(series, \".-\")
    if y is not None:
        plt.plot(n_steps, y, \"bo\", label=\"Target\")
    if y_pred is not None:
        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=\"upper left\")


fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(
        X_valid[col, :, 0],
        y_valid[col, 0],
        y_label=(\"$x(t)$\" if col == 0 else None),
        legend=(col == 0),
    )
save_fig(\"time_series_plot\")
plt.show()


# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.

# ## Computing Some Baselines

# Naive predictions (just predict the last observed value):

# In[6]:


y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))


# In[7]:


plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Linear predictions:

# In[8]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(1)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[9]:


model.evaluate(X_valid, y_valid)


# In[10]:


def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(\"Epochs\")
    plt.ylabel(\"Loss\")
    plt.grid(True)


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[11]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Using a Simple RNN

# In[12]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1])])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=\"mse\", optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[13]:


model.evaluate(X_valid, y_valid)


# In[14]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[15]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Deep RNNs

# In[16]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.SimpleRNN(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[17]:


model.evaluate(X_valid, y_valid)


# In[18]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[19]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Make the second `SimpleRNN` layer return only the last output:

# In[20]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[21]:


model.evaluate(X_valid, y_valid)


# In[22]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[23]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Forecasting Several Steps Ahead

# In[24]:


np.random.seed(43)  # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]


# In[25]:


Y_pred.shape


# In[26]:


def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")
    plt.plot(
        np.arange(n_steps, n_steps + ahead),
        Y_pred[0, :, 0],
        \"rx-\",
        label=\"Forecast\",
        markersize=10,
    )
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)


plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(\"forecast_ahead_plot\")
plt.show()


# Now let's use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.

# In[27]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]


# Now let's predict the next 10 values one by one:

# In[28]:


X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]


# In[29]:


Y_pred.shape


# In[30]:


np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))


# Let's compare this performance with some baselines: naive predictions and a simple linear model:

# In[31]:


Y_naive_pred = np.tile(
    X_valid[:, -1], 10
)  # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))


# In[32]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(10)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Now let's create an RNN that predicts all 10 next values at once:

# In[33]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(10),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[34]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]


# In[35]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# Now let's create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.

# In[36]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead : step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]


# In[37]:


X_train.shape, Y_train.shape


# In[38]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)


def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])


model.compile(
    loss=\"mse\",
    optimizer=keras.optimizers.Adam(learning_rate=0.01),
    metrics=[last_time_step_mse],
)
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[39]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[40]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # Deep RNN with Batch Norm

# In[41]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.BatchNormalization(),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.BatchNormalization(),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Deep RNNs with Layer Norm

# In[42]:


from tensorflow.keras.layers import LayerNormalization


# In[43]:


class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]

    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]


# In[44]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.RNN(
            LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]
        ),
        keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Creating a Custom RNN Class

# In[45]:


class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, \"get_initial_state\", self.fallback_initial_state
        )

    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]

    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0)
        )
        outputs = tf.zeros(
            shape=[batch_size, self.cell.output_size], dtype=inputs.dtype
        )
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs


# In[46]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        MyRNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),
        MyRNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # LSTMs

# In[47]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.LSTM(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[48]:


model.evaluate(X_valid, Y_valid)


# In[49]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[50]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[51]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # GRUs

# In[52]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[53]:


model.evaluate(X_valid, Y_valid)


# In[54]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[55]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[56]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# ## Using One-Dimensional Convolutional Layers to Process Sequences

# ```
# 1D conv layer with kernel size 4, stride 2, VALID padding:
#
#               |-----2-----|     |-----5---...------|     |-----23----|
#         |-----1-----|     |-----4-----|   ...      |-----22----|
#   |-----0----|      |-----3-----|     |---...|-----21----|
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 42 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 43 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 52 53 54 55 56 57 58 59
#
# Output:
#
# X:     0/3   2/5   4/7   6/9   8/11 10/13 .../43 42/45 44/47 46/49
# Y:     4/13  6/15  8/17 10/19 12/21 14/23 .../53 46/55 48/57 50/59
# ```

# In[57]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.Conv1D(
            filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]
        ),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(
    X_train, Y_train[:, 3::2], epochs=20, validation_data=(X_valid, Y_valid[:, 3::2])
)


# ## WaveNet

# ```
# C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\.../\\ /\\ /\\ /\\ /\\ /\\
#    \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\       /  \\  /  \\  /  \\
#      /    \\      /    \\      /    \\                 /    \\
# C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /.../\\ /\\ /\\ /\\ /\\ /\\ /\\
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 53 54 55 56 57 58 59
# ```

# In[58]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(
        keras.layers.Conv1D(
            filters=20,
            kernel_size=2,
            padding=\"causal\",
            activation=\"relu\",
            dilation_rate=rate,
        )
    )
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:

# In[59]:


class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)

    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate


# In[60]:


def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(
        2 * n_filters, kernel_size=2, padding=\"causal\", dilation_rate=dilation_rate
    )(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z


# In[61]:


keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3  # 10 in the paper
n_blocks = 1  # 3 in the paper
n_filters = 32  # 128 in the paper
n_outputs = 10  # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)
skip_to_last = []
for dilation_rate in [2 ** i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])


# In[62]:


model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_valid, Y_valid))


# In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.

# # Exercise solutions

# ## 1. to 8.

# See Appendix A.

# ## 9. Tackling the SketchRNN Dataset

# _Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets._

# The dataset is not available in TFDS yet, the [pull request](https://github.com/tensorflow/datasets/pull/361) is still work in progress. Luckily, the data is conveniently available as TFRecords, so let's download it (it might take a while, as it's about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):

# In[63]:


DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"
FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"
filepath = keras.utils.get_file(
    FILENAME, DOWNLOAD_ROOT + FILENAME, cache_subdir=\"datasets/quickdraw\", extract=True
)


# In[64]:


quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])


# In[65]:


train_files


# In[66]:


eval_files


# In[67]:


with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:
    test_classes = test_classes_file.readlines()

with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:
    train_classes = train_classes_file.readlines()


# In[68]:


assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]


# In[69]:


sorted(class_names)


# In[70]:


def parse(data_batch):
    feature_descriptions = {
        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),
        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),
        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64),
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[\"shape\"][:, 0]
    labels = examples[\"class_index\"][:, 0]
    return sketches, lengths, labels


# In[71]:


def quickdraw_dataset(
    filepaths,
    batch_size=32,
    shuffle_buffer_size=None,
    n_parse_threads=5,
    n_read_threads=5,
    cache=False,
):
    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)


# In[72]:


train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])


# In[73]:


for sketches, lengths, labels in train_set.take(1):
    print(\"sketches =\", sketches)
    print(\"lengths =\", lengths)
    print(\"labels =\", labels)


# In[74]:


def draw_sketch(sketch, label=None):
    origin = np.array([[0.0, 0.0, 0.0]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1] == 1.0)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else \"Try to guess\"
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")
    plt.axis(\"off\")


def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(
        range(n_sketches), sketches, lengths, labels
    ):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()


for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)


# Most sketches are composed of less than 100 points:

# In[75]:


lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(\"length\")
plt.ylabel(\"density\")
plt.show()


# In[76]:


def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))


cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)


# In[77]:


model = keras.models.Sequential(
    [
        keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(128, return_sequences=True),
        keras.layers.LSTM(128),
        keras.layers.Dense(len(class_names), activation=\"softmax\"),
    ]
)
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.0)
model.compile(
    loss=\"sparse_categorical_crossentropy\",
    optimizer=optimizer,
    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],
)
history = model.fit(cropped_train_set, epochs=2, validation_data=cropped_valid_set)


# In[78]:


y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)


# In[79]:


np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))


# In[80]:


n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(\"Top-5 predictions:\".format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))
    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))


# In[81]:


model.save(\"my_sketchrnn\")


# ## 10. Bach Chorales
# _Exercise: Download the [Bach chorales](https://homl.info/bach) dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out [Google's Coconet model](https://homl.info/coconet), which was used for a nice [Google doodle about Bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)._
#
#

# In[82]:


DOWNLOAD_ROOT = (
    \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"
)
FILENAME = \"jsb_chorales.tgz\"
filepath = keras.utils.get_file(
    FILENAME,
    DOWNLOAD_ROOT + FILENAME,
    cache_subdir=\"datasets/jsb_chorales\",
    extract=True,
)


# In[83]:


jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))
valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))
test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))


# In[84]:


import pandas as pd


def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]


train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)


# In[85]:


train_chorales[0]


# Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:

# In[86]:


notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81


# Let's write a few functions to listen to these chorales (you don't need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):

# In[87]:


from IPython.display import Audio


def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440


def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo  # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 9.0).reshape(-1, 1)
    return sine_waves.reshape(-1)


def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]]  # make last note a bit longer
    merged = np.mean(
        [frequencies_to_samples(melody, tempo, sample_rate) for melody in freqs.T],
        axis=0,
    )
    n_fade_out_samples = sample_rate * 60 // tempo  # fade out last note
    fade_out = np.linspace(1.0, 0.0, n_fade_out_samples) ** 2
    merged[-n_fade_out_samples:] *= fade_out
    return merged


def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile

        samples = (2 ** 15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))


# Now let's listen to a few chorales:

# In[88]:


for index in range(3):
    play_chords(train_chorales[index])


# Divine! :)

# In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don't go very well together (believe me, I tried). It's much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.
#
# We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).
#
# And we will train the model on windows of 128 notes (i.e., 32 chords).
#
# Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).

# In[89]:


def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:]  # predict next note in each arpegio, at each step
    return X, Y


def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1)  # shift values
    return tf.reshape(window, [-1])  # convert to arpegio


def bach_dataset(
    chorales,
    batch_size=32,
    shuffle_buffer_size=None,
    window_size=32,
    window_shift=16,
    cache=True,
):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)


# Now let's create the training set, the validation set and the test set:

# In[90]:


train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)


# Now let's create the model:
#
# * We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C\\#3, it's very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an `Embedding` layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of `[batch_size, window_size, 5]`.
# * We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 `Conv1D` layers with doubling dilation rates. We will intersperse these layers with `BatchNormalization` layers for faster better convergence.
# * Then one `LSTM` layer to try to capture long-term patterns.
# * And finally a `Dense` layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be `[batch_size, window_size, 47]`.

# In[91]:


n_embedding_dims = 5

model = keras.models.Sequential(
    [
        keras.layers.Embedding(
            input_dim=n_notes, output_dim=n_embedding_dims, input_shape=[None]
        ),
        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8
        ),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(256, return_sequences=True),
        keras.layers.Dense(n_notes, activation=\"softmax\"),
    ]
)

model.summary()


# Now we're ready to compile and train the model!

# In[92]:


optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(
    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]
)
model.fit(train_set, epochs=20, validation_data=valid_set)


# I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the `LSTM` layer and replacing it with `Conv1D` layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.

# Once you're satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:

# In[93]:


model.save(\"my_bach_model.h5\")
model.evaluate(test_set)


# **Note:** There's no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.

# Now let's write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.

# **Warning**: `model.predict_classes(X)` is deprecated. It is replaced with `np.argmax(model.predict(X), axis=-1)`.

# In[94]:


def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            # next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# To test this function, we need some seed chords. Let's use the first 8 chords of one of the test chorales (it's actually just 2 different chords, each played 4 times):

# In[95]:


seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)


# Now we are ready to generate our first chorale! Let's ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):

# In[96]:


new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)


# This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.
#
# So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a `temperature` parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.

# In[97]:


def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# Let's generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!
#
# **Please share your most beautiful generated chorale with me on Twitter @aureliengeron, I would really appreciate it! :))**

# In[98]:


new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")


# In[99]:


new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")


# In[100]:


new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")


# Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!

# In[101]:


play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")
" 0 1 (fontified t face font-lock-comment-delimiter-face) 1 22 (fontified t face font-lock-comment-face) 22 23 (fontified t) 23 27 (fontified t face font-lock-keyword-face) 27 28 (fontified t) 28 42 (fontified t) 42 48 (fontified t face font-lock-keyword-face) 48 51 (fontified t) 51 52 (fontified t) 52 58 (fontified t face font-lock-keyword-face) 58 67 (fontified t) 67 73 (fontified t face font-lock-keyword-face) 73 85 (fontified t) 85 87 (fontified t face font-lock-keyword-face) 87 91 (fontified t) 91 95 (fontified t face font-lock-keyword-face) 95 107 (fontified t) 107 113 (fontified t face font-lock-keyword-face) 113 120 (fontified t) 120 126 (fontified t face font-lock-keyword-face) 126 133 (fontified t) 133 135 (fontified t face font-lock-keyword-face) 135 139 (fontified t) 139 143 (fontified t face font-lock-keyword-face) 143 152 (fontified t) 152 158 (fontified t face font-lock-keyword-face) 158 165 (fontified t) 165 167 (fontified t face font-lock-comment-delimiter-face) 167 217 (fontified t face font-lock-comment-face) 217 231 (fontified t) 231 232 (fontified t face (rainbow-delimiters-depth-1-face)) 232 234 (fontified t) 234 235 (fontified t face (rainbow-delimiters-depth-1-face)) 235 254 (fontified t) 254 255 (fontified t face (rainbow-delimiters-depth-1-face)) 255 257 (fontified t) 257 258 (fontified t face (rainbow-delimiters-depth-1-face)) 258 260 (fontified t) 260 266 (fontified t face font-lock-keyword-face) 266 278 (fontified t) 278 280 (fontified t face font-lock-keyword-face) 280 285 (fontified t) 285 291 (fontified t face font-lock-keyword-face) 291 310 (fontified t) 310 312 (fontified t face font-lock-keyword-face) 312 324 (fontified t) 324 325 (fontified t face (rainbow-delimiters-depth-1-face)) 325 331 (fontified t face font-lock-string-face) 331 345 (fontified t) 345 346 (fontified t face (rainbow-delimiters-depth-1-face)) 346 353 (fontified t) 353 354 (fontified t face (rainbow-delimiters-depth-1-face)) 354 361 (fontified t face font-lock-string-face) 361 375 (fontified t) 375 376 (fontified t face (rainbow-delimiters-depth-1-face)) 376 383 (fontified t) 383 384 (fontified t face (rainbow-delimiters-depth-1-face)) 384 391 (fontified t face font-lock-string-face) 391 405 (fontified t) 405 406 (fontified t face (rainbow-delimiters-depth-1-face)) 406 409 (fontified t) 409 416 (fontified t face font-lock-variable-name-face) 416 422 (fontified t) 422 428 (fontified t face font-lock-variable-name-face) 428 451 (fontified t) 451 452 (fontified t face (rainbow-delimiters-depth-1-face)) 452 470 (fontified t) 470 471 (fontified t face (rainbow-delimiters-depth-1-face)) 471 472 (fontified t) 472 479 (fontified t face font-lock-variable-name-face) 479 481 (fontified t) 481 488 (fontified t face font-lock-variable-name-face) 488 497 (fontified t) 497 498 (fontified t face (rainbow-delimiters-depth-1-face)) 498 513 (fontified t) 513 514 (fontified t face (rainbow-delimiters-depth-1-face)) 514 522 (fontified t) 522 523 (fontified t face (rainbow-delimiters-depth-1-face)) 523 529 (fontified t) 529 532 (fontified t) 532 533 (fontified t face (rainbow-delimiters-depth-1-face)) 533 534 (fontified t) 534 541 (fontified t face font-lock-variable-name-face) 541 543 (fontified t) 543 550 (fontified t face font-lock-variable-name-face) 550 552 (fontified t) 552 559 (fontified t) 559 560 (face (rainbow-delimiters-depth-1-face) fontified t) 560 579 (fontified t) 579 580 (face (rainbow-delimiters-depth-1-face) fontified t) 580 588 (fontified t) 588 589 (face (rainbow-delimiters-depth-1-face) fontified t) 589 602 (fontified t) 602 603 (face (rainbow-delimiters-depth-1-face) fontified t) 603 604 (fontified t) 604 610 (fontified t face font-lock-variable-name-face) 610 612 (fontified t) 612 618 (fontified t face font-lock-variable-name-face) 618 627 (fontified t) 627 628 (fontified t face (rainbow-delimiters-depth-1-face)) 628 643 (fontified t) 643 644 (fontified t face (rainbow-delimiters-depth-1-face)) 644 652 (fontified t) 652 653 (fontified t face (rainbow-delimiters-depth-1-face)) 653 662 (fontified t) 662 663 (fontified t face (rainbow-delimiters-depth-1-face)) 663 666 (fontified t) 666 668 (fontified t face font-lock-comment-delimiter-face) 668 675 (fontified t face font-lock-comment-face) 675 708 (fontified t) 708 710 (fontified t face font-lock-comment-delimiter-face) 710 717 (fontified t face font-lock-comment-face) 717 719 (fontified t) 719 722 (fontified t face font-lock-keyword-face) 722 723 (fontified t) 723 734 (fontified t face font-lock-function-name-face) 734 735 (fontified t face (rainbow-delimiters-depth-1-face)) 735 750 (fontified t) 750 754 (fontified t face font-lock-constant-face) 754 763 (fontified t) 763 767 (fontified t face font-lock-constant-face) 767 777 (fontified t) 777 782 (fontified t face font-lock-string-face) 782 792 (fontified t) 792 800 (fontified t face font-lock-string-face) 800 809 (fontified t) 809 813 (fontified t face font-lock-constant-face) 813 814 (fontified t) 814 815 (fontified t face (rainbow-delimiters-depth-1-face)) 815 829 (fontified t) 829 830 (fontified t face (rainbow-delimiters-depth-1-face)) 830 838 (fontified t) 838 842 (fontified t face font-lock-string-face) 842 843 (fontified t face (rainbow-delimiters-depth-1-face)) 843 848 (fontified t) 848 850 (fontified t face font-lock-keyword-face) 850 853 (fontified t) 853 855 (fontified t face font-lock-keyword-face) 855 856 (fontified t) 856 859 (fontified t face font-lock-keyword-face) 859 860 (fontified t) 860 864 (fontified t face font-lock-constant-face) 864 882 (fontified t) 882 883 (fontified t face (rainbow-delimiters-depth-1-face)) 883 895 (fontified t) 895 899 (fontified t face font-lock-string-face) 899 907 (fontified t) 907 915 (fontified t face font-lock-string-face) 915 916 (fontified t face (rainbow-delimiters-depth-1-face)) 916 921 (fontified t) 921 923 (fontified t face font-lock-keyword-face) 923 931 (fontified t) 931 933 (fontified t face font-lock-keyword-face) 933 934 (fontified t) 934 937 (fontified t face font-lock-keyword-face) 937 938 (fontified t) 938 942 (fontified t face font-lock-constant-face) 942 960 (fontified t) 960 961 (fontified t face (rainbow-delimiters-depth-1-face)) 961 978 (fontified t) 978 982 (fontified t face font-lock-string-face) 982 1005 (fontified t) 1005 1017 (fontified t face font-lock-string-face) 1017 1018 (fontified t face (rainbow-delimiters-depth-1-face)) 1018 1031 (fontified t) 1031 1032 (fontified t face (rainbow-delimiters-depth-1-face)) 1032 1034 (fontified t face font-lock-constant-face) 1034 1036 (fontified t face font-lock-constant-face) 1036 1037 (fontified t face (rainbow-delimiters-depth-1-face)) 1037 1038 (fontified t) 1038 1042 (fontified t) 1042 1044 (fontified t face font-lock-keyword-face) 1044 1072 (fontified t) 1072 1073 (fontified t face (rainbow-delimiters-depth-1-face)) 1073 1093 (fontified t) 1093 1094 (fontified t face (rainbow-delimiters-depth-1-face)) 1094 1099 (fontified t) 1099 1101 (fontified t face font-lock-keyword-face) 1101 1104 (fontified t) 1104 1111 (fontified t)) . 1) (undo-tree-id4287 . -41687) (undo-tree-id4288 . -41687) (undo-tree-id4289 . 41636) (undo-tree-id4290 . -409) (undo-tree-id4291 . -409) (undo-tree-id4292 . -409) (undo-tree-id4293 . -409) (undo-tree-id4294 . -409) (undo-tree-id4295 . -409) (undo-tree-id4296 . -409) (undo-tree-id4297 . -409) (undo-tree-id4298 . -409) (undo-tree-id4299 . -409) (undo-tree-id4300 . -409) (undo-tree-id4301 . -409) (undo-tree-id4302 . -409) (undo-tree-id4303 . -22) (undo-tree-id4304 . -22) (undo-tree-id4305 . -22) (undo-tree-id4306 . -22) (undo-tree-id4307 . -22) (undo-tree-id4308 . -22) (undo-tree-id4309 . -22) (undo-tree-id4310 . -22) (undo-tree-id4311 . -22) (undo-tree-id4312 . -22) (undo-tree-id4313 . -22) (undo-tree-id4314 . -22) (undo-tree-id4315 . -22) (undo-tree-id4316 . -22) (undo-tree-id4317 . -22) (undo-tree-id4318 . -22) (undo-tree-id4319 . -22) (undo-tree-id4320 . -22) (undo-tree-id4321 . -22) (undo-tree-id4322 . -22) (undo-tree-id4323 . -22) (undo-tree-id4324 . -22) (undo-tree-id4325 . -22) (undo-tree-id4326 . -22) (undo-tree-id4327 . -22) (undo-tree-id4328 . -22) (undo-tree-id4329 . -23) (undo-tree-id4330 . -23) (undo-tree-id4331 . -23) (undo-tree-id4332 . -23) (undo-tree-id4333 . -23) (undo-tree-id4334 . -23) (undo-tree-id4335 . -23) (undo-tree-id4336 . -23) (undo-tree-id4337 . -23) (undo-tree-id4338 . -23) (undo-tree-id4339 . -23) (undo-tree-id4340 . -52) (undo-tree-id4341 . -58) (undo-tree-id4342 . -260) (undo-tree-id4343 . -266) (undo-tree-id4344 . -285) (undo-tree-id4345 . -291) (undo-tree-id4346 . -431) (undo-tree-id4347 . -451) (undo-tree-id4348 . -1596) (undo-tree-id4349 . -1604) (undo-tree-id4350 . -1717) (undo-tree-id4351 . -1726) (undo-tree-id4352 . -2475) (undo-tree-id4353 . -2482) (undo-tree-id4354 . -2742) (undo-tree-id4355 . -2746) (undo-tree-id4356 . -3316) (undo-tree-id4357 . -3317) (undo-tree-id4358 . -3499) (undo-tree-id4359 . -3506) (undo-tree-id4360 . -3963) (undo-tree-id4361 . -3964) (undo-tree-id4362 . -4188) (undo-tree-id4363 . -4195) (undo-tree-id4364 . -4702) (undo-tree-id4365 . -4703) (undo-tree-id4366 . -4900) (undo-tree-id4367 . -4907) (undo-tree-id4368 . -5302) (undo-tree-id4369 . -5305) (undo-tree-id4370 . -5316) (undo-tree-id4371 . -5336) (undo-tree-id4372 . -5826) (undo-tree-id4373 . -5832) (undo-tree-id4374 . -6107) (undo-tree-id4375 . -6115) (undo-tree-id4376 . -6227) (undo-tree-id4377 . -6237) (undo-tree-id4378 . -6331) (undo-tree-id4379 . -6351) (undo-tree-id4380 . -6995) (undo-tree-id4381 . -7001) (undo-tree-id4382 . -7484) (undo-tree-id4383 . -7491) (undo-tree-id4384 . -7738) (undo-tree-id4385 . -7739) (undo-tree-id4386 . -7937) (undo-tree-id4387 . -7944) (undo-tree-id4388 . -7990) (undo-tree-id4389 . -8010) (undo-tree-id4390 . -8273) (undo-tree-id4391 . -8277) (undo-tree-id4392 . -8699) (undo-tree-id4393 . -8719) (undo-tree-id4394 . -8968) (undo-tree-id4395 . -8969) (undo-tree-id4396 . -9274) (undo-tree-id4397 . -9275) (undo-tree-id4398 . -9723) (undo-tree-id4399 . -9730) (undo-tree-id4400 . -9776) (undo-tree-id4401 . -9796) (undo-tree-id4402 . -10191) (undo-tree-id4403 . -10192) (undo-tree-id4404 . -10559) (undo-tree-id4405 . -10566) (undo-tree-id4406 . -10614) (undo-tree-id4407 . -10618) (undo-tree-id4408 . -10962) (undo-tree-id4409 . -10966) (undo-tree-id4410 . -12044) (undo-tree-id4411 . -12051) (undo-tree-id4412 . -12598) (undo-tree-id4413 . -12599) (undo-tree-id4414 . -13529) (undo-tree-id4415 . -13530) (undo-tree-id4416 . -13811) (undo-tree-id4417 . -13818) (undo-tree-id4418 . -14279) (undo-tree-id4419 . -14286) (undo-tree-id4420 . -14479) (undo-tree-id4421 . -14499) (undo-tree-id4422 . -15144) (undo-tree-id4423 . -15151) (undo-tree-id4424 . -15344) (undo-tree-id4425 . -15364) (undo-tree-id4426 . -16473) (undo-tree-id4427 . -16474) (undo-tree-id4428 . -16845) (undo-tree-id4429 . -16846) (undo-tree-id4430 . -17938) (undo-tree-id4431 . -17945) (undo-tree-id4432 . -18028) (undo-tree-id4433 . -18033) (undo-tree-id4434 . -18807) (undo-tree-id4435 . -18820) (undo-tree-id4436 . -19726) (undo-tree-id4437 . -19727) (undo-tree-id4438 . -19954) (undo-tree-id4439 . -19961) (undo-tree-id4440 . -20045) (undo-tree-id4441 . -20046) (undo-tree-id4442 . -20623) (undo-tree-id4443 . -20625) (undo-tree-id4444 . -20727) (undo-tree-id4445 . -20730) (undo-tree-id4446 . -21204) (undo-tree-id4447 . -21211) (undo-tree-id4448 . -21344) (undo-tree-id4449 . -21352) (undo-tree-id4450 . -21438) (undo-tree-id4451 . -21439) (undo-tree-id4452 . -22715) (undo-tree-id4453 . -22729) (undo-tree-id4454 . -24809) (undo-tree-id4455 . -24815) (undo-tree-id4456 . -25829) (undo-tree-id4457 . -25846) (undo-tree-id4458 . -26262) (undo-tree-id4459 . -26263) (undo-tree-id4460 . -26706) (undo-tree-id4461 . -26711) (undo-tree-id4462 . -28165) (undo-tree-id4463 . -28171) (undo-tree-id4464 . -28538) (undo-tree-id4465 . -28541) (undo-tree-id4466 . -28930) (undo-tree-id4467 . -28940) (undo-tree-id4468 . -29124) (undo-tree-id4469 . -29128) (undo-tree-id4470 . -30344) (undo-tree-id4471 . -30345) (undo-tree-id4472 . -30649) (undo-tree-id4473 . -30653) (undo-tree-id4474 . -30907) (undo-tree-id4475 . -30914) (undo-tree-id4476 . -30957) (undo-tree-id4477 . -30964) (undo-tree-id4478 . -31208) (undo-tree-id4479 . -31211) (undo-tree-id4480 . -32058) (undo-tree-id4481 . -32068) (undo-tree-id4482 . -32286) (undo-tree-id4483 . -32291) (undo-tree-id4484 . -32728) (undo-tree-id4485 . -32734) (undo-tree-id4486 . -33182) (undo-tree-id4487 . -33186) (undo-tree-id4488 . -34002) (undo-tree-id4489 . -34007) (undo-tree-id4490 . -34732) (undo-tree-id4491 . -34740) (undo-tree-id4492 . -35040) (undo-tree-id4493 . -35044) (undo-tree-id4494 . -35502) (undo-tree-id4495 . -35506) (undo-tree-id4496 . -35650) (undo-tree-id4497 . -35663) (undo-tree-id4498 . -35817) (undo-tree-id4499 . -35830) (undo-tree-id4500 . -35984) (undo-tree-id4501 . -35997) (undo-tree-id4502 . -36403) (undo-tree-id4503 . -36411) (undo-tree-id4504 . -36555) (undo-tree-id4505 . -36560) (undo-tree-id4506 . -36853) (undo-tree-id4507 . -36854) (undo-tree-id4508 . -37068) (undo-tree-id4509 . -37069) (undo-tree-id4510 . -37361) (undo-tree-id4511 . -37362) (undo-tree-id4512 . -37699) (undo-tree-id4513 . -37701) (undo-tree-id4514 . -38374) (undo-tree-id4515 . -38375) (undo-tree-id4516 . -38631) (undo-tree-id4517 . -38639) (undo-tree-id4518 . -38921) (undo-tree-id4519 . -38926) (undo-tree-id4520 . -39347) (undo-tree-id4521 . -39354) (undo-tree-id4522 . -40626) (undo-tree-id4523 . -40629) (undo-tree-id4524 . -40906) (undo-tree-id4525 . -40919) (undo-tree-id4526 . -41049) (undo-tree-id4527 . -41050) (undo-tree-id4528 . -41205) (undo-tree-id4529 . -41206) (undo-tree-id4530 . -41368) (undo-tree-id4531 . -41369) (undo-tree-id4532 . -41509) (undo-tree-id4533 . -41517) (undo-tree-id4534 . -23) (undo-tree-id4535 . -23) (undo-tree-id4536 . -23) (undo-tree-id4537 . -23) (undo-tree-id4538 . -23) (undo-tree-id4539 . -23) (undo-tree-id4540 . -23) (undo-tree-id4541 . -23) (undo-tree-id4542 . -23) (undo-tree-id4543 . -23) (undo-tree-id4544 . -318) (undo-tree-id4545 . -318) (undo-tree-id4546 . -347) (undo-tree-id4547 . -347) (undo-tree-id4548 . -377) (undo-tree-id4549 . -377) (undo-tree-id4550 . -719) (undo-tree-id4551 . -719) (undo-tree-id4552 . -719) (undo-tree-id4553 . -719) (undo-tree-id4554 . -719) (undo-tree-id4555 . -719) (undo-tree-id4556 . -821) (undo-tree-id4557 . -821) (undo-tree-id4558 . -874) (undo-tree-id4559 . -874) (undo-tree-id4560 . -874) (undo-tree-id4561 . -874) (undo-tree-id4562 . -952) (undo-tree-id4563 . -952) (undo-tree-id4564 . -952) (undo-tree-id4565 . -952) (undo-tree-id4566 . -23) (undo-tree-id4567 . -23) (undo-tree-id4568 . -23) (undo-tree-id4569 . -23) (undo-tree-id4570 . -23) (undo-tree-id4571 . -23) (undo-tree-id4572 . -23) (undo-tree-id4573 . -23) (undo-tree-id4574 . -23) (undo-tree-id4575 . -24) (undo-tree-id4576 . -24) (undo-tree-id4577 . -24) (undo-tree-id4578 . -24) (undo-tree-id4579 . -24) (undo-tree-id4580 . -24) (undo-tree-id4581 . -24) (undo-tree-id4582 . -24) (undo-tree-id4583 . -24) (undo-tree-id4584 . -24) (undo-tree-id4585 . -24) (undo-tree-id4586 . -24) (undo-tree-id4587 . -24) (undo-tree-id4588 . -24) (undo-tree-id4589 . -24) (undo-tree-id4590 . -24) (undo-tree-id4591 . -24) (undo-tree-id4592 . -24) (undo-tree-id4593 . -24) (undo-tree-id4594 . -24) (undo-tree-id4595 . -24) (undo-tree-id4596 . -24) (undo-tree-id4597 . -24) (undo-tree-id4598 . -24) (undo-tree-id4599 . -24) (undo-tree-id4600 . -24) (undo-tree-id4601 . -24) (undo-tree-id4602 . -24) (undo-tree-id4603 . -24) (undo-tree-id4604 . -24) (undo-tree-id4605 . -24) (undo-tree-id4606 . -24) (undo-tree-id4607 . -24) (undo-tree-id4608 . -24) (undo-tree-id4609 . -24) (undo-tree-id4610 . -24) (undo-tree-id4611 . -24) (undo-tree-id4612 . -24) (undo-tree-id4613 . -24) (undo-tree-id4614 . -24) (undo-tree-id4615 . -25) (undo-tree-id4616 . -25) (undo-tree-id4617 . -25) (undo-tree-id4618 . -25) (undo-tree-id4619 . -25) (undo-tree-id4620 . -25) (undo-tree-id4621 . -25) (undo-tree-id4622 . -25) (undo-tree-id4623 . -25) (undo-tree-id4624 . -25) (undo-tree-id4625 . -25) (undo-tree-id4626 . -25) (undo-tree-id4627 . -25) (undo-tree-id4628 . -25) (undo-tree-id4629 . -25) (undo-tree-id4630 . -25) (undo-tree-id4631 . -25) (undo-tree-id4632 . -25) (undo-tree-id4633 . -25) (undo-tree-id4634 . -318) (undo-tree-id4635 . -318) (undo-tree-id4636 . -347) (undo-tree-id4637 . -347) (undo-tree-id4638 . -377) (undo-tree-id4639 . -377) (undo-tree-id4640 . -719) (undo-tree-id4641 . -719) (undo-tree-id4642 . -719) (undo-tree-id4643 . -719) (undo-tree-id4644 . -719) (undo-tree-id4645 . -719) (undo-tree-id4646 . -821) (undo-tree-id4647 . -821) (undo-tree-id4648 . -874) (undo-tree-id4649 . -874) (undo-tree-id4650 . -874) (undo-tree-id4651 . -874) (undo-tree-id4652 . -952) (undo-tree-id4653 . -952) (undo-tree-id4654 . -952) (undo-tree-id4655 . -952) (undo-tree-id4656 . -25) (undo-tree-id4657 . -25) (undo-tree-id4658 . -25) (undo-tree-id4659 . -25) (undo-tree-id4660 . -25) (undo-tree-id4661 . -25) (undo-tree-id4662 . -25) (undo-tree-id4663 . -25) (undo-tree-id4664 . -25) (undo-tree-id4665 . -25) (undo-tree-id4666 . -25) (undo-tree-id4667 . -25) (undo-tree-id4668 . -25) (undo-tree-id4669 . -25) (undo-tree-id4670 . -25) (undo-tree-id4671 . -25) (undo-tree-id4672 . -26) (undo-tree-id4673 . -26) (undo-tree-id4674 . -26) (undo-tree-id4675 . -26) (undo-tree-id4676 . -26) (undo-tree-id4677 . -26) (undo-tree-id4678 . -26) (undo-tree-id4679 . -26) (undo-tree-id4680 . -26) (undo-tree-id4681 . -26) (undo-tree-id4682 . -26) (undo-tree-id4683 . -26) (undo-tree-id4684 . -26) (undo-tree-id4685 . -26) (undo-tree-id4686 . -26) (undo-tree-id4687 . -26) (undo-tree-id4688 . -26) (undo-tree-id4689 . -27) (undo-tree-id4690 . -27) (undo-tree-id4691 . -27) (undo-tree-id4692 . -27) (undo-tree-id4693 . -27) (undo-tree-id4694 . -27) (undo-tree-id4695 . -27) (undo-tree-id4696 . -27) (undo-tree-id4697 . -27) (undo-tree-id4698 . -27) (undo-tree-id4699 . -27) (undo-tree-id4700 . -27) (undo-tree-id4701 . -27) (undo-tree-id4702 . -27) (undo-tree-id4703 . -27) (undo-tree-id4704 . -27) (undo-tree-id4705 . -27) (undo-tree-id4706 . -27) (undo-tree-id4707 . -318) (undo-tree-id4708 . -318) (undo-tree-id4709 . -347) (undo-tree-id4710 . -347) (undo-tree-id4711 . -377) (undo-tree-id4712 . -377) (undo-tree-id4713 . -719) (undo-tree-id4714 . -719) (undo-tree-id4715 . -719) (undo-tree-id4716 . -719) (undo-tree-id4717 . -719) (undo-tree-id4718 . -719) (undo-tree-id4719 . -821) (undo-tree-id4720 . -821) (undo-tree-id4721 . -874) (undo-tree-id4722 . -874) (undo-tree-id4723 . -874) (undo-tree-id4724 . -874) (undo-tree-id4725 . -952) (undo-tree-id4726 . -952) (undo-tree-id4727 . -952) (undo-tree-id4728 . -952) (undo-tree-id4729 . -27) (undo-tree-id4730 . -27) (undo-tree-id4731 . -27) (undo-tree-id4732 . -27) (undo-tree-id4733 . -27) (undo-tree-id4734 . -27) (undo-tree-id4735 . -27) (undo-tree-id4736 . -27) (undo-tree-id4737 . -27) (undo-tree-id4738 . -27) (undo-tree-id4739 . -27) (undo-tree-id4740 . -27) (undo-tree-id4741 . -27) (undo-tree-id4742 . -27) (undo-tree-id4743 . -27) (undo-tree-id4744 . -27) (undo-tree-id4745 . -27) (undo-tree-id4746 . -27) (undo-tree-id4747 . -27) (undo-tree-id4748 . -28) (undo-tree-id4749 . -28) (undo-tree-id4750 . -28) (undo-tree-id4751 . -28) (undo-tree-id4752 . -28) (undo-tree-id4753 . -28) (undo-tree-id4754 . -28) (undo-tree-id4755 . -28) (undo-tree-id4756 . -28) (undo-tree-id4757 . -28) (undo-tree-id4758 . -28) (undo-tree-id4759 . -28) (undo-tree-id4760 . -28) (undo-tree-id4761 . -28) (undo-tree-id4762 . -28) (undo-tree-id4763 . -28) (undo-tree-id4764 . -28) (undo-tree-id4765 . -28) (undo-tree-id4766 . -28) (undo-tree-id4767 . -28) (undo-tree-id4768 . -28) (undo-tree-id4769 . -28) (undo-tree-id4770 . -28) (undo-tree-id4771 . -28) (undo-tree-id4772 . -28) (undo-tree-id4773 . -28) (undo-tree-id4774 . -28) (undo-tree-id4775 . -28) (undo-tree-id4776 . -28) (undo-tree-id4777 . -28) (undo-tree-id4778 . -28) (undo-tree-id4779 . -28) (undo-tree-id4780 . -28) (undo-tree-id4781 . -28) (undo-tree-id4782 . -28) (undo-tree-id4783 . -28) (undo-tree-id4784 . -28) (undo-tree-id4785 . -28) (undo-tree-id4786 . -28) (undo-tree-id4787 . -28) (undo-tree-id4788 . -28) (undo-tree-id4789 . -28) (undo-tree-id4790 . -28) (undo-tree-id4791 . -28) (undo-tree-id4792 . -28) (undo-tree-id4793 . -28) (undo-tree-id4794 . -28) (undo-tree-id4795 . -28) (undo-tree-id4796 . -28) (undo-tree-id4797 . -28) (undo-tree-id4798 . -28) (undo-tree-id4799 . -28) (undo-tree-id4800 . -28) (undo-tree-id4801 . -28) (undo-tree-id4802 . -28) (undo-tree-id4803 . -28) (undo-tree-id4804 . -28) (undo-tree-id4805 . -28) (undo-tree-id4806 . -28) (undo-tree-id4807 . -28) (undo-tree-id4808 . -28) (undo-tree-id4809 . -28) (undo-tree-id4810 . -28) (undo-tree-id4811 . -28) (undo-tree-id4812 . -28) (undo-tree-id4813 . -28) (undo-tree-id4814 . -28) (undo-tree-id4815 . -28) (undo-tree-id4816 . -28) (undo-tree-id4817 . -28) (undo-tree-id4818 . -28) (undo-tree-id4819 . -28) (undo-tree-id4820 . -28) (undo-tree-id4821 . -28) (undo-tree-id4822 . -28) (undo-tree-id4823 . -28) (undo-tree-id4824 . -28) (undo-tree-id4825 . -28) (undo-tree-id4826 . -28) (undo-tree-id4827 . -28) (undo-tree-id4828 . -28) (undo-tree-id4829 . -28) (undo-tree-id4830 . -28) (undo-tree-id4831 . -28) (undo-tree-id4832 . -28) (undo-tree-id4833 . -28) (undo-tree-id4834 . -28) (undo-tree-id4835 . -28) (undo-tree-id4836 . -28) (undo-tree-id4837 . -28) (undo-tree-id4838 . -28) (undo-tree-id4839 . -28) (undo-tree-id4840 . -28) (undo-tree-id4841 . -28) (undo-tree-id4842 . -28) (undo-tree-id4843 . -28) (undo-tree-id4844 . -28) (undo-tree-id4845 . -28) (undo-tree-id4846 . -28) (undo-tree-id4847 . -28) (undo-tree-id4848 . -28) (undo-tree-id4849 . -28) (undo-tree-id4850 . -28) (undo-tree-id4851 . -28) (undo-tree-id4852 . -28) (undo-tree-id4853 . -28) (undo-tree-id4854 . -28) (undo-tree-id4855 . -28) (undo-tree-id4856 . -28) (undo-tree-id4857 . -28) (undo-tree-id4858 . -28) (undo-tree-id4859 . -28) (undo-tree-id4860 . -28) (undo-tree-id4861 . -28) (undo-tree-id4862 . -28) (undo-tree-id4863 . -28) (undo-tree-id4864 . -28) (undo-tree-id4865 . -28) (undo-tree-id4866 . -28) (undo-tree-id4867 . -28) (undo-tree-id4868 . -28) (undo-tree-id4869 . -28) (undo-tree-id4870 . -28) (undo-tree-id4871 . -28) (undo-tree-id4872 . -28) (undo-tree-id4873 . -28) (undo-tree-id4874 . -28) (undo-tree-id4875 . -28) (undo-tree-id4876 . -28) (undo-tree-id4877 . -28) (undo-tree-id4878 . -28) (undo-tree-id4879 . -28) (undo-tree-id4880 . -28) (undo-tree-id4881 . -28) (undo-tree-id4882 . -28) (undo-tree-id4883 . -28) (undo-tree-id4884 . -28) (undo-tree-id4885 . -28) (undo-tree-id4886 . -28) (undo-tree-id4887 . -28) (undo-tree-id4888 . -28) (undo-tree-id4889 . -28) (undo-tree-id4890 . -28) (undo-tree-id4891 . -28) (undo-tree-id4892 . -41) (undo-tree-id4893 . -41) (undo-tree-id4894 . -41) (undo-tree-id4895 . -41) (undo-tree-id4896 . -41) (undo-tree-id4897 . -41) (undo-tree-id4898 . -41) (undo-tree-id4899 . -41) (undo-tree-id4900 . -41) (undo-tree-id4901 . -41) (undo-tree-id4902 . -42) (undo-tree-id4903 . -42) (undo-tree-id4904 . -42) (undo-tree-id4905 . -42) (undo-tree-id4906 . -42) (undo-tree-id4907 . -42) (undo-tree-id4908 . -42) (undo-tree-id4909 . -42) (undo-tree-id4910 . -42) (undo-tree-id4911 . -42) (undo-tree-id4912 . -42) (undo-tree-id4913 . -42) (undo-tree-id4914 . -42) (undo-tree-id4915 . -42) (undo-tree-id4916 . -42) (undo-tree-id4917 . -42) (undo-tree-id4918 . -42) (undo-tree-id4919 . -42) (undo-tree-id4920 . -42) (undo-tree-id4921 . -42) (undo-tree-id4922 . -42) (undo-tree-id4923 . -42) (undo-tree-id4924 . -42) (undo-tree-id4925 . -42) (undo-tree-id4926 . -42) (undo-tree-id4927 . -42) (undo-tree-id4928 . -42) (undo-tree-id4929 . -42) (undo-tree-id4930 . -42) (undo-tree-id4931 . -42) (undo-tree-id4932 . -42) (undo-tree-id4933 . -42) (undo-tree-id4934 . -42) (undo-tree-id4935 . -42) (undo-tree-id4936 . -42) (undo-tree-id4937 . -42) (undo-tree-id4938 . -42) (undo-tree-id4939 . -42) (undo-tree-id4940 . -42) (undo-tree-id4941 . -42) (undo-tree-id4942 . -42) (undo-tree-id4943 . -42) (undo-tree-id4944 . -42) (undo-tree-id4945 . -42) (undo-tree-id4946 . -42) (undo-tree-id4947 . -42) (undo-tree-id4948 . -42) (undo-tree-id4949 . -42) (undo-tree-id4950 . -42) (undo-tree-id4951 . -42) (undo-tree-id4952 . -42) (undo-tree-id4953 . -42) (undo-tree-id4954 . -42) (undo-tree-id4955 . -42) (undo-tree-id4956 . -42) (undo-tree-id4957 . -42) (undo-tree-id4958 . -42) (undo-tree-id4959 . -42) (undo-tree-id4960 . -42) (undo-tree-id4961 . -42) (undo-tree-id4962 . -42) (undo-tree-id4963 . -42) (undo-tree-id4964 . -42) (undo-tree-id4965 . -42) (undo-tree-id4966 . -42) (undo-tree-id4967 . -42) (undo-tree-id4968 . -42) (undo-tree-id4969 . -42) (undo-tree-id4970 . -42) (undo-tree-id4971 . -42) (undo-tree-id4972 . -42) (undo-tree-id4973 . -42) (undo-tree-id4974 . -42) (undo-tree-id4975 . -42) (undo-tree-id4976 . -42) (undo-tree-id4977 . -318) (undo-tree-id4978 . -318) (undo-tree-id4979 . -347) (undo-tree-id4980 . -347) (undo-tree-id4981 . -377) (undo-tree-id4982 . -377) (undo-tree-id4983 . -719) (undo-tree-id4984 . -719) (undo-tree-id4985 . -719) (undo-tree-id4986 . -719) (undo-tree-id4987 . -719) (undo-tree-id4988 . -719) (undo-tree-id4989 . -821) (undo-tree-id4990 . -821) (undo-tree-id4991 . -874) (undo-tree-id4992 . -874) (undo-tree-id4993 . -874) (undo-tree-id4994 . -874) (undo-tree-id4995 . -952) (undo-tree-id4996 . -952) (undo-tree-id4997 . -952) (undo-tree-id4998 . -952) (undo-tree-id4999 . -42) (undo-tree-id5000 . -42) (undo-tree-id5001 . -42) (undo-tree-id5002 . -42) (undo-tree-id5003 . -42) (undo-tree-id5004 . -42) (undo-tree-id5005 . -42) (undo-tree-id5006 . -42) (undo-tree-id5007 . -42) (undo-tree-id5008 . -48) (undo-tree-id5009 . -48) (undo-tree-id5010 . -48) (undo-tree-id5011 . -48) (undo-tree-id5012 . -48) (undo-tree-id5013 . -48) (undo-tree-id5014 . -48) (undo-tree-id5015 . -48) (undo-tree-id5016 . -48) (undo-tree-id5017 . -48) (undo-tree-id5018 . -48) (undo-tree-id5019 . -48) (undo-tree-id5020 . -48) (undo-tree-id5021 . -48) (undo-tree-id5022 . -48) (undo-tree-id5023 . -48) (undo-tree-id5024 . -48) (undo-tree-id5025 . -48) (undo-tree-id5026 . -48) (undo-tree-id5027 . -49) (undo-tree-id5028 . -49) (undo-tree-id5029 . -49) (undo-tree-id5030 . -49) (undo-tree-id5031 . -49) (undo-tree-id5032 . -49) (undo-tree-id5033 . -49) (undo-tree-id5034 . -49) (undo-tree-id5035 . -49) (undo-tree-id5036 . -318) (undo-tree-id5037 . -318) (undo-tree-id5038 . -347) (undo-tree-id5039 . -347) (undo-tree-id5040 . -377) (undo-tree-id5041 . -377) (undo-tree-id5042 . -719) (undo-tree-id5043 . -719) (undo-tree-id5044 . -719) (undo-tree-id5045 . -719) (undo-tree-id5046 . -719) (undo-tree-id5047 . -719) (undo-tree-id5048 . -821) (undo-tree-id5049 . -821) (undo-tree-id5050 . -874) (undo-tree-id5051 . -874) (undo-tree-id5052 . -874) (undo-tree-id5053 . -874) (undo-tree-id5054 . -952) (undo-tree-id5055 . -952) (undo-tree-id5056 . -952) (undo-tree-id5057 . -952) (undo-tree-id5058 . -49) (undo-tree-id5059 . -49) (undo-tree-id5060 . -49) (undo-tree-id5061 . -49) (undo-tree-id5062 . -49) (undo-tree-id5063 . -49) (undo-tree-id5064 . -49) (undo-tree-id5065 . -49) (undo-tree-id5066 . -49) (undo-tree-id5067 . -50) (undo-tree-id5068 . -50) (undo-tree-id5069 . -50) (undo-tree-id5070 . -50) (undo-tree-id5071 . -50) (undo-tree-id5072 . -50) (undo-tree-id5073 . -50) (undo-tree-id5074 . -50) (undo-tree-id5075 . -50) (undo-tree-id5076 . -50) (undo-tree-id5077 . -50) (undo-tree-id5078 . -50) (undo-tree-id5079 . -50) (undo-tree-id5080 . -50) (undo-tree-id5081 . -50) (undo-tree-id5082 . -50) (undo-tree-id5083 . -50) (undo-tree-id5084 . -50) (undo-tree-id5085 . -50) (undo-tree-id5086 . -50) (undo-tree-id5087 . -50) (undo-tree-id5088 . -50) (undo-tree-id5089 . -50) (undo-tree-id5090 . -50) (undo-tree-id5091 . -50) (undo-tree-id5092 . -50) (undo-tree-id5093 . -50) (undo-tree-id5094 . -51) (undo-tree-id5095 . -51) (undo-tree-id5096 . -51) (undo-tree-id5097 . -51) (undo-tree-id5098 . -51) (undo-tree-id5099 . -51) (undo-tree-id5100 . -51) (undo-tree-id5101 . -51) (undo-tree-id5102 . -51) (undo-tree-id5103 . -50) (undo-tree-id5104 . -50) (undo-tree-id5105 . -50) (undo-tree-id5106 . -50) (undo-tree-id5107 . -50) (undo-tree-id5108 . -50) (undo-tree-id5109 . -50) (undo-tree-id5110 . -50) (undo-tree-id5111 . -50) (undo-tree-id5112 . -23) (undo-tree-id5113 . -50) (undo-tree-id5114 . -50) (undo-tree-id5115 . -50) (undo-tree-id5116 . -50) (undo-tree-id5117 . -50) (undo-tree-id5118 . -50) (undo-tree-id5119 . -50) (undo-tree-id5120 . -50) (undo-tree-id5121 . -50) (undo-tree-id5122 . -50) (undo-tree-id5123 . -318) (undo-tree-id5124 . -318) (undo-tree-id5125 . -347) (undo-tree-id5126 . -347) (undo-tree-id5127 . -377) (undo-tree-id5128 . -377) (undo-tree-id5129 . -719) (undo-tree-id5130 . -719) (undo-tree-id5131 . -719) (undo-tree-id5132 . -719) (undo-tree-id5133 . -719) (undo-tree-id5134 . -719) (undo-tree-id5135 . -821) (undo-tree-id5136 . -821) (undo-tree-id5137 . -874) (undo-tree-id5138 . -874) (undo-tree-id5139 . -874) (undo-tree-id5140 . -874) (undo-tree-id5141 . -952) (undo-tree-id5142 . -952) (undo-tree-id5143 . -952) (undo-tree-id5144 . -952) (undo-tree-id5145 . -50) (undo-tree-id5146 . -50) (undo-tree-id5147 . -50) (undo-tree-id5148 . -50) (undo-tree-id5149 . -50) (undo-tree-id5150 . -50) (undo-tree-id5151 . -50) (undo-tree-id5152 . -50) (undo-tree-id5153 . -50) (undo-tree-id5154 . -50) (undo-tree-id5155 . -50) (undo-tree-id5156 . -50) (undo-tree-id5157 . -50) (undo-tree-id5158 . -50) (undo-tree-id5159 . -50) (undo-tree-id5160 . -50) (undo-tree-id5161 . -50) (undo-tree-id5162 . -50) (undo-tree-id5163 . -50) (undo-tree-id5164 . -50) (undo-tree-id5165 . -50) (undo-tree-id5166 . -50) (undo-tree-id5167 . -50) (undo-tree-id5168 . -50) (undo-tree-id5169 . -50) (undo-tree-id5170 . -50) (undo-tree-id5171 . -50) (undo-tree-id5172 . -50) (undo-tree-id5173 . -50) (undo-tree-id5174 . -50) (undo-tree-id5175 . -50) (undo-tree-id5176 . -50) (undo-tree-id5177 . -50) (undo-tree-id5178 . -50)) nil (25760 29866 871867 690000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 665) (undo-tree-id7361 . -1) (t 25760 29866 887275 529000)) nil (25760 29891 498424 246000) 0 nil])
([nil nil ((#("# In[4]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 665) (undo-tree-id7358 . -8) (undo-tree-id7359 . -8) (undo-tree-id7360 . -9)) nil (25760 29891 498422 591000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 665) (undo-tree-id7357 . -1)) nil (25760 29891 498420 127000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 665) (undo-tree-id7356 . -1)) nil (25760 29891 498418 747000) 0 nil])
([nil nil ((#("# In[5]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 9 (fontified t face font-lock-comment-face)) . 696) (undo-tree-id7354 . -8) (undo-tree-id7355 . -9)) nil (25760 29891 498417 303000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 696) (undo-tree-id7353 . -1)) nil (25760 29891 498415 370000) 0 nil])
([nil nil ((#("
def plot_series(
    series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True
):
    plt.plot(series, \".-\")
    if y is not None:
        plt.plot(n_steps, y, \"bo\", label=\"Target\")
    if y_pred is not None:
        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=\"upper left\")
" 0 1 (fontified t) 1 4 (fontified t face font-lock-keyword-face) 4 5 (fontified t) 5 16 (fontified t face font-lock-function-name-face) 16 17 (fontified t face (rainbow-delimiters-depth-1-face)) 17 32 (fontified t) 32 36 (fontified t face font-lock-constant-face) 36 45 (fontified t) 45 49 (fontified t face font-lock-constant-face) 49 59 (fontified t) 59 64 (fontified t face font-lock-string-face) 64 74 (fontified t) 74 82 (fontified t face font-lock-string-face) 82 91 (fontified t) 91 95 (fontified t face font-lock-constant-face) 95 96 (fontified t) 96 97 (fontified t face (rainbow-delimiters-depth-1-face)) 97 111 (fontified t) 111 112 (fontified t face (rainbow-delimiters-depth-1-face)) 112 120 (fontified t) 120 124 (fontified t face font-lock-string-face) 124 125 (fontified t face (rainbow-delimiters-depth-1-face)) 125 130 (fontified t) 130 132 (fontified t face font-lock-keyword-face) 132 135 (fontified t) 135 137 (fontified t face font-lock-keyword-face) 137 138 (fontified t) 138 141 (fontified t face font-lock-keyword-face) 141 142 (fontified t) 142 146 (fontified t face font-lock-constant-face) 146 164 (fontified t) 164 165 (fontified t face (rainbow-delimiters-depth-1-face)) 165 177 (fontified t) 177 181 (fontified t face font-lock-string-face) 181 189 (fontified t) 189 197 (fontified t face font-lock-string-face) 197 198 (fontified t face (rainbow-delimiters-depth-1-face)) 198 203 (fontified t) 203 205 (fontified t face font-lock-keyword-face) 205 213 (fontified t) 213 215 (fontified t face font-lock-keyword-face) 215 216 (fontified t) 216 219 (fontified t face font-lock-keyword-face) 219 220 (fontified t) 220 224 (fontified t face font-lock-constant-face) 224 242 (fontified t) 242 243 (fontified t face (rainbow-delimiters-depth-1-face)) 243 260 (fontified t) 260 264 (fontified t face font-lock-string-face) 264 287 (fontified t) 287 299 (fontified t face font-lock-string-face) 299 300 (fontified t face (rainbow-delimiters-depth-1-face)) 300 313 (fontified t) 313 314 (fontified t face (rainbow-delimiters-depth-1-face)) 314 316 (fontified t face font-lock-constant-face) 316 318 (fontified t face font-lock-constant-face) 318 319 (fontified t face (rainbow-delimiters-depth-1-face)) 319 320 (fontified t) 320 324 (fontified t) 324 326 (fontified t face font-lock-keyword-face) 326 354 (fontified t) 354 355 (fontified t face (rainbow-delimiters-depth-1-face)) 355 375 (fontified t) 375 376 (fontified t face (rainbow-delimiters-depth-1-face)) 376 381 (fontified t) 381 383 (fontified t face font-lock-keyword-face) 383 411 (fontified t) 411 412 (fontified t face (rainbow-delimiters-depth-1-face)) 412 444 (fontified t) 444 445 (fontified t face (rainbow-delimiters-depth-1-face)) 445 458 (fontified t) 458 460 (fontified t) 460 461 (fontified t face (rainbow-delimiters-depth-1-face)) 461 483 (fontified t) 483 484 (fontified t face (rainbow-delimiters-depth-1-face)) 484 485 (fontified t) 485 488 (fontified t) 488 497 (fontified t) 497 498 (fontified t face (rainbow-delimiters-depth-1-face)) 498 499 (fontified t face (rainbow-delimiters-depth-2-face)) 499 501 (fontified t) 501 520 (fontified t) 520 521 (face (rainbow-delimiters-depth-2-face) fontified t) 521 522 (face (rainbow-delimiters-depth-1-face) fontified t) 522 523 (fontified t) 523 527 (fontified t) 527 529 (fontified t face font-lock-keyword-face) 529 537 (fontified t) 537 540 (fontified t face font-lock-keyword-face) 540 541 (fontified t) 541 542 (fontified t face (rainbow-delimiters-depth-1-face)) 542 544 (fontified t) 544 546 (fontified t face font-lock-keyword-face) 546 553 (fontified t) 553 554 (fontified t face (rainbow-delimiters-depth-1-face)) 554 574 (fontified t) 574 575 (fontified t face (rainbow-delimiters-depth-1-face)) 575 592 (fontified t) 592 604 (fontified t face font-lock-string-face) 604 605 (fontified t face (rainbow-delimiters-depth-1-face)) 605 606 (fontified t)) . 696) (undo-tree-id7089 . -605) (undo-tree-id7090 . -556) (undo-tree-id7091 . -556) (undo-tree-id7092 . -556) (undo-tree-id7093 . -564) (undo-tree-id7094 . -564) (undo-tree-id7095 . -1) (undo-tree-id7096 . -1) (undo-tree-id7097 . -1) (undo-tree-id7098 . -1) (undo-tree-id7099 . -1) (undo-tree-id7100 . -1) (undo-tree-id7101 . -103) (undo-tree-id7102 . -103) (undo-tree-id7103 . -156) (undo-tree-id7104 . -156) (undo-tree-id7105 . -156) (undo-tree-id7106 . -156) (undo-tree-id7107 . -234) (undo-tree-id7108 . -234) (undo-tree-id7109 . -234) (undo-tree-id7110 . -234) (undo-tree-id7111 . -564) (undo-tree-id7112 . -564) (undo-tree-id7113 . -1) (undo-tree-id7114 . -1) (undo-tree-id7115 . -1) (undo-tree-id7116 . -1) (undo-tree-id7117 . -1) (undo-tree-id7118 . -1) (undo-tree-id7119 . -103) (undo-tree-id7120 . -103) (undo-tree-id7121 . -156) (undo-tree-id7122 . -156) (undo-tree-id7123 . -156) (undo-tree-id7124 . -156) (undo-tree-id7125 . -234) (undo-tree-id7126 . -234) (undo-tree-id7127 . -234) (undo-tree-id7128 . -234) (undo-tree-id7129 . -564) (undo-tree-id7130 . -564) (undo-tree-id7131 . -1) (undo-tree-id7132 . -1) (undo-tree-id7133 . -1) (undo-tree-id7134 . -1) (undo-tree-id7135 . -1) (undo-tree-id7136 . -1) (undo-tree-id7137 . -103) (undo-tree-id7138 . -103) (undo-tree-id7139 . -156) (undo-tree-id7140 . -156) (undo-tree-id7141 . -156) (undo-tree-id7142 . -156) (undo-tree-id7143 . -234) (undo-tree-id7144 . -234) (undo-tree-id7145 . -234) (undo-tree-id7146 . -234) (undo-tree-id7147 . -564) (undo-tree-id7148 . -564) (undo-tree-id7149 . -606) (undo-tree-id7150 . -556) (undo-tree-id7151 . -1) (undo-tree-id7152 . -1) (undo-tree-id7153 . -1) (undo-tree-id7154 . -1) (undo-tree-id7155 . -1) (undo-tree-id7156 . -1) (undo-tree-id7157 . -1) (undo-tree-id7158 . -1) (undo-tree-id7159 . -1) (undo-tree-id7160 . -1) (undo-tree-id7161 . -1) (undo-tree-id7162 . -1) (undo-tree-id7163 . -1) (undo-tree-id7164 . -1) (undo-tree-id7165 . -1) (undo-tree-id7166 . -1) (undo-tree-id7167 . -1) (undo-tree-id7168 . -1) (undo-tree-id7169 . -1) (undo-tree-id7170 . -1) (undo-tree-id7171 . -1) (undo-tree-id7172 . -1) (undo-tree-id7173 . -1) (undo-tree-id7174 . -1) (undo-tree-id7175 . -1) (undo-tree-id7176 . -1) (undo-tree-id7177 . -1) (undo-tree-id7178 . -18) (undo-tree-id7179 . -18) (undo-tree-id7180 . -18) (undo-tree-id7181 . -18) (undo-tree-id7182 . -18) (undo-tree-id7183 . -18) (undo-tree-id7184 . -18) (undo-tree-id7185 . -18) (undo-tree-id7186 . -18) (undo-tree-id7187 . -18) (undo-tree-id7188 . -18) (undo-tree-id7189 . -18) (undo-tree-id7190 . -18) (undo-tree-id7191 . -18) (undo-tree-id7192 . -18) (undo-tree-id7193 . -85) (undo-tree-id7194 . -85) (undo-tree-id7195 . -85) (undo-tree-id7196 . -85) (undo-tree-id7197 . -85) (undo-tree-id7198 . -85) (undo-tree-id7199 . -85) (undo-tree-id7200 . -85) (undo-tree-id7201 . -85) (undo-tree-id7202 . -85) (undo-tree-id7203 . -85) (undo-tree-id7204 . -85) (undo-tree-id7205 . -85) (undo-tree-id7206 . -85) (undo-tree-id7207 . -85) (undo-tree-id7208 . -96) (undo-tree-id7209 . -96) (undo-tree-id7210 . -96) (undo-tree-id7211 . -96) (undo-tree-id7212 . -96) (undo-tree-id7213 . -96) (undo-tree-id7214 . -96) (undo-tree-id7215 . -96) (undo-tree-id7216 . -99) (undo-tree-id7217 . -99) (undo-tree-id7218 . -99) (undo-tree-id7219 . -99) (undo-tree-id7220 . -99) (undo-tree-id7221 . -99) (undo-tree-id7222 . -99) (undo-tree-id7223 . -99) (undo-tree-id7224 . -126) (undo-tree-id7225 . -126) (undo-tree-id7226 . -126) (undo-tree-id7227 . -126) (undo-tree-id7228 . -126) (undo-tree-id7229 . -126) (undo-tree-id7230 . -126) (undo-tree-id7231 . -126) (undo-tree-id7232 . -148) (undo-tree-id7233 . -148) (undo-tree-id7234 . -148) (undo-tree-id7235 . -148) (undo-tree-id7236 . -148) (undo-tree-id7237 . -148) (undo-tree-id7238 . -148) (undo-tree-id7239 . -148) (undo-tree-id7240 . -199) (undo-tree-id7241 . -199) (undo-tree-id7242 . -199) (undo-tree-id7243 . -199) (undo-tree-id7244 . -199) (undo-tree-id7245 . -199) (undo-tree-id7246 . -199) (undo-tree-id7247 . -199) (undo-tree-id7248 . -226) (undo-tree-id7249 . -226) (undo-tree-id7250 . -226) (undo-tree-id7251 . -226) (undo-tree-id7252 . -226) (undo-tree-id7253 . -226) (undo-tree-id7254 . -226) (undo-tree-id7255 . -226) (undo-tree-id7256 . -226) (undo-tree-id7257 . -226) (undo-tree-id7258 . -226) (undo-tree-id7259 . -226) (undo-tree-id7260 . -226) (undo-tree-id7261 . -226) (undo-tree-id7262 . -226) (undo-tree-id7263 . -293) (undo-tree-id7264 . -293) (undo-tree-id7265 . -293) (undo-tree-id7266 . -293) (undo-tree-id7267 . -293) (undo-tree-id7268 . -293) (undo-tree-id7269 . -293) (undo-tree-id7270 . -293) (undo-tree-id7271 . -293) (undo-tree-id7272 . -293) (undo-tree-id7273 . -293) (undo-tree-id7274 . -293) (undo-tree-id7275 . -293) (undo-tree-id7276 . -293) (undo-tree-id7277 . -293) (undo-tree-id7278 . -301) (undo-tree-id7279 . -301) (undo-tree-id7280 . -301) (undo-tree-id7281 . -301) (undo-tree-id7282 . -301) (undo-tree-id7283 . -301) (undo-tree-id7284 . -301) (undo-tree-id7285 . -301) (undo-tree-id7286 . -320) (undo-tree-id7287 . -320) (undo-tree-id7288 . -320) (undo-tree-id7289 . -320) (undo-tree-id7290 . -320) (undo-tree-id7291 . -320) (undo-tree-id7292 . -320) (undo-tree-id7293 . -320) (undo-tree-id7294 . -336) (undo-tree-id7295 . -336) (undo-tree-id7296 . -336) (undo-tree-id7297 . -336) (undo-tree-id7298 . -336) (undo-tree-id7299 . -336) (undo-tree-id7300 . -336) (undo-tree-id7301 . -336) (undo-tree-id7302 . -377) (undo-tree-id7303 . -377) (undo-tree-id7304 . -377) (undo-tree-id7305 . -377) (undo-tree-id7306 . -377) (undo-tree-id7307 . -377) (undo-tree-id7308 . -377) (undo-tree-id7309 . -377) (undo-tree-id7310 . -393) (undo-tree-id7311 . -393) (undo-tree-id7312 . -393) (undo-tree-id7313 . -393) (undo-tree-id7314 . -393) (undo-tree-id7315 . -393) (undo-tree-id7316 . -393) (undo-tree-id7317 . -393) (undo-tree-id7318 . -446) (undo-tree-id7319 . -446) (undo-tree-id7320 . -446) (undo-tree-id7321 . -446) (undo-tree-id7322 . -446) (undo-tree-id7323 . -446) (undo-tree-id7324 . -446) (undo-tree-id7325 . -446) (undo-tree-id7326 . -485) (undo-tree-id7327 . -485) (undo-tree-id7328 . -485) (undo-tree-id7329 . -485) (undo-tree-id7330 . -485) (undo-tree-id7331 . -485) (undo-tree-id7332 . -485) (undo-tree-id7333 . -485) (undo-tree-id7334 . -523) (undo-tree-id7335 . -523) (undo-tree-id7336 . -523) (undo-tree-id7337 . -523) (undo-tree-id7338 . -523) (undo-tree-id7339 . -523) (undo-tree-id7340 . -523) (undo-tree-id7341 . -523) (undo-tree-id7342 . -556) (undo-tree-id7343 . -556) (undo-tree-id7344 . -556) (undo-tree-id7345 . -556) (undo-tree-id7346 . -556) (undo-tree-id7347 . -556) (undo-tree-id7348 . -556) (undo-tree-id7349 . -556) (undo-tree-id7350 . -556) (undo-tree-id7351 . -556) (undo-tree-id7352 . -606) 1252) nil (25760 29891 498406 194000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 696) (undo-tree-id7087 . 1) (undo-tree-id7088 . -1)) nil (25760 29891 498244 414000) 0 nil])
([nil nil ((1 . 41057) (#("#!/usr/bin/env python

from custom_functs import *
import sklearn
import tensorflow as tf
from tensorflow import keras
import numpy as np
from pathlib import Path

# to make this notebook's output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rc(\"axes\", labelsize=14)
mpl.rc(\"xtick\", labelsize=12)
mpl.rc(\"ytick\", labelsize=12)


n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]

X_train.shape, y_train.shape



fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(
        X_valid[col, :, 0],
        y_valid[col, 0],
        y_label=(\"$x(t)$\" if col == 0 else None),
        legend=(col == 0),
    )
save_fig(\"time_series_plot\")
plt.show()


# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.

# ## Computing Some Baselines

# Naive predictions (just predict the last observed value):

# In[6]:


y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))


# In[7]:


plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Linear predictions:

# In[8]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(1)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[9]:


model.evaluate(X_valid, y_valid)


# In[10]:


def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(\"Epochs\")
    plt.ylabel(\"Loss\")
    plt.grid(True)


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[11]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Using a Simple RNN

# In[12]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1])])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=\"mse\", optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[13]:


model.evaluate(X_valid, y_valid)


# In[14]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[15]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Deep RNNs

# In[16]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.SimpleRNN(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[17]:


model.evaluate(X_valid, y_valid)


# In[18]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[19]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# Make the second `SimpleRNN` layer return only the last output:

# In[20]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(1),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))


# In[21]:


model.evaluate(X_valid, y_valid)


# In[22]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[23]:


y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()


# ## Forecasting Several Steps Ahead

# In[24]:


np.random.seed(43)  # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]


# In[25]:


Y_pred.shape


# In[26]:


def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")
    plt.plot(
        np.arange(n_steps, n_steps + ahead),
        Y_pred[0, :, 0],
        \"rx-\",
        label=\"Forecast\",
        markersize=10,
    )
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)


plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(\"forecast_ahead_plot\")
plt.show()


# Now let's use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.

# In[27]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]


# Now let's predict the next 10 values one by one:

# In[28]:


X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]


# In[29]:


Y_pred.shape


# In[30]:


np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))


# Let's compare this performance with some baselines: naive predictions and a simple linear model:

# In[31]:


Y_naive_pred = np.tile(
    X_valid[:, -1], 10
)  # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))


# In[32]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [keras.layers.Flatten(input_shape=[50, 1]), keras.layers.Dense(10)]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Now let's create an RNN that predicts all 10 next values at once:

# In[33]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20),
        keras.layers.Dense(10),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\")
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[34]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]


# In[35]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# Now let's create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.

# In[36]:


np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead : step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]


# In[37]:


X_train.shape, Y_train.shape


# In[38]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)


def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])


model.compile(
    loss=\"mse\",
    optimizer=keras.optimizers.Adam(learning_rate=0.01),
    metrics=[last_time_step_mse],
)
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[39]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[40]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # Deep RNN with Batch Norm

# In[41]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.BatchNormalization(),
        keras.layers.SimpleRNN(20, return_sequences=True),
        keras.layers.BatchNormalization(),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Deep RNNs with Layer Norm

# In[42]:


from tensorflow.keras.layers import LayerNormalization


# In[43]:


class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]

    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]


# In[44]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.RNN(
            LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]
        ),
        keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # Creating a Custom RNN Class

# In[45]:


class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, \"get_initial_state\", self.fallback_initial_state
        )

    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]

    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0)
        )
        outputs = tf.zeros(
            shape=[batch_size, self.cell.output_size], dtype=inputs.dtype
        )
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs


# In[46]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        MyRNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),
        MyRNN(LNSimpleRNNCell(20), return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# # LSTMs

# In[47]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.LSTM(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[48]:


model.evaluate(X_valid, Y_valid)


# In[49]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[50]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[51]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# # GRUs

# In[52]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# In[53]:


model.evaluate(X_valid, Y_valid)


# In[54]:


plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])
plt.show()


# In[55]:


np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]


# In[56]:


plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()


# ## Using One-Dimensional Convolutional Layers to Process Sequences

# ```
# 1D conv layer with kernel size 4, stride 2, VALID padding:
#
#               |-----2-----|     |-----5---...------|     |-----23----|
#         |-----1-----|     |-----4-----|   ...      |-----22----|
#   |-----0----|      |-----3-----|     |---...|-----21----|
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 42 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 43 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 52 53 54 55 56 57 58 59
#
# Output:
#
# X:     0/3   2/5   4/7   6/9   8/11 10/13 .../43 42/45 44/47 46/49
# Y:     4/13  6/15  8/17 10/19 12/21 14/23 .../53 46/55 48/57 50/59
# ```

# In[57]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential(
    [
        keras.layers.Conv1D(
            filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]
        ),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.GRU(20, return_sequences=True),
        keras.layers.TimeDistributed(keras.layers.Dense(10)),
    ]
)

model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(
    X_train, Y_train[:, 3::2], epochs=20, validation_data=(X_valid, Y_valid[:, 3::2])
)


# ## WaveNet

# ```
# C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\.../\\ /\\ /\\ /\\ /\\ /\\
#    \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\       /  \\  /  \\  /  \\
#      /    \\      /    \\      /    \\                 /    \\
# C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /.../\\ /\\ /\\ /\\ /\\ /\\ /\\
# X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 43 44 45 46 47 48 49
# Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 44 45 46 47 48 49 50
#   /10 11 12 13 14 15 16 17 18 19 20 21 22 ... 53 54 55 56 57 58 59
# ```

# In[58]:


np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(
        keras.layers.Conv1D(
            filters=20,
            kernel_size=2,
            padding=\"causal\",
            activation=\"relu\",
            dilation_rate=rate,
        )
    )
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))


# Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:

# In[59]:


class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=\"tanh\", **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)

    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate


# In[60]:


def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(
        2 * n_filters, kernel_size=2, padding=\"causal\", dilation_rate=dilation_rate
    )(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z


# In[61]:


keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3  # 10 in the paper
n_blocks = 1  # 3 in the paper
n_filters = 32  # 128 in the paper
n_outputs = 10  # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)
skip_to_last = []
for dilation_rate in [2 ** i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=\"softmax\")(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])


# In[62]:


model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_valid, Y_valid))


# In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.

# # Exercise solutions

# ## 1. to 8.

# See Appendix A.

# ## 9. Tackling the SketchRNN Dataset

# _Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets._

# The dataset is not available in TFDS yet, the [pull request](https://github.com/tensorflow/datasets/pull/361) is still work in progress. Luckily, the data is conveniently available as TFRecords, so let's download it (it might take a while, as it's about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):

# In[63]:


DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"
FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"
filepath = keras.utils.get_file(
    FILENAME, DOWNLOAD_ROOT + FILENAME, cache_subdir=\"datasets/quickdraw\", extract=True
)


# In[64]:


quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")])


# In[65]:


train_files


# In[66]:


eval_files


# In[67]:


with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:
    test_classes = test_classes_file.readlines()

with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:
    train_classes = train_classes_file.readlines()


# In[68]:


assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]


# In[69]:


sorted(class_names)


# In[70]:


def parse(data_batch):
    feature_descriptions = {
        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),
        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),
        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64),
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[\"shape\"][:, 0]
    labels = examples[\"class_index\"][:, 0]
    return sketches, lengths, labels


# In[71]:


def quickdraw_dataset(
    filepaths,
    batch_size=32,
    shuffle_buffer_size=None,
    n_parse_threads=5,
    n_read_threads=5,
    cache=False,
):
    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)


# In[72]:


train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])


# In[73]:


for sketches, lengths, labels in train_set.take(1):
    print(\"sketches =\", sketches)
    print(\"lengths =\", lengths)
    print(\"labels =\", labels)


# In[74]:


def draw_sketch(sketch, label=None):
    origin = np.array([[0.0, 0.0, 0.0]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1] == 1.0)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else \"Try to guess\"
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")
    plt.axis(\"off\")


def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(
        range(n_sketches), sketches, lengths, labels
    ):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()


for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)


# Most sketches are composed of less than 100 points:

# In[75]:


lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(\"length\")
plt.ylabel(\"density\")
plt.show()


# In[76]:


def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))


cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)


# In[77]:


model = keras.models.Sequential(
    [
        keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(128, return_sequences=True),
        keras.layers.LSTM(128),
        keras.layers.Dense(len(class_names), activation=\"softmax\"),
    ]
)
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.0)
model.compile(
    loss=\"sparse_categorical_crossentropy\",
    optimizer=optimizer,
    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],
)
history = model.fit(cropped_train_set, epochs=2, validation_data=cropped_valid_set)


# In[78]:


y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)


# In[79]:


np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))


# In[80]:


n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(\"Top-5 predictions:\".format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))
    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))


# In[81]:


model.save(\"my_sketchrnn\")


# ## 10. Bach Chorales
# _Exercise: Download the [Bach chorales](https://homl.info/bach) dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out [Google's Coconet model](https://homl.info/coconet), which was used for a nice [Google doodle about Bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)._
#
#

# In[82]:


DOWNLOAD_ROOT = (
    \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"
)
FILENAME = \"jsb_chorales.tgz\"
filepath = keras.utils.get_file(
    FILENAME,
    DOWNLOAD_ROOT + FILENAME,
    cache_subdir=\"datasets/jsb_chorales\",
    extract=True,
)


# In[83]:


jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))
valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))
test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))


# In[84]:


import pandas as pd


def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]


train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)


# In[85]:


train_chorales[0]


# Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:

# In[86]:


notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81


# Let's write a few functions to listen to these chorales (you don't need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):

# In[87]:


from IPython.display import Audio


def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440


def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo  # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies > 9.0).reshape(-1, 1)
    return sine_waves.reshape(-1)


def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]]  # make last note a bit longer
    merged = np.mean(
        [frequencies_to_samples(melody, tempo, sample_rate) for melody in freqs.T],
        axis=0,
    )
    n_fade_out_samples = sample_rate * 60 // tempo  # fade out last note
    fade_out = np.linspace(1.0, 0.0, n_fade_out_samples) ** 2
    merged[-n_fade_out_samples:] *= fade_out
    return merged


def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile

        samples = (2 ** 15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))


# Now let's listen to a few chorales:

# In[88]:


for index in range(3):
    play_chords(train_chorales[index])


# Divine! :)

# In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don't go very well together (believe me, I tried). It's much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.
#
# We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).
#
# And we will train the model on windows of 128 notes (i.e., 32 chords).
#
# Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).

# In[89]:


def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:]  # predict next note in each arpegio, at each step
    return X, Y


def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1)  # shift values
    return tf.reshape(window, [-1])  # convert to arpegio


def bach_dataset(
    chorales,
    batch_size=32,
    shuffle_buffer_size=None,
    window_size=32,
    window_shift=16,
    cache=True,
):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)


# Now let's create the training set, the validation set and the test set:

# In[90]:


train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)


# Now let's create the model:
#
# * We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C\\#3, it's very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an `Embedding` layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of `[batch_size, window_size, 5]`.
# * We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 `Conv1D` layers with doubling dilation rates. We will intersperse these layers with `BatchNormalization` layers for faster better convergence.
# * Then one `LSTM` layer to try to capture long-term patterns.
# * And finally a `Dense` layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be `[batch_size, window_size, 47]`.

# In[91]:


n_embedding_dims = 5

model = keras.models.Sequential(
    [
        keras.layers.Embedding(
            input_dim=n_notes, output_dim=n_embedding_dims, input_shape=[None]
        ),
        keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4
        ),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(
            96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8
        ),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(256, return_sequences=True),
        keras.layers.Dense(n_notes, activation=\"softmax\"),
    ]
)

model.summary()


# Now we're ready to compile and train the model!

# In[92]:


optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(
    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]
)
model.fit(train_set, epochs=20, validation_data=valid_set)


# I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the `LSTM` layer and replacing it with `Conv1D` layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.

# Once you're satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:

# In[93]:


model.save(\"my_bach_model.h5\")
model.evaluate(test_set)


# **Note:** There's no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.

# Now let's write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.

# **Warning**: `model.predict_classes(X)` is deprecated. It is replaced with `np.argmax(model.predict(X), axis=-1)`.

# In[94]:


def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            # next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# To test this function, we need some seed chords. Let's use the first 8 chords of one of the test chorales (it's actually just 2 different chords, each played 4 times):

# In[95]:


seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)


# Now we are ready to generate our first chorale! Let's ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):

# In[96]:


new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)


# This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.
#
# So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a `temperature` parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.

# In[97]:


def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])


# Let's generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!
#
# **Please share your most beautiful generated chorale with me on Twitter @aureliengeron, I would really appreciate it! :))**

# In[98]:


new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")


# In[99]:


new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")


# In[100]:


new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")


# Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!

# In[101]:


play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")
" 0 1 (fontified t face font-lock-comment-delimiter-face) 1 22 (fontified t face font-lock-comment-face) 22 23 (fontified t) 23 27 (fontified t face font-lock-keyword-face) 27 42 (fontified t) 42 48 (fontified t face font-lock-keyword-face) 48 51 (fontified t) 51 57 (fontified t face font-lock-keyword-face) 57 66 (fontified t) 66 72 (fontified t face font-lock-keyword-face) 72 84 (fontified t) 84 86 (fontified t face font-lock-keyword-face) 86 90 (fontified t) 90 94 (fontified t face font-lock-keyword-face) 94 106 (fontified t) 106 112 (fontified t face font-lock-keyword-face) 112 119 (fontified t) 119 125 (fontified t face font-lock-keyword-face) 125 132 (fontified t) 132 134 (fontified t face font-lock-keyword-face) 134 138 (fontified t) 138 142 (fontified t face font-lock-keyword-face) 142 151 (fontified t) 151 157 (fontified t face font-lock-keyword-face) 157 164 (fontified t) 164 166 (fontified t face font-lock-comment-delimiter-face) 166 216 (fontified t face font-lock-comment-face) 216 230 (fontified t) 230 231 (fontified t face (rainbow-delimiters-depth-1-face)) 231 233 (fontified t) 233 234 (fontified t face (rainbow-delimiters-depth-1-face)) 234 253 (fontified t) 253 254 (fontified t face (rainbow-delimiters-depth-1-face)) 254 256 (fontified t) 256 257 (fontified t face (rainbow-delimiters-depth-1-face)) 257 259 (fontified t) 259 265 (fontified t face font-lock-keyword-face) 265 277 (fontified t) 277 279 (fontified t face font-lock-keyword-face) 279 284 (fontified t) 284 290 (fontified t face font-lock-keyword-face) 290 309 (fontified t) 309 311 (fontified t face font-lock-keyword-face) 311 323 (fontified t) 323 324 (fontified t face (rainbow-delimiters-depth-1-face)) 324 330 (fontified t face font-lock-string-face) 330 344 (fontified t) 344 345 (fontified t face (rainbow-delimiters-depth-1-face)) 345 352 (fontified t) 352 353 (fontified t face (rainbow-delimiters-depth-1-face)) 353 360 (fontified t face font-lock-string-face) 360 374 (fontified t) 374 375 (fontified t face (rainbow-delimiters-depth-1-face)) 375 382 (fontified t) 382 383 (fontified t face (rainbow-delimiters-depth-1-face)) 383 390 (fontified t face font-lock-string-face) 390 404 (fontified t) 404 405 (fontified t face (rainbow-delimiters-depth-1-face)) 405 408 (fontified t) 408 415 (fontified t face font-lock-variable-name-face) 415 421 (fontified t) 421 427 (fontified t face font-lock-variable-name-face) 427 450 (fontified t) 450 451 (fontified t face (rainbow-delimiters-depth-1-face)) 451 469 (fontified t) 469 470 (fontified t face (rainbow-delimiters-depth-1-face)) 470 471 (fontified t) 471 478 (fontified t face font-lock-variable-name-face) 478 480 (fontified t) 480 487 (fontified t face font-lock-variable-name-face) 487 496 (fontified t) 496 497 (fontified t face (rainbow-delimiters-depth-1-face)) 497 500 (fontified t) 500 512 (fontified t) 512 513 (fontified t face (rainbow-delimiters-depth-1-face)) 513 521 (fontified t) 521 522 (fontified t face (rainbow-delimiters-depth-1-face)) 522 531 (fontified t) 531 532 (fontified t face (rainbow-delimiters-depth-1-face)) 532 533 (fontified t) 533 540 (fontified t face font-lock-variable-name-face) 540 542 (fontified t) 542 549 (fontified t face font-lock-variable-name-face) 549 558 (fontified t) 558 559 (fontified t face (rainbow-delimiters-depth-1-face)) 559 578 (fontified t) 578 579 (fontified t face (rainbow-delimiters-depth-1-face)) 579 587 (fontified t) 587 588 (fontified t face (rainbow-delimiters-depth-1-face)) 588 601 (fontified t) 601 602 (fontified t face (rainbow-delimiters-depth-1-face)) 602 603 (fontified t) 603 609 (fontified t face font-lock-variable-name-face) 609 611 (fontified t) 611 617 (fontified t face font-lock-variable-name-face) 617 626 (fontified t) 626 627 (fontified t face (rainbow-delimiters-depth-1-face)) 627 642 (fontified t) 642 643 (fontified t face (rainbow-delimiters-depth-1-face)) 643 651 (fontified t) 651 652 (fontified t face (rainbow-delimiters-depth-1-face)) 652 661 (fontified t) 661 662 (fontified t face (rainbow-delimiters-depth-1-face)) 662 664 (fontified t) 664 692 (fontified t) 692 693 (fontified t) 693 695 (fontified t) 695 696 (fontified t) 696 699 (fontified t face font-lock-variable-name-face) 699 701 (fontified t) 701 705 (fontified t face font-lock-variable-name-face) 705 720 (fontified t) 720 721 (fontified t face (rainbow-delimiters-depth-1-face)) 721 746 (fontified t) 746 750 (fontified t face font-lock-constant-face) 750 760 (fontified t) 760 761 (fontified t face (rainbow-delimiters-depth-2-face)) 761 766 (fontified t) 766 767 (fontified t face (rainbow-delimiters-depth-2-face)) 767 768 (fontified t face (rainbow-delimiters-depth-1-face)) 768 769 (fontified t) 769 772 (fontified t face font-lock-keyword-face) 772 777 (fontified t) 777 779 (fontified t face font-lock-keyword-face) 779 780 (fontified t) 780 785 (fontified t face font-lock-builtin-face) 785 786 (fontified t face (rainbow-delimiters-depth-1-face)) 786 787 (fontified t) 787 788 (fontified t face (rainbow-delimiters-depth-1-face)) 788 801 (fontified t) 801 802 (fontified t face (rainbow-delimiters-depth-1-face)) 802 806 (fontified t) 806 807 (fontified t face (rainbow-delimiters-depth-2-face)) 807 810 (fontified t) 810 811 (fontified t face (rainbow-delimiters-depth-2-face)) 811 812 (fontified t face (rainbow-delimiters-depth-1-face)) 812 828 (fontified t) 828 829 (fontified t face (rainbow-delimiters-depth-1-face)) 829 845 (fontified t) 845 846 (fontified t face (rainbow-delimiters-depth-2-face)) 846 855 (fontified t) 855 856 (fontified t face (rainbow-delimiters-depth-2-face)) 856 873 (fontified t) 873 874 (fontified t face (rainbow-delimiters-depth-2-face)) 874 880 (fontified t) 880 881 (fontified t face (rainbow-delimiters-depth-2-face)) 881 899 (fontified t) 899 900 (fontified t face (rainbow-delimiters-depth-2-face)) 900 908 (fontified t face font-lock-string-face) 908 909 (fontified t) 909 911 (fontified t face font-lock-keyword-face) 911 921 (fontified t) 921 925 (fontified t face font-lock-keyword-face) 925 926 (fontified t) 926 930 (fontified t face font-lock-constant-face) 930 931 (fontified t face (rainbow-delimiters-depth-2-face)) 931 933 (fontified t) 933 948 (fontified t) 948 949 (fontified t face (rainbow-delimiters-depth-2-face)) 949 957 (fontified t) 957 958 (fontified t face (rainbow-delimiters-depth-2-face)) 958 964 (fontified t) 964 965 (fontified t face (rainbow-delimiters-depth-1-face)) 965 974 (fontified t) 974 975 (fontified t face (rainbow-delimiters-depth-1-face)) 975 993 (fontified t face font-lock-string-face) 993 994 (fontified t face (rainbow-delimiters-depth-1-face)) 994 1003 (fontified t) 1003 1004 (fontified t face (rainbow-delimiters-depth-1-face)) 1004 1005 (fontified t face (rainbow-delimiters-depth-1-face)) 1005 1008 (fontified t) 1008 1010 (fontified t face font-lock-comment-delimiter-face) 1010 1073 (fontified t face font-lock-comment-face) 1073 1111 (fontified t face font-lock-comment-face) 1111 1195 (fontified t face font-lock-comment-face) 1195 1196 (fontified t face font-lock-comment-face) 1196 1271 (face font-lock-comment-face fontified t) 1271 1272 (fontified t) 1272 1274 (fontified t face font-lock-comment-delimiter-face) 1274 1302 (fontified t face font-lock-comment-face) 1302 1303 (fontified t) 1303 1305 (fontified t face font-lock-comment-delimiter-face) 1305 1363 (fontified t face font-lock-comment-face) 1363 1364 (fontified t) 1364 1366 (fontified t face font-lock-comment-delimiter-face) 1366 1373 (fontified t face font-lock-comment-face) 1373 1375 (fontified t) 1375 1381 (fontified t face font-lock-variable-name-face) 1381 1391 (fontified t) 1391 1392 (fontified t face (rainbow-delimiters-depth-1-face)) 1392 1397 (fontified t) 1397 1398 (fontified t face (rainbow-delimiters-depth-1-face)) 1398 1406 (fontified t) 1406 1407 (fontified t face (rainbow-delimiters-depth-1-face)) 1407 1438 (fontified t) 1438 1439 (fontified t face (rainbow-delimiters-depth-2-face)) 1439 1454 (fontified t) 1454 1455 (fontified t face (rainbow-delimiters-depth-2-face)) 1455 1456 (fontified t face (rainbow-delimiters-depth-1-face)) 1456 1459 (fontified t) 1459 1461 (fontified t face font-lock-comment-delimiter-face) 1461 1468 (fontified t face font-lock-comment-face) 1468 1481 (fontified t) 1481 1482 (fontified t face (rainbow-delimiters-depth-1-face)) 1482 1489 (fontified t) 1489 1490 (fontified t face (rainbow-delimiters-depth-2-face)) 1490 1497 (fontified t) 1497 1498 (fontified t face (rainbow-delimiters-depth-2-face)) 1498 1507 (fontified t) 1507 1508 (fontified t face (rainbow-delimiters-depth-2-face)) 1508 1512 (fontified t) 1512 1513 (fontified t face (rainbow-delimiters-depth-2-face)) 1513 1521 (fontified t) 1521 1522 (fontified t face (rainbow-delimiters-depth-2-face)) 1522 1526 (fontified t) 1526 1527 (fontified t face (rainbow-delimiters-depth-2-face)) 1527 1528 (fontified t face (rainbow-delimiters-depth-1-face)) 1528 1537 (fontified t) 1537 1538 (fontified t face (rainbow-delimiters-depth-1-face)) 1538 1539 (fontified t face (rainbow-delimiters-depth-1-face)) 1539 1542 (fontified t) 1542 1544 (fontified t face font-lock-comment-delimiter-face) 1544 1564 (fontified t face font-lock-comment-face) 1564 1565 (fontified t) 1565 1567 (fontified t face font-lock-comment-delimiter-face) 1567 1574 (fontified t face font-lock-comment-face) 1574 1590 (fontified t) 1590 1591 (fontified t face (rainbow-delimiters-depth-1-face)) 1591 1593 (fontified t) 1593 1594 (fontified t face (rainbow-delimiters-depth-1-face)) 1594 1613 (fontified t) 1613 1614 (fontified t face (rainbow-delimiters-depth-1-face)) 1614 1616 (fontified t) 1616 1617 (fontified t face (rainbow-delimiters-depth-1-face)) 1617 1619 (fontified t) 1619 1624 (fontified t face font-lock-variable-name-face) 1624 1650 (fontified t) 1650 1651 (fontified t face (rainbow-delimiters-depth-1-face)) 1651 1656 (fontified t) 1656 1657 (fontified t face (rainbow-delimiters-depth-2-face)) 1657 1677 (fontified t) 1677 1678 (fontified t face (rainbow-delimiters-depth-3-face)) 1678 1690 (fontified t) 1690 1691 (fontified t face (rainbow-delimiters-depth-4-face)) 1691 1696 (fontified t) 1696 1697 (fontified t face (rainbow-delimiters-depth-4-face)) 1697 1698 (fontified t face (rainbow-delimiters-depth-3-face)) 1698 1718 (fontified t) 1718 1719 (fontified t face (rainbow-delimiters-depth-3-face)) 1719 1720 (fontified t) 1720 1721 (fontified t face (rainbow-delimiters-depth-3-face)) 1721 1722 (fontified t face (rainbow-delimiters-depth-2-face)) 1722 1723 (fontified t) 1723 1724 (fontified t face (rainbow-delimiters-depth-1-face)) 1724 1732 (fontified t) 1732 1739 (fontified t face font-lock-builtin-face) 1739 1740 (fontified t face (rainbow-delimiters-depth-1-face)) 1740 1745 (fontified t) 1745 1750 (fontified t face font-lock-string-face) 1750 1762 (fontified t) 1762 1768 (fontified t face font-lock-string-face) 1768 1769 (fontified t face (rainbow-delimiters-depth-1-face)) 1769 1770 (fontified t) 1770 1771 (fontified t face font-lock-variable-name-face) 1771 1777 (face font-lock-variable-name-face fontified t) 1777 1789 (fontified t) 1789 1790 (face (rainbow-delimiters-depth-1-face) fontified t) 1790 1835 (fontified t) 1835 1836 (face (rainbow-delimiters-depth-2-face) fontified t) 1836 1852 (fontified t) 1852 1853 (face (rainbow-delimiters-depth-2-face) fontified t) 1853 1854 (face (rainbow-delimiters-depth-1-face) fontified t) 1854 1855 (fontified t)) . 1) (undo-tree-id5393 . -695) (undo-tree-id5394 . -695) (undo-tree-id5395 . -695) (undo-tree-id5396 . -695) (undo-tree-id5397 . 40362) (undo-tree-id5398 . -695) (undo-tree-id5399 . -695) (undo-tree-id5400 . -49) (undo-tree-id5401 . -49) (undo-tree-id5402 . -49) (undo-tree-id5403 . -49) (undo-tree-id5404 . -49) (undo-tree-id5405 . -49) (undo-tree-id5406 . -49) (undo-tree-id5407 . -49) (undo-tree-id5408 . -49) (undo-tree-id5409 . -49) (undo-tree-id5410 . -51) (undo-tree-id5411 . -51) (undo-tree-id5412 . -51) (undo-tree-id5413 . -51) (undo-tree-id5414 . -51) (undo-tree-id5415 . -51) (undo-tree-id5416 . -51) (undo-tree-id5417 . -23) (undo-tree-id5418 . -27) (undo-tree-id5419 . -51) (undo-tree-id5420 . -57) (undo-tree-id5421 . -259) (undo-tree-id5422 . -265) (undo-tree-id5423 . -284) (undo-tree-id5424 . -290) (undo-tree-id5425 . -430) (undo-tree-id5426 . -450) (undo-tree-id5427 . -966) (undo-tree-id5428 . -974) (undo-tree-id5429 . -1087) (undo-tree-id5430 . -1096) (undo-tree-id5431 . -1845) (undo-tree-id5432 . -1852) (undo-tree-id5433 . -2112) (undo-tree-id5434 . -2116) (undo-tree-id5435 . -2686) (undo-tree-id5436 . -2687) (undo-tree-id5437 . -2869) (undo-tree-id5438 . -2876) (undo-tree-id5439 . -3333) (undo-tree-id5440 . -3334) (undo-tree-id5441 . -3558) (undo-tree-id5442 . -3565) (undo-tree-id5443 . -4072) (undo-tree-id5444 . -4073) (undo-tree-id5445 . -4270) (undo-tree-id5446 . -4277) (undo-tree-id5447 . -4672) (undo-tree-id5448 . -4675) (undo-tree-id5449 . -4686) (undo-tree-id5450 . -4706) (undo-tree-id5451 . -5196) (undo-tree-id5452 . -5202) (undo-tree-id5453 . -5477) (undo-tree-id5454 . -5485) (undo-tree-id5455 . -5597) (undo-tree-id5456 . -5607) (undo-tree-id5457 . -5701) (undo-tree-id5458 . -5721) (undo-tree-id5459 . -6365) (undo-tree-id5460 . -6371) (undo-tree-id5461 . -6854) (undo-tree-id5462 . -6861) (undo-tree-id5463 . -7108) (undo-tree-id5464 . -7109) (undo-tree-id5465 . -7307) (undo-tree-id5466 . -7314) (undo-tree-id5467 . -7360) (undo-tree-id5468 . -7380) (undo-tree-id5469 . -7643) (undo-tree-id5470 . -7647) (undo-tree-id5471 . -8069) (undo-tree-id5472 . -8089) (undo-tree-id5473 . -8338) (undo-tree-id5474 . -8339) (undo-tree-id5475 . -8644) (undo-tree-id5476 . -8645) (undo-tree-id5477 . -9093) (undo-tree-id5478 . -9100) (undo-tree-id5479 . -9146) (undo-tree-id5480 . -9166) (undo-tree-id5481 . -9561) (undo-tree-id5482 . -9562) (undo-tree-id5483 . -9929) (undo-tree-id5484 . -9936) (undo-tree-id5485 . -9984) (undo-tree-id5486 . -9988) (undo-tree-id5487 . -10332) (undo-tree-id5488 . -10336) (undo-tree-id5489 . -11414) (undo-tree-id5490 . -11421) (undo-tree-id5491 . -11968) (undo-tree-id5492 . -11969) (undo-tree-id5493 . -12899) (undo-tree-id5494 . -12900) (undo-tree-id5495 . -13181) (undo-tree-id5496 . -13188) (undo-tree-id5497 . -13649) (undo-tree-id5498 . -13656) (undo-tree-id5499 . -13849) (undo-tree-id5500 . -13869) (undo-tree-id5501 . -14514) (undo-tree-id5502 . -14521) (undo-tree-id5503 . -14714) (undo-tree-id5504 . -14734) (undo-tree-id5505 . -15843) (undo-tree-id5506 . -15844) (undo-tree-id5507 . -16215) (undo-tree-id5508 . -16216) (undo-tree-id5509 . -17308) (undo-tree-id5510 . -17315) (undo-tree-id5511 . -17398) (undo-tree-id5512 . -17403) (undo-tree-id5513 . -18177) (undo-tree-id5514 . -18190) (undo-tree-id5515 . -19096) (undo-tree-id5516 . -19097) (undo-tree-id5517 . -19324) (undo-tree-id5518 . -19331) (undo-tree-id5519 . -19415) (undo-tree-id5520 . -19416) (undo-tree-id5521 . -19993) (undo-tree-id5522 . -19995) (undo-tree-id5523 . -20097) (undo-tree-id5524 . -20100) (undo-tree-id5525 . -20574) (undo-tree-id5526 . -20581) (undo-tree-id5527 . -20714) (undo-tree-id5528 . -20722) (undo-tree-id5529 . -20808) (undo-tree-id5530 . -20809) (undo-tree-id5531 . -22085) (undo-tree-id5532 . -22099) (undo-tree-id5533 . -24179) (undo-tree-id5534 . -24185) (undo-tree-id5535 . -25199) (undo-tree-id5536 . -25216) (undo-tree-id5537 . -25632) (undo-tree-id5538 . -25633) (undo-tree-id5539 . -26076) (undo-tree-id5540 . -26081) (undo-tree-id5541 . -27535) (undo-tree-id5542 . -27541) (undo-tree-id5543 . -27908) (undo-tree-id5544 . -27911) (undo-tree-id5545 . -28300) (undo-tree-id5546 . -28310) (undo-tree-id5547 . -28494) (undo-tree-id5548 . -28498) (undo-tree-id5549 . -29714) (undo-tree-id5550 . -29715) (undo-tree-id5551 . -30019) (undo-tree-id5552 . -30023) (undo-tree-id5553 . -30277) (undo-tree-id5554 . -30284) (undo-tree-id5555 . -30327) (undo-tree-id5556 . -30334) (undo-tree-id5557 . -30578) (undo-tree-id5558 . -30581) (undo-tree-id5559 . -31428) (undo-tree-id5560 . -31438) (undo-tree-id5561 . -31656) (undo-tree-id5562 . -31661) (undo-tree-id5563 . -32098) (undo-tree-id5564 . -32104) (undo-tree-id5565 . -32552) (undo-tree-id5566 . -32556) (undo-tree-id5567 . -33372) (undo-tree-id5568 . -33377) (undo-tree-id5569 . -34102) (undo-tree-id5570 . -34110) (undo-tree-id5571 . -34410) (undo-tree-id5572 . -34414) (undo-tree-id5573 . -34872) (undo-tree-id5574 . -34876) (undo-tree-id5575 . -35020) (undo-tree-id5576 . -35033) (undo-tree-id5577 . -35187) (undo-tree-id5578 . -35200) (undo-tree-id5579 . -35354) (undo-tree-id5580 . -35367) (undo-tree-id5581 . -35773) (undo-tree-id5582 . -35781) (undo-tree-id5583 . -35925) (undo-tree-id5584 . -35930) (undo-tree-id5585 . -36223) (undo-tree-id5586 . -36224) (undo-tree-id5587 . -36438) (undo-tree-id5588 . -36439) (undo-tree-id5589 . -36731) (undo-tree-id5590 . -36732) (undo-tree-id5591 . -37069) (undo-tree-id5592 . -37071) (undo-tree-id5593 . -37744) (undo-tree-id5594 . -37745) (undo-tree-id5595 . -38001) (undo-tree-id5596 . -38009) (undo-tree-id5597 . -38291) (undo-tree-id5598 . -38296) (undo-tree-id5599 . -38717) (undo-tree-id5600 . -38724) (undo-tree-id5601 . -39996) (undo-tree-id5602 . -39999) (undo-tree-id5603 . -40276) (undo-tree-id5604 . -40289) (undo-tree-id5605 . -40419) (undo-tree-id5606 . -40420) (undo-tree-id5607 . -40575) (undo-tree-id5608 . -40576) (undo-tree-id5609 . -40738) (undo-tree-id5610 . -40739) (undo-tree-id5611 . -40879) (undo-tree-id5612 . -40887) (undo-tree-id5613 . -51) (undo-tree-id5614 . -51) (undo-tree-id5615 . -51) (undo-tree-id5616 . -51) (undo-tree-id5617 . -51) (undo-tree-id5618 . -51) (undo-tree-id5619 . -51) (undo-tree-id5620 . -51) (undo-tree-id5621 . -51) (undo-tree-id5622 . -51) (undo-tree-id5623 . -51) (undo-tree-id5624 . -51) (undo-tree-id5625 . -51) (undo-tree-id5626 . -51) (undo-tree-id5627 . -51) (undo-tree-id5628 . -51) (undo-tree-id5629 . -51) (undo-tree-id5630 . -51) (undo-tree-id5631 . -51) (undo-tree-id5632 . -51) (undo-tree-id5633 . -51) (undo-tree-id5634 . -51) (undo-tree-id5635 . -51) (undo-tree-id5636 . -51) (undo-tree-id5637 . -51) (undo-tree-id5638 . -51) (undo-tree-id5639 . -51) (undo-tree-id5640 . -51) (undo-tree-id5641 . -51) (undo-tree-id5642 . -51) (undo-tree-id5643 . -51) (undo-tree-id5644 . -51) (undo-tree-id5645 . -51) (undo-tree-id5646 . -51) (undo-tree-id5647 . -51) (undo-tree-id5648 . -51) (undo-tree-id5649 . -51) (undo-tree-id5650 . -51) (undo-tree-id5651 . -51) (undo-tree-id5652 . -51) (undo-tree-id5653 . -51) (undo-tree-id5654 . -51) (undo-tree-id5655 . -51) (undo-tree-id5656 . -51) (undo-tree-id5657 . -51) (undo-tree-id5658 . -58) (undo-tree-id5659 . -66) (undo-tree-id5660 . -66) (undo-tree-id5661 . -66) (undo-tree-id5662 . -66) (undo-tree-id5663 . -66) (undo-tree-id5664 . -66) (undo-tree-id5665 . -66) (undo-tree-id5666 . -66) (undo-tree-id5667 . -66) (undo-tree-id5668 . -73) (undo-tree-id5669 . -84) (undo-tree-id5670 . -84) (undo-tree-id5671 . -84) (undo-tree-id5672 . -84) (undo-tree-id5673 . -84) (undo-tree-id5674 . -84) (undo-tree-id5675 . -84) (undo-tree-id5676 . -84) (undo-tree-id5677 . -84) (undo-tree-id5678 . -84) (undo-tree-id5679 . -84) (undo-tree-id5680 . -84) (undo-tree-id5681 . -84) (undo-tree-id5682 . -84) (undo-tree-id5683 . -84) (undo-tree-id5684 . -84) (undo-tree-id5685 . -84) (undo-tree-id5686 . -84) (undo-tree-id5687 . -84) (undo-tree-id5688 . -84) (undo-tree-id5689 . -84) (undo-tree-id5690 . -84) (undo-tree-id5691 . -84) (undo-tree-id5692 . -84) (undo-tree-id5693 . -84) (undo-tree-id5694 . -84) (undo-tree-id5695 . -84) (undo-tree-id5696 . -84) (undo-tree-id5697 . -84) (undo-tree-id5698 . -84) (undo-tree-id5699 . -84) (undo-tree-id5700 . -84) (undo-tree-id5701 . -84) (undo-tree-id5702 . -84) (undo-tree-id5703 . -84) (undo-tree-id5704 . -84) (undo-tree-id5705 . -84) (undo-tree-id5706 . -84) (undo-tree-id5707 . -84) (undo-tree-id5708 . -84) (undo-tree-id5709 . -84) (undo-tree-id5710 . -84) (undo-tree-id5711 . -84) (undo-tree-id5712 . -87) (undo-tree-id5713 . -88) (undo-tree-id5714 . -93) (undo-tree-id5715 . -93) (undo-tree-id5716 . -93) (undo-tree-id5717 . -93) (undo-tree-id5718 . -93) (undo-tree-id5719 . -93) (undo-tree-id5720 . -93) (undo-tree-id5721 . -93) (undo-tree-id5722 . -104) (undo-tree-id5723 . -111) (undo-tree-id5724 . -117) (undo-tree-id5725 . -124) (undo-tree-id5726 . -124) (undo-tree-id5727 . -124) (undo-tree-id5728 . -124) (undo-tree-id5729 . -124) (undo-tree-id5730 . -124) (undo-tree-id5731 . -124) (undo-tree-id5732 . -124) (undo-tree-id5733 . -130) (undo-tree-id5734 . -133) (undo-tree-id5735 . -136) (undo-tree-id5736 . -141) (undo-tree-id5737 . -141) (undo-tree-id5738 . -141) (undo-tree-id5739 . -141) (undo-tree-id5740 . -141) (undo-tree-id5741 . -141) (undo-tree-id5742 . -141) (undo-tree-id5743 . -141) (undo-tree-id5744 . -149) (undo-tree-id5745 . -156) (undo-tree-id5746 . -161) (undo-tree-id5747 . -163) (undo-tree-id5748 . -163) (undo-tree-id5749 . -163) (undo-tree-id5750 . -163) (undo-tree-id5751 . -163) (undo-tree-id5752 . -163) (undo-tree-id5753 . -163) (undo-tree-id5754 . -163) (undo-tree-id5755 . -164) (undo-tree-id5756 . -164) (undo-tree-id5757 . -164) (undo-tree-id5758 . -164) (undo-tree-id5759 . -164) (undo-tree-id5760 . -164) (undo-tree-id5761 . -164) (undo-tree-id5762 . -164) (undo-tree-id5763 . -164) (undo-tree-id5764 . -164) (undo-tree-id5765 . -164) (undo-tree-id5766 . -164) (undo-tree-id5767 . -164) (undo-tree-id5768 . -164) (undo-tree-id5769 . -164) (undo-tree-id5770 . -164) (undo-tree-id5771 . -164) (undo-tree-id5772 . -164) (undo-tree-id5773 . -164) (undo-tree-id5774 . -164) (undo-tree-id5775 . -164) (undo-tree-id5776 . -164) (undo-tree-id5777 . -164) (undo-tree-id5778 . -164) (undo-tree-id5779 . -164) (undo-tree-id5780 . -164) (undo-tree-id5781 . -164) (undo-tree-id5782 . -164) (undo-tree-id5783 . -164) (undo-tree-id5784 . -164) (undo-tree-id5785 . -164) (undo-tree-id5786 . -164) (undo-tree-id5787 . -164) (undo-tree-id5788 . -164) (undo-tree-id5789 . -164) (undo-tree-id5790 . -164) (undo-tree-id5791 . -164) (undo-tree-id5792 . -164) (undo-tree-id5793 . -164) (undo-tree-id5794 . -164) (undo-tree-id5795 . -164) (undo-tree-id5796 . -164) (undo-tree-id5797 . -164) (undo-tree-id5798 . -164) (undo-tree-id5799 . -164) (undo-tree-id5800 . -164) (undo-tree-id5801 . -164) (undo-tree-id5802 . -164) (undo-tree-id5803 . -164) (undo-tree-id5804 . -164) (undo-tree-id5805 . -164) (undo-tree-id5806 . -164) (undo-tree-id5807 . -164) (undo-tree-id5808 . -164) (undo-tree-id5809 . -164) (undo-tree-id5810 . -164) (undo-tree-id5811 . -164) (undo-tree-id5812 . -164) (undo-tree-id5813 . -164) (undo-tree-id5814 . -164) (undo-tree-id5815 . -164) (undo-tree-id5816 . -164) (undo-tree-id5817 . -164) (undo-tree-id5818 . -164) (undo-tree-id5819 . -164) (undo-tree-id5820 . -164) (undo-tree-id5821 . -164) (undo-tree-id5822 . -164) (undo-tree-id5823 . -164) (undo-tree-id5824 . -164) (undo-tree-id5825 . -164) (undo-tree-id5826 . -164) (undo-tree-id5827 . -164) (undo-tree-id5828 . -164) (undo-tree-id5829 . -164) (undo-tree-id5830 . -664) (undo-tree-id5831 . -664) (undo-tree-id5832 . -695) (undo-tree-id5833 . -695) (undo-tree-id5834 . -817) (undo-tree-id5835 . -817) (undo-tree-id5836 . -817) (undo-tree-id5837 . -664) (undo-tree-id5838 . -664) (undo-tree-id5839 . -664) (undo-tree-id5840 . -664) (undo-tree-id5841 . -664) (undo-tree-id5842 . -664) (undo-tree-id5843 . -664) (undo-tree-id5844 . -664) (undo-tree-id5845 . -664) (undo-tree-id5846 . -664) (undo-tree-id5847 . -664) (undo-tree-id5848 . -664) (undo-tree-id5849 . -664) (undo-tree-id5850 . -664) (undo-tree-id5851 . -664) (undo-tree-id5852 . -664) (undo-tree-id5853 . -664) (undo-tree-id5854 . -664) (undo-tree-id5855 . -664) (undo-tree-id5856 . -664) (undo-tree-id5857 . -664) (undo-tree-id5858 . -664) (undo-tree-id5859 . -664) (undo-tree-id5860 . -664) (undo-tree-id5861 . -664) (undo-tree-id5862 . -664) (undo-tree-id5863 . -664) (undo-tree-id5864 . -664) (undo-tree-id5865 . -664) (undo-tree-id5866 . -664) (undo-tree-id5867 . -664) (undo-tree-id5868 . -664) (undo-tree-id5869 . -664) (undo-tree-id5870 . -664) (undo-tree-id5871 . -664) (undo-tree-id5872 . -664) (undo-tree-id5873 . -664) (undo-tree-id5874 . -664) (undo-tree-id5875 . -664) (undo-tree-id5876 . -664) (undo-tree-id5877 . -664) (undo-tree-id5878 . -664) (undo-tree-id5879 . -664) (undo-tree-id5880 . -664) (undo-tree-id5881 . -664) (undo-tree-id5882 . -664) (undo-tree-id5883 . -664) (undo-tree-id5884 . -664) (undo-tree-id5885 . -664) (undo-tree-id5886 . -664) (undo-tree-id5887 . -664) (undo-tree-id5888 . -664) (undo-tree-id5889 . -664) (undo-tree-id5890 . -664) (undo-tree-id5891 . -664) (undo-tree-id5892 . -664) (undo-tree-id5893 . -664) (undo-tree-id5894 . -664) (undo-tree-id5895 . -664) (undo-tree-id5896 . -664) (undo-tree-id5897 . -664) (undo-tree-id5898 . -664) (undo-tree-id5899 . -664) (undo-tree-id5900 . -664) (undo-tree-id5901 . -664) (undo-tree-id5902 . -664) (undo-tree-id5903 . -664) (undo-tree-id5904 . -695) (undo-tree-id5905 . -695) (undo-tree-id5906 . -695) (undo-tree-id5907 . -695) (undo-tree-id5908 . -695) (undo-tree-id5909 . -695) (undo-tree-id5910 . -695) (undo-tree-id5911 . -695) (undo-tree-id5912 . -695) (undo-tree-id5913 . -695) (undo-tree-id5914 . -695) (undo-tree-id5915 . -695) (undo-tree-id5916 . -695) (undo-tree-id5917 . -695) (undo-tree-id5918 . -695) (undo-tree-id5919 . -695) (undo-tree-id5920 . -695) (undo-tree-id5921 . -695) (undo-tree-id5922 . -817) (undo-tree-id5923 . -817) (undo-tree-id5924 . -817) (undo-tree-id5925 . -966) (undo-tree-id5926 . -966) (undo-tree-id5927 . -664) (undo-tree-id5928 . -664) (undo-tree-id5929 . -664) (undo-tree-id5930 . -664) (undo-tree-id5931 . -664) (undo-tree-id5932 . -664) (undo-tree-id5933 . -664) (undo-tree-id5934 . -664) (undo-tree-id5935 . -664) (undo-tree-id5936 . -664) (undo-tree-id5937 . -664) (undo-tree-id5938 . -664) (undo-tree-id5939 . -664) (undo-tree-id5940 . -664) (undo-tree-id5941 . -664) (undo-tree-id5942 . -664) (undo-tree-id5943 . -664) (undo-tree-id5944 . -664) (undo-tree-id5945 . -664) (undo-tree-id5946 . -664) (undo-tree-id5947 . -664) (undo-tree-id5948 . -664) (undo-tree-id5949 . -664) (undo-tree-id5950 . -664) (undo-tree-id5951 . -664) (undo-tree-id5952 . -664) (undo-tree-id5953 . -664) (undo-tree-id5954 . -664) (undo-tree-id5955 . -664) (undo-tree-id5956 . -664) (undo-tree-id5957 . -664) (undo-tree-id5958 . -664) (undo-tree-id5959 . -664) (undo-tree-id5960 . -664) (undo-tree-id5961 . -664) (undo-tree-id5962 . -664) (undo-tree-id5963 . -664) (undo-tree-id5964 . -664) (undo-tree-id5965 . -664) (undo-tree-id5966 . -664) (undo-tree-id5967 . -664) (undo-tree-id5968 . -664) (undo-tree-id5969 . -664) (undo-tree-id5970 . -664) (undo-tree-id5971 . -664) (undo-tree-id5972 . -664) (undo-tree-id5973 . -664) (undo-tree-id5974 . -692) (undo-tree-id5975 . -664) (undo-tree-id5976 . -664) (undo-tree-id5977 . -664) (undo-tree-id5978 . -664) (undo-tree-id5979 . -664) (undo-tree-id5980 . -664) (undo-tree-id5981 . -664) (undo-tree-id5982 . -664) (undo-tree-id5983 . -664) (undo-tree-id5984 . -664) (undo-tree-id5985 . -695) (undo-tree-id5986 . -695) (undo-tree-id5987 . -695) (undo-tree-id5988 . -695) (undo-tree-id5989 . -695) (undo-tree-id5990 . -695) (undo-tree-id5991 . -695) (undo-tree-id5992 . -695) (undo-tree-id5993 . -695) (undo-tree-id5994 . -695) (undo-tree-id5995 . -695) (undo-tree-id5996 . -695) (undo-tree-id5997 . -695) (undo-tree-id5998 . -695) (undo-tree-id5999 . -695) (undo-tree-id6000 . -695) (undo-tree-id6001 . -695) (undo-tree-id6002 . -695) (undo-tree-id6003 . -817) (undo-tree-id6004 . -817) (undo-tree-id6005 . -817) (undo-tree-id6006 . -966) (undo-tree-id6007 . -966) (undo-tree-id6008 . -664) (undo-tree-id6009 . -664) (undo-tree-id6010 . -664) (undo-tree-id6011 . -664) (undo-tree-id6012 . -664) (undo-tree-id6013 . -664) (undo-tree-id6014 . -664) (undo-tree-id6015 . -664) (undo-tree-id6016 . -664) (undo-tree-id6017 . -664) (undo-tree-id6018 . -664) (undo-tree-id6019 . -664) (undo-tree-id6020 . -664) (undo-tree-id6021 . -664) (undo-tree-id6022 . -664) (undo-tree-id6023 . -664) (undo-tree-id6024 . -664) (undo-tree-id6025 . -664) (undo-tree-id6026 . -664) (undo-tree-id6027 . -664) (undo-tree-id6028 . -664) (undo-tree-id6029 . -664) (undo-tree-id6030 . -664) (undo-tree-id6031 . -664) (undo-tree-id6032 . -664) (undo-tree-id6033 . -664) (undo-tree-id6034 . -664) (undo-tree-id6035 . -664) (undo-tree-id6036 . -664) (undo-tree-id6037 . -664) (undo-tree-id6038 . -664) (undo-tree-id6039 . -664) (undo-tree-id6040 . -664) (undo-tree-id6041 . -664) (undo-tree-id6042 . -664) (undo-tree-id6043 . -664) (undo-tree-id6044 . -664) (undo-tree-id6045 . -664) (undo-tree-id6046 . -664) (undo-tree-id6047 . -664) (undo-tree-id6048 . -664) (undo-tree-id6049 . -664) (undo-tree-id6050 . -693) (undo-tree-id6051 . -693) (undo-tree-id6052 . -693) (undo-tree-id6053 . -693) (undo-tree-id6054 . -693) (undo-tree-id6055 . -693) (undo-tree-id6056 . -693) (undo-tree-id6057 . -693) (undo-tree-id6058 . -694) (undo-tree-id6059 . -694) (undo-tree-id6060 . -694) (undo-tree-id6061 . -694) (undo-tree-id6062 . -694) (undo-tree-id6063 . -694) (undo-tree-id6064 . -694) (undo-tree-id6065 . -694) (undo-tree-id6066 . -695) (undo-tree-id6067 . -695) (undo-tree-id6068 . -695) (undo-tree-id6069 . -695) (undo-tree-id6070 . -695) (undo-tree-id6071 . -695) (undo-tree-id6072 . -695) (undo-tree-id6073 . -695) (undo-tree-id6074 . -695) (undo-tree-id6075 . -695) (undo-tree-id6076 . -695) (undo-tree-id6077 . -695) (undo-tree-id6078 . -695) (undo-tree-id6079 . -695) (undo-tree-id6080 . -695) (undo-tree-id6081 . -695) (undo-tree-id6082 . -695) (undo-tree-id6083 . -695) (undo-tree-id6084 . -695) (undo-tree-id6085 . -695) (undo-tree-id6086 . -695) (undo-tree-id6087 . -695) (undo-tree-id6088 . -695) (undo-tree-id6089 . -695) (undo-tree-id6090 . -695) (undo-tree-id6091 . -695) (undo-tree-id6092 . -695) (undo-tree-id6093 . -695) (undo-tree-id6094 . -695) (undo-tree-id6095 . -695) (undo-tree-id6096 . -695) (undo-tree-id6097 . -695) (undo-tree-id6098 . -695) (undo-tree-id6099 . -695) (undo-tree-id6100 . -695) (undo-tree-id6101 . -695) (undo-tree-id6102 . -695) (undo-tree-id6103 . -695) (undo-tree-id6104 . -695) (undo-tree-id6105 . -695) (undo-tree-id6106 . -695) (undo-tree-id6107 . -695) (undo-tree-id6108 . -695) (undo-tree-id6109 . -695) (undo-tree-id6110 . -695) (undo-tree-id6111 . -695) (undo-tree-id6112 . -695) (undo-tree-id6113 . -695) (undo-tree-id6114 . -695) (undo-tree-id6115 . -695) (undo-tree-id6116 . -695) (undo-tree-id6117 . -695) (undo-tree-id6118 . -695) (undo-tree-id6119 . -695) (undo-tree-id6120 . -695) (undo-tree-id6121 . -695) (undo-tree-id6122 . -695) (undo-tree-id6123 . -695) (undo-tree-id6124 . -695) (undo-tree-id6125 . -695) (undo-tree-id6126 . -695) (undo-tree-id6127 . -695) (undo-tree-id6128 . -695) (undo-tree-id6129 . -695) (undo-tree-id6130 . -817) (undo-tree-id6131 . -817) (undo-tree-id6132 . -817) (undo-tree-id6133 . -966) (undo-tree-id6134 . -966) (undo-tree-id6135 . -695) (undo-tree-id6136 . -695) (undo-tree-id6137 . -695) (undo-tree-id6138 . -695) (undo-tree-id6139 . -695) (undo-tree-id6140 . -695) (undo-tree-id6141 . -695) (undo-tree-id6142 . -695) (undo-tree-id6143 . -695) (undo-tree-id6144 . -695) (undo-tree-id6145 . -695) (undo-tree-id6146 . -695) (undo-tree-id6147 . -695) (undo-tree-id6148 . -695) (undo-tree-id6149 . -695) (undo-tree-id6150 . -695) (undo-tree-id6151 . -695) (undo-tree-id6152 . -695) (undo-tree-id6153 . -695) (undo-tree-id6154 . -695) (undo-tree-id6155 . -695) (undo-tree-id6156 . -695) (undo-tree-id6157 . -695) (undo-tree-id6158 . -695) (undo-tree-id6159 . -695) (undo-tree-id6160 . -695) (undo-tree-id6161 . -695) (undo-tree-id6162 . -695) (undo-tree-id6163 . -695) (undo-tree-id6164 . -695) (undo-tree-id6165 . -695) (undo-tree-id6166 . -695) (undo-tree-id6167 . -695) (undo-tree-id6168 . -695) (undo-tree-id6169 . -695) (undo-tree-id6170 . -695) (undo-tree-id6171 . -695) (undo-tree-id6172 . -695) (undo-tree-id6173 . -695) (undo-tree-id6174 . -695) (undo-tree-id6175 . -695) (undo-tree-id6176 . -695) (undo-tree-id6177 . -695) (undo-tree-id6178 . -695) (undo-tree-id6179 . -695) (undo-tree-id6180 . -695) (undo-tree-id6181 . -695) (undo-tree-id6182 . -695) (undo-tree-id6183 . -695) (undo-tree-id6184 . -695) (undo-tree-id6185 . -695) (undo-tree-id6186 . -695) (undo-tree-id6187 . -695) (undo-tree-id6188 . -695) (undo-tree-id6189 . -695) (undo-tree-id6190 . -695) (undo-tree-id6191 . -695) (undo-tree-id6192 . -695) (undo-tree-id6193 . -695) (undo-tree-id6194 . -695) (undo-tree-id6195 . -695) (undo-tree-id6196 . -695) (undo-tree-id6197 . -695) (undo-tree-id6198 . -695) (undo-tree-id6199 . -695) (undo-tree-id6200 . -695) (undo-tree-id6201 . -695) (undo-tree-id6202 . -695) (undo-tree-id6203 . -695) (undo-tree-id6204 . -695) (undo-tree-id6205 . -695) (undo-tree-id6206 . -695) (undo-tree-id6207 . -695) (undo-tree-id6208 . -695) (undo-tree-id6209 . -695) (undo-tree-id6210 . -695) (undo-tree-id6211 . -695) (undo-tree-id6212 . -695) (undo-tree-id6213 . -695) (undo-tree-id6214 . -695) (undo-tree-id6215 . -695) (undo-tree-id6216 . -695) (undo-tree-id6217 . -695) (undo-tree-id6218 . -695) (undo-tree-id6219 . -695) (undo-tree-id6220 . -695) (undo-tree-id6221 . -695) (undo-tree-id6222 . -695) (undo-tree-id6223 . -695) (undo-tree-id6224 . -695) (undo-tree-id6225 . -695) (undo-tree-id6226 . -695) (undo-tree-id6227 . -695) (undo-tree-id6228 . -695) (undo-tree-id6229 . -695) (undo-tree-id6230 . -695) (undo-tree-id6231 . -695) (undo-tree-id6232 . -695) (undo-tree-id6233 . -695) (undo-tree-id6234 . -695) (undo-tree-id6235 . -695) (undo-tree-id6236 . -695) (undo-tree-id6237 . -695) (undo-tree-id6238 . -695) (undo-tree-id6239 . -695) (undo-tree-id6240 . -695) (undo-tree-id6241 . -695) (undo-tree-id6242 . -695) (undo-tree-id6243 . -695) (undo-tree-id6244 . -695) (undo-tree-id6245 . -695) (undo-tree-id6246 . -695) (undo-tree-id6247 . -695) (undo-tree-id6248 . -695) (undo-tree-id6249 . -695) (undo-tree-id6250 . -695) (undo-tree-id6251 . -695) (undo-tree-id6252 . -695) (undo-tree-id6253 . -695) (undo-tree-id6254 . -695) (undo-tree-id6255 . -695) (undo-tree-id6256 . -695) (undo-tree-id6257 . -695) (undo-tree-id6258 . -695) (undo-tree-id6259 . -695) (undo-tree-id6260 . -695) (undo-tree-id6261 . -695) (undo-tree-id6262 . -695) (undo-tree-id6263 . -695) (undo-tree-id6264 . -695) (undo-tree-id6265 . -695) (undo-tree-id6266 . -695) (undo-tree-id6267 . -695) (undo-tree-id6268 . -695) (undo-tree-id6269 . -695) (undo-tree-id6270 . -695) (undo-tree-id6271 . -695) (undo-tree-id6272 . -695) (undo-tree-id6273 . -695) (undo-tree-id6274 . -695) (undo-tree-id6275 . -695) (undo-tree-id6276 . -695) (undo-tree-id6277 . -695) (undo-tree-id6278 . -695) (undo-tree-id6279 . -695) (undo-tree-id6280 . -695) (undo-tree-id6281 . -695) (undo-tree-id6282 . -695) (undo-tree-id6283 . -695) (undo-tree-id6284 . -695) (undo-tree-id6285 . -695) (undo-tree-id6286 . -695) (undo-tree-id6287 . -695) (undo-tree-id6288 . -695) (undo-tree-id6289 . -695) (undo-tree-id6290 . -695) (undo-tree-id6291 . -695) (undo-tree-id6292 . -695) (undo-tree-id6293 . -695) (undo-tree-id6294 . -695) (undo-tree-id6295 . -695) (undo-tree-id6296 . -695) (undo-tree-id6297 . -695) (undo-tree-id6298 . -695) (undo-tree-id6299 . -695) (undo-tree-id6300 . -695) (undo-tree-id6301 . -695) (undo-tree-id6302 . -695) (undo-tree-id6303 . -695) (undo-tree-id6304 . -695) (undo-tree-id6305 . -695) (undo-tree-id6306 . -695) (undo-tree-id6307 . -695) (undo-tree-id6308 . -695) (undo-tree-id6309 . -695) (undo-tree-id6310 . -695) (undo-tree-id6311 . -695) (undo-tree-id6312 . -695) (undo-tree-id6313 . -695) (undo-tree-id6314 . -695) (undo-tree-id6315 . -695) (undo-tree-id6316 . -695) (undo-tree-id6317 . -695) (undo-tree-id6318 . -695) (undo-tree-id6319 . -695) (undo-tree-id6320 . -695) (undo-tree-id6321 . -695) (undo-tree-id6322 . -695) (undo-tree-id6323 . -695) (undo-tree-id6324 . -695) (undo-tree-id6325 . -695) (undo-tree-id6326 . -695) (undo-tree-id6327 . -695) (undo-tree-id6328 . -695) (undo-tree-id6329 . -695) (undo-tree-id6330 . -695) (undo-tree-id6331 . -695) (undo-tree-id6332 . -695) (undo-tree-id6333 . -695) (undo-tree-id6334 . -695) (undo-tree-id6335 . -695) (undo-tree-id6336 . -695) (undo-tree-id6337 . -695) (undo-tree-id6338 . -695) (undo-tree-id6339 . -695) (undo-tree-id6340 . -695) (undo-tree-id6341 . -695) (undo-tree-id6342 . -695) (undo-tree-id6343 . -695) (undo-tree-id6344 . -695) (undo-tree-id6345 . -695) (undo-tree-id6346 . -695) (undo-tree-id6347 . -695) (undo-tree-id6348 . -695) (undo-tree-id6349 . -695) (undo-tree-id6350 . -695) (undo-tree-id6351 . -695) (undo-tree-id6352 . -695) (undo-tree-id6353 . -695) (undo-tree-id6354 . -695) (undo-tree-id6355 . -695) (undo-tree-id6356 . -695) (undo-tree-id6357 . -695) (undo-tree-id6358 . -695) (undo-tree-id6359 . -695) (undo-tree-id6360 . -695) (undo-tree-id6361 . -695) (undo-tree-id6362 . -695) (undo-tree-id6363 . -695) (undo-tree-id6364 . -695) (undo-tree-id6365 . -695) (undo-tree-id6366 . -695) (undo-tree-id6367 . -695) (undo-tree-id6368 . -695) (undo-tree-id6369 . -695) (undo-tree-id6370 . -1726) (undo-tree-id6371 . -1726) (undo-tree-id6372 . -1726) (undo-tree-id6373 . -1726) (undo-tree-id6374 . -695) (undo-tree-id6375 . -695) (undo-tree-id6376 . -695) (undo-tree-id6377 . -695) (undo-tree-id6378 . -695) (undo-tree-id6379 . -695) (undo-tree-id6380 . -695) (undo-tree-id6381 . -695) (undo-tree-id6382 . -695) (undo-tree-id6383 . -817) (undo-tree-id6384 . -817) (undo-tree-id6385 . -817) (undo-tree-id6386 . -966) (undo-tree-id6387 . -966) (undo-tree-id6388 . -1726) (undo-tree-id6389 . -1726) (undo-tree-id6390 . -1726) (undo-tree-id6391 . -1726) (undo-tree-id6392 . -695) (undo-tree-id6393 . -695) (undo-tree-id6394 . -695) (undo-tree-id6395 . -695) (undo-tree-id6396 . -695) (undo-tree-id6397 . -695) (undo-tree-id6398 . -695) (undo-tree-id6399 . -695) (undo-tree-id6400 . -695) (undo-tree-id6401 . -695) (undo-tree-id6402 . -695) (undo-tree-id6403 . -695) (undo-tree-id6404 . -695) (undo-tree-id6405 . -695) (undo-tree-id6406 . -695) (undo-tree-id6407 . -695) (undo-tree-id6408 . -695) (undo-tree-id6409 . -695) (undo-tree-id6410 . -695) (undo-tree-id6411 . -695) (undo-tree-id6412 . -695) (undo-tree-id6413 . -695) (undo-tree-id6414 . -695) (undo-tree-id6415 . -695) (undo-tree-id6416 . -695) (undo-tree-id6417 . -695) (undo-tree-id6418 . -695) (undo-tree-id6419 . -695) (undo-tree-id6420 . -695) (undo-tree-id6421 . -695) (undo-tree-id6422 . -695) (undo-tree-id6423 . -695) (undo-tree-id6424 . -695) (undo-tree-id6425 . -695) (undo-tree-id6426 . -695) (undo-tree-id6427 . -695) (undo-tree-id6428 . -695) (undo-tree-id6429 . -1) (undo-tree-id6430 . -1) (undo-tree-id6431 . -23) (undo-tree-id6432 . -27) (undo-tree-id6433 . -51) (undo-tree-id6434 . -57) (undo-tree-id6435 . -51) (undo-tree-id6436 . -57) (undo-tree-id6437 . -66) (undo-tree-id6438 . -72) (undo-tree-id6439 . -90) (undo-tree-id6440 . -94) (undo-tree-id6441 . -119) (undo-tree-id6442 . -125) (undo-tree-id6443 . -138) (undo-tree-id6444 . -142) (undo-tree-id6445 . -259) (undo-tree-id6446 . -265) (undo-tree-id6447 . -259) (undo-tree-id6448 . -265) (undo-tree-id6449 . -284) (undo-tree-id6450 . -290) (undo-tree-id6451 . -284) (undo-tree-id6452 . -290) (undo-tree-id6453 . -408) (undo-tree-id6454 . -415) (undo-tree-id6455 . -696) (undo-tree-id6456 . -699) (undo-tree-id6457 . -883) (undo-tree-id6458 . -884) (undo-tree-id6459 . -883) (undo-tree-id6460 . -884) (undo-tree-id6461 . -883) (undo-tree-id6462 . -884) (undo-tree-id6463 . -937) (undo-tree-id6464 . -938) (undo-tree-id6465 . -953) (undo-tree-id6466 . -954) (undo-tree-id6467 . -941) (undo-tree-id6468 . -947) (undo-tree-id6469 . -1564) (undo-tree-id6470 . -1565) (undo-tree-id6471 . -1576) (undo-tree-id6472 . -1578) (undo-tree-id6473 . -2409) (undo-tree-id6474 . -2410) (undo-tree-id6475 . -2552) (undo-tree-id6476 . -2553) (undo-tree-id6477 . -2552) (undo-tree-id6478 . -2553) (undo-tree-id6479 . -3159) (undo-tree-id6480 . -3160) (undo-tree-id6481 . -3898) (undo-tree-id6482 . -3899) (undo-tree-id6483 . -4582) (undo-tree-id6484 . -4583) (undo-tree-id6485 . -5520) (undo-tree-id6486 . -5521) (undo-tree-id6487 . -5658) (undo-tree-id6488 . -5659) (undo-tree-id6489 . -5658) (undo-tree-id6490 . -5659) (undo-tree-id6491 . -5658) (undo-tree-id6492 . -5659) (undo-tree-id6493 . -5658) (undo-tree-id6494 . -5659) (undo-tree-id6495 . -5658) (undo-tree-id6496 . -5659) (undo-tree-id6497 . -5658) (undo-tree-id6498 . -5659) (undo-tree-id6499 . -5658) (undo-tree-id6500 . -5659) (undo-tree-id6501 . -5662) (undo-tree-id6502 . -5668) (undo-tree-id6503 . -6057) (undo-tree-id6504 . -6058) (undo-tree-id6505 . -6185) (undo-tree-id6506 . -6186) (undo-tree-id6507 . -6213) (undo-tree-id6508 . -6214) (undo-tree-id6509 . -6626) (undo-tree-id6510 . -6627) (undo-tree-id6511 . -7330) (undo-tree-id6512 . -7331) (undo-tree-id6513 . -8027) (undo-tree-id6514 . -8029) (undo-tree-id6515 . -8470) (undo-tree-id6516 . -8471) (undo-tree-id6517 . -8526) (undo-tree-id6518 . -8531) (undo-tree-id6519 . -8982) (undo-tree-id6520 . -8983) (undo-tree-id6521 . -9330) (undo-tree-id6522 . -9335) (undo-tree-id6523 . -9322) (undo-tree-id6524 . -9323) (undo-tree-id6525 . -9330) (undo-tree-id6526 . -9335) (undo-tree-id6527 . -9299) (undo-tree-id6528 . -9322) (undo-tree-id6529 . -9400) (undo-tree-id6530 . -9402) (undo-tree-id6531 . -10552) (undo-tree-id6532 . -10553) (undo-tree-id6533 . -10913) (undo-tree-id6534 . -10914) (undo-tree-id6535 . -10913) (undo-tree-id6536 . -10914) (undo-tree-id6537 . -10913) (undo-tree-id6538 . -10914) (undo-tree-id6539 . -10913) (undo-tree-id6540 . -10914) (undo-tree-id6541 . -10946) (undo-tree-id6542 . -10948) (undo-tree-id6543 . -11261) (undo-tree-id6544 . -11262) (undo-tree-id6545 . -11260) (undo-tree-id6546 . -11261) (undo-tree-id6547 . -11425) (undo-tree-id6548 . -11426) (undo-tree-id6549 . -11425) (undo-tree-id6550 . -11426) (undo-tree-id6551 . -11425) (undo-tree-id6552 . -11426) (undo-tree-id6553 . -11441) (undo-tree-id6554 . -11447) (undo-tree-id6555 . -12098) (undo-tree-id6556 . -12099) (undo-tree-id6557 . -12386) (undo-tree-id6558 . -12387) (undo-tree-id6559 . -12725) (undo-tree-id6560 . -12726) (undo-tree-id6561 . -12725) (undo-tree-id6562 . -12726) (undo-tree-id6563 . -12776) (undo-tree-id6564 . -12778) (undo-tree-id6565 . -12760) (undo-tree-id6566 . -12766) (undo-tree-id6567 . -12828) (undo-tree-id6568 . -12833) (undo-tree-id6569 . -13203) (undo-tree-id6570 . -13204) (undo-tree-id6571 . -13672) (undo-tree-id6572 . -13673) (undo-tree-id6573 . -13989) (undo-tree-id6574 . -13990) (undo-tree-id6575 . -14854) (undo-tree-id6576 . -14855) (undo-tree-id6577 . -16867) (undo-tree-id6578 . -16870) (undo-tree-id6579 . -18107) (undo-tree-id6580 . -18108) (undo-tree-id6581 . -18238) (undo-tree-id6582 . -18239) (undo-tree-id6583 . -18353) (undo-tree-id6584 . -18354) (undo-tree-id6585 . -18427) (undo-tree-id6586 . -18428) (undo-tree-id6587 . -18427) (undo-tree-id6588 . -18428) (undo-tree-id6589 . -18428) (undo-tree-id6590 . -18446) (undo-tree-id6591 . -18802) (undo-tree-id6592 . -18824) (undo-tree-id6593 . -18802) (undo-tree-id6594 . -18824) (undo-tree-id6595 . -18828) (undo-tree-id6596 . -18837) (undo-tree-id6597 . -18788) (undo-tree-id6598 . -18789) (undo-tree-id6599 . -18858) (undo-tree-id6600 . -18870) (undo-tree-id6601 . -18858) (undo-tree-id6602 . -18870) (undo-tree-id6603 . -19017) (undo-tree-id6604 . -19024) (undo-tree-id6605 . -19098) (undo-tree-id6606 . -19099) (undo-tree-id6607 . -19336) (undo-tree-id6608 . -19337) (undo-tree-id6609 . -19815) (undo-tree-id6610 . -19816) (undo-tree-id6611 . -19816) (undo-tree-id6612 . -19817) (undo-tree-id6613 . -19839) (undo-tree-id6614 . -19840) (undo-tree-id6615 . -20589) (undo-tree-id6616 . -20590) (undo-tree-id6617 . -20601) (undo-tree-id6618 . -20602) (undo-tree-id6619 . -20826) (undo-tree-id6620 . -20837) (undo-tree-id6621 . -20839) (undo-tree-id6622 . -20840) (undo-tree-id6623 . -21244) (undo-tree-id6624 . -21245) (undo-tree-id6625 . -21278) (undo-tree-id6626 . -21279) (undo-tree-id6627 . -21348) (undo-tree-id6628 . -21349) (undo-tree-id6629 . -21530) (undo-tree-id6630 . -21531) (undo-tree-id6631 . -22017) (undo-tree-id6632 . -22018) (undo-tree-id6633 . -22286) (undo-tree-id6634 . -22293) (undo-tree-id6635 . -22286) (undo-tree-id6636 . -22293) (undo-tree-id6637 . -22286) (undo-tree-id6638 . -22293) (undo-tree-id6639 . -22286) (undo-tree-id6640 . -22293) (undo-tree-id6641 . -22286) (undo-tree-id6642 . -22293) (undo-tree-id6643 . -22286) (undo-tree-id6644 . -22293) (undo-tree-id6645 . -22286) (undo-tree-id6646 . -22293) (undo-tree-id6647 . -22286) (undo-tree-id6648 . -22293) (undo-tree-id6649 . -22286) (undo-tree-id6650 . -22293) (undo-tree-id6651 . -22372) (undo-tree-id6652 . -22373) (undo-tree-id6653 . -22373) (undo-tree-id6654 . -22374) (undo-tree-id6655 . -22378) (undo-tree-id6656 . -22379) (undo-tree-id6657 . -22548) (undo-tree-id6658 . -22549) (undo-tree-id6659 . -22548) (undo-tree-id6660 . -22549) (undo-tree-id6661 . -23670) (undo-tree-id6662 . -23671) (undo-tree-id6663 . -24004) (undo-tree-id6664 . -24005) (undo-tree-id6665 . -24006) (undo-tree-id6666 . -24007) (undo-tree-id6667 . -24006) (undo-tree-id6668 . -24007) (undo-tree-id6669 . -23986) (undo-tree-id6670 . -23989) (undo-tree-id6671 . -24050) (undo-tree-id6672 . -24051) (undo-tree-id6673 . -24918) (undo-tree-id6674 . -24927) (undo-tree-id6675 . -25607) (undo-tree-id6676 . -25608) (undo-tree-id6677 . -26987) (undo-tree-id6678 . -26988) (undo-tree-id6679 . -27108) (undo-tree-id6680 . -27109) (undo-tree-id6681 . -27108) (undo-tree-id6682 . -27109) (undo-tree-id6683 . -27209) (undo-tree-id6684 . -27221) (undo-tree-id6685 . -27251) (undo-tree-id6686 . -27258) (undo-tree-id6687 . -27456) (undo-tree-id6688 . -27466) (undo-tree-id6689 . -28013) (undo-tree-id6690 . -28014) (undo-tree-id6691 . -28013) (undo-tree-id6692 . -28014) (undo-tree-id6693 . -28104) (undo-tree-id6694 . -28105) (undo-tree-id6695 . -28492) (undo-tree-id6696 . -28493) (undo-tree-id6697 . -29451) (undo-tree-id6698 . -29452) (undo-tree-id6699 . -29613) (undo-tree-id6700 . -29614) (undo-tree-id6701 . -29613) (undo-tree-id6702 . -29614) (undo-tree-id6703 . -29740) (undo-tree-id6704 . -29741) (undo-tree-id6705 . -29735) (undo-tree-id6706 . -29736) (undo-tree-id6707 . -29940) (undo-tree-id6708 . -29941) (undo-tree-id6709 . -30371) (undo-tree-id6710 . -30372) (undo-tree-id6711 . -31420) (undo-tree-id6712 . -31425) (undo-tree-id6713 . -31355) (undo-tree-id6714 . -31356) (undo-tree-id6715 . -31507) (undo-tree-id6716 . -31510) (undo-tree-id6717 . -31579) (undo-tree-id6718 . -31580) (undo-tree-id6719 . -31859) (undo-tree-id6720 . -31860) (undo-tree-id6721 . -31865) (undo-tree-id6722 . -31878) (undo-tree-id6723 . -32216) (undo-tree-id6724 . -32217) (undo-tree-id6725 . -32266) (undo-tree-id6726 . -32267) (undo-tree-id6727 . -32336) (undo-tree-id6728 . -32337) (undo-tree-id6729 . -32558) (undo-tree-id6730 . -32559) (undo-tree-id6731 . -32604) (undo-tree-id6732 . -32605) (undo-tree-id6733 . -32604) (undo-tree-id6734 . -32605) (undo-tree-id6735 . -32609) (undo-tree-id6736 . -32617) (undo-tree-id6737 . -32609) (undo-tree-id6738 . -32617) (undo-tree-id6739 . -32796) (undo-tree-id6740 . -32797) (undo-tree-id6741 . -32994) (undo-tree-id6742 . -32995) (undo-tree-id6743 . -32994) (undo-tree-id6744 . -32995) (undo-tree-id6745 . -33025) (undo-tree-id6746 . -33026) (undo-tree-id6747 . -33261) (undo-tree-id6748 . -33262) (undo-tree-id6749 . -35257) (undo-tree-id6750 . -35258) (undo-tree-id6751 . -35286) (undo-tree-id6752 . -35287) (undo-tree-id6753 . -35381) (undo-tree-id6754 . -35382) (undo-tree-id6755 . -35546) (undo-tree-id6756 . -35547) (undo-tree-id6757 . -37343) (undo-tree-id6758 . -37344) (undo-tree-id6759 . -37485) (undo-tree-id6760 . -37486) (undo-tree-id6761 . -37847) (undo-tree-id6762 . -37848) (undo-tree-id6763 . -37883) (undo-tree-id6764 . -37894) (undo-tree-id6765 . -37924) (undo-tree-id6766 . -37925) (undo-tree-id6767 . -38130) (undo-tree-id6768 . -38131) (undo-tree-id6769 . -38130) (undo-tree-id6770 . -38131) (undo-tree-id6771 . -38130) (undo-tree-id6772 . -38131) (undo-tree-id6773 . -38211) (undo-tree-id6774 . -38212) (undo-tree-id6775 . -38211) (undo-tree-id6776 . -38212) (undo-tree-id6777 . -38212) (undo-tree-id6778 . -38213) (undo-tree-id6779 . -38656) (undo-tree-id6780 . -38662) (undo-tree-id6781 . -38656) (undo-tree-id6782 . -38662) (undo-tree-id6783 . -39283) (undo-tree-id6784 . -39286) (undo-tree-id6785 . -39799) (undo-tree-id6786 . -39800) (undo-tree-id6787 . -40338) (undo-tree-id6788 . -40339) (undo-tree-id6789 . -40340) (undo-tree-id6790 . -40359) (undo-tree-id6791 . -40494) (undo-tree-id6792 . -40495) (undo-tree-id6793 . -40494) (undo-tree-id6794 . -40495) (undo-tree-id6795 . -40494) (undo-tree-id6796 . -40495) (undo-tree-id6797 . -40581) (undo-tree-id6798 . -40592) (undo-tree-id6799 . -40581) (undo-tree-id6800 . -40592) (undo-tree-id6801 . -40644) (undo-tree-id6802 . -40645) (undo-tree-id6803 . -40658) (undo-tree-id6804 . -40659) (undo-tree-id6805 . -40658) (undo-tree-id6806 . -40659) (undo-tree-id6807 . -40800) (undo-tree-id6808 . -40801) (undo-tree-id6809 . -40981) (undo-tree-id6810 . -40982) (undo-tree-id6811 . -41056) (undo-tree-id6812 . -41057) (undo-tree-id6813 . -695) (undo-tree-id6814 . -695) (undo-tree-id6815 . -695) (undo-tree-id6816 . -695) (undo-tree-id6817 . -695) (undo-tree-id6818 . -695) (undo-tree-id6819 . -695) (undo-tree-id6820 . -695) (undo-tree-id6821 . -695) (undo-tree-id6822 . -695) (undo-tree-id6823 . -817) (undo-tree-id6824 . -817) (undo-tree-id6825 . -817) (undo-tree-id6826 . -966) (undo-tree-id6827 . -966) (undo-tree-id6828 . -1726) (undo-tree-id6829 . -1726) (undo-tree-id6830 . -1726) (undo-tree-id6831 . -1726) (undo-tree-id6832 . -695) (undo-tree-id6833 . -695) (undo-tree-id6834 . -695) (undo-tree-id6835 . -695) (undo-tree-id6836 . -695) (undo-tree-id6837 . -695) (undo-tree-id6838 . -695) (undo-tree-id6839 . -695) (undo-tree-id6840 . -23) (undo-tree-id6841 . -27) (undo-tree-id6842 . -51) (undo-tree-id6843 . -57) (undo-tree-id6844 . -259) (undo-tree-id6845 . -265) (undo-tree-id6846 . -284) (undo-tree-id6847 . -290) (undo-tree-id6848 . -430) (undo-tree-id6849 . -450) (undo-tree-id6850 . -696) (undo-tree-id6851 . -699) (undo-tree-id6852 . -817) (undo-tree-id6853 . -828) (undo-tree-id6854 . -966) (undo-tree-id6855 . -974) (undo-tree-id6856 . -1087) (undo-tree-id6857 . -1096) (undo-tree-id6858 . -1470) (undo-tree-id6859 . -1481) (undo-tree-id6860 . -1845) (undo-tree-id6861 . -1852) (undo-tree-id6862 . -2112) (undo-tree-id6863 . -2116) (undo-tree-id6864 . -2455) (undo-tree-id6865 . -2466) (undo-tree-id6866 . -2686) (undo-tree-id6867 . -2687) (undo-tree-id6868 . -2869) (undo-tree-id6869 . -2876) (undo-tree-id6870 . -3072) (undo-tree-id6871 . -3083) (undo-tree-id6872 . -3333) (undo-tree-id6873 . -3334) (undo-tree-id6874 . -3558) (undo-tree-id6875 . -3565) (undo-tree-id6876 . -3761) (undo-tree-id6877 . -3772) (undo-tree-id6878 . -4072) (undo-tree-id6879 . -4073) (undo-tree-id6880 . -4270) (undo-tree-id6881 . -4277) (undo-tree-id6882 . -4473) (undo-tree-id6883 . -4484) (undo-tree-id6884 . -4672) (undo-tree-id6885 . -4675) (undo-tree-id6886 . -4686) (undo-tree-id6887 . -4706) (undo-tree-id6888 . -5096) (undo-tree-id6889 . -5107) (undo-tree-id6890 . -5196) (undo-tree-id6891 . -5202) (undo-tree-id6892 . -5477) (undo-tree-id6893 . -5485) (undo-tree-id6894 . -5597) (undo-tree-id6895 . -5607) (undo-tree-id6896 . -5701) (undo-tree-id6897 . -5721) (undo-tree-id6898 . -6365) (undo-tree-id6899 . -6371) (undo-tree-id6900 . -6854) (undo-tree-id6901 . -6861) (undo-tree-id6902 . -7108) (undo-tree-id6903 . -7109) (undo-tree-id6904 . -7307) (undo-tree-id6905 . -7314) (undo-tree-id6906 . -7360) (undo-tree-id6907 . -7380) (undo-tree-id6908 . -7643) (undo-tree-id6909 . -7647) (undo-tree-id6910 . -8069) (undo-tree-id6911 . -8089) (undo-tree-id6912 . -8338) (undo-tree-id6913 . -8339) (undo-tree-id6914 . -8644) (undo-tree-id6915 . -8645) (undo-tree-id6916 . -9093) (undo-tree-id6917 . -9100) (undo-tree-id6918 . -9146) (undo-tree-id6919 . -9166) (undo-tree-id6920 . -9561) (undo-tree-id6921 . -9562) (undo-tree-id6922 . -9929) (undo-tree-id6923 . -9936) (undo-tree-id6924 . -9984) (undo-tree-id6925 . -9988) (undo-tree-id6926 . -10332) (undo-tree-id6927 . -10336) (undo-tree-id6928 . -11414) (undo-tree-id6929 . -11421) (undo-tree-id6930 . -11968) (undo-tree-id6931 . -11969) (undo-tree-id6932 . -12899) (undo-tree-id6933 . -12900) (undo-tree-id6934 . -13181) (undo-tree-id6935 . -13188) (undo-tree-id6936 . -13649) (undo-tree-id6937 . -13656) (undo-tree-id6938 . -13849) (undo-tree-id6939 . -13869) (undo-tree-id6940 . -14514) (undo-tree-id6941 . -14521) (undo-tree-id6942 . -14714) (undo-tree-id6943 . -14734) (undo-tree-id6944 . -15843) (undo-tree-id6945 . -15844) (undo-tree-id6946 . -16215) (undo-tree-id6947 . -16216) (undo-tree-id6948 . -17308) (undo-tree-id6949 . -17315) (undo-tree-id6950 . -17398) (undo-tree-id6951 . -17403) (undo-tree-id6952 . -18177) (undo-tree-id6953 . -18190) (undo-tree-id6954 . -19096) (undo-tree-id6955 . -19097) (undo-tree-id6956 . -19324) (undo-tree-id6957 . -19331) (undo-tree-id6958 . -19415) (undo-tree-id6959 . -19416) (undo-tree-id6960 . -19993) (undo-tree-id6961 . -19995) (undo-tree-id6962 . -20097) (undo-tree-id6963 . -20100) (undo-tree-id6964 . -20574) (undo-tree-id6965 . -20581) (undo-tree-id6966 . -20714) (undo-tree-id6967 . -20722) (undo-tree-id6968 . -20808) (undo-tree-id6969 . -20809) (undo-tree-id6970 . -22085) (undo-tree-id6971 . -22099) (undo-tree-id6972 . -24179) (undo-tree-id6973 . -24185) (undo-tree-id6974 . -25199) (undo-tree-id6975 . -25216) (undo-tree-id6976 . -25632) (undo-tree-id6977 . -25633) (undo-tree-id6978 . -26076) (undo-tree-id6979 . -26081) (undo-tree-id6980 . -27535) (undo-tree-id6981 . -27541) (undo-tree-id6982 . -27908) (undo-tree-id6983 . -27911) (undo-tree-id6984 . -28300) (undo-tree-id6985 . -28310) (undo-tree-id6986 . -28494) (undo-tree-id6987 . -28498) (undo-tree-id6988 . -29714) (undo-tree-id6989 . -29715) (undo-tree-id6990 . -30019) (undo-tree-id6991 . -30023) (undo-tree-id6992 . -30277) (undo-tree-id6993 . -30284) (undo-tree-id6994 . -30327) (undo-tree-id6995 . -30334) (undo-tree-id6996 . -30578) (undo-tree-id6997 . -30581) (undo-tree-id6998 . -31428) (undo-tree-id6999 . -31438) (undo-tree-id7000 . -31656) (undo-tree-id7001 . -31661) (undo-tree-id7002 . -32098) (undo-tree-id7003 . -32104) (undo-tree-id7004 . -32552) (undo-tree-id7005 . -32556) (undo-tree-id7006 . -33372) (undo-tree-id7007 . -33377) (undo-tree-id7008 . -34102) (undo-tree-id7009 . -34110) (undo-tree-id7010 . -34410) (undo-tree-id7011 . -34414) (undo-tree-id7012 . -34872) (undo-tree-id7013 . -34876) (undo-tree-id7014 . -35020) (undo-tree-id7015 . -35033) (undo-tree-id7016 . -35187) (undo-tree-id7017 . -35200) (undo-tree-id7018 . -35354) (undo-tree-id7019 . -35367) (undo-tree-id7020 . -35773) (undo-tree-id7021 . -35781) (undo-tree-id7022 . -35925) (undo-tree-id7023 . -35930) (undo-tree-id7024 . -36223) (undo-tree-id7025 . -36224) (undo-tree-id7026 . -36438) (undo-tree-id7027 . -36439) (undo-tree-id7028 . -36731) (undo-tree-id7029 . -36732) (undo-tree-id7030 . -37069) (undo-tree-id7031 . -37071) (undo-tree-id7032 . -37744) (undo-tree-id7033 . -37745) (undo-tree-id7034 . -38001) (undo-tree-id7035 . -38009) (undo-tree-id7036 . -38291) (undo-tree-id7037 . -38296) (undo-tree-id7038 . -38717) (undo-tree-id7039 . -38724) (undo-tree-id7040 . -39996) (undo-tree-id7041 . -39999) (undo-tree-id7042 . -40276) (undo-tree-id7043 . -40289) (undo-tree-id7044 . -40419) (undo-tree-id7045 . -40420) (undo-tree-id7046 . -40575) (undo-tree-id7047 . -40576) (undo-tree-id7048 . -40738) (undo-tree-id7049 . -40739) (undo-tree-id7050 . -40879) (undo-tree-id7051 . -40887) (undo-tree-id7052 . -695) (undo-tree-id7053 . -695) (undo-tree-id7054 . -695) (undo-tree-id7055 . -695) (undo-tree-id7056 . -695) (undo-tree-id7057 . -695) (undo-tree-id7058 . -695) (undo-tree-id7059 . -695) (undo-tree-id7060 . -695) (undo-tree-id7061 . -695) (undo-tree-id7062 . -695) (undo-tree-id7063 . -695) (undo-tree-id7064 . -695) (undo-tree-id7065 . -406) (undo-tree-id7066 . -695) (undo-tree-id7067 . -695) (undo-tree-id7068 . -695) (undo-tree-id7069 . -695) (undo-tree-id7070 . -695) (undo-tree-id7071 . -695) (undo-tree-id7072 . -695) (undo-tree-id7073 . -695) (undo-tree-id7074 . -695) (undo-tree-id7075 . -695) (undo-tree-id7076 . -695) (undo-tree-id7077 . -695) (undo-tree-id7078 . -695) (undo-tree-id7079 . -695) (undo-tree-id7080 . -695) (undo-tree-id7081 . -695) (undo-tree-id7082 . -406) (undo-tree-id7083 . -695) (undo-tree-id7084 . -695) (undo-tree-id7085 . -695) (undo-tree-id7086 . -695)) nil (25760 29907 548429 19000) 0 nil])
([nil nil ((#("# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 263 (fontified t face font-lock-comment-face)) . 1008) (undo-tree-id7615 . -262) (undo-tree-id7616 . -138) (undo-tree-id7617 . -2) (undo-tree-id7618 . -2) (undo-tree-id7619 . -2) (undo-tree-id7620 . -2) (undo-tree-id7621 . -2) (undo-tree-id7622 . -2) (undo-tree-id7623 . -2) (undo-tree-id7624 . -2) (undo-tree-id7625 . -2) (undo-tree-id7626 . -2) (undo-tree-id7627 . -2) (undo-tree-id7628 . -2) (undo-tree-id7629 . -2) (undo-tree-id7630 . -2) (undo-tree-id7631 . -2) (undo-tree-id7632 . -2) (undo-tree-id7633 . -2) (undo-tree-id7634 . -2) (undo-tree-id7635 . -2) (undo-tree-id7636 . -2) (undo-tree-id7637 . -2) (undo-tree-id7638 . -2) (undo-tree-id7639 . -2) (undo-tree-id7640 . -2) (undo-tree-id7641 . -2) (undo-tree-id7642 . -2) (undo-tree-id7643 . -2) (undo-tree-id7644 . -2) (undo-tree-id7645 . -2) (undo-tree-id7646 . -2) (undo-tree-id7647 . -2) (undo-tree-id7648 . -2) (undo-tree-id7649 . -2) (undo-tree-id7650 . -2) (undo-tree-id7651 . -2) (undo-tree-id7652 . -2) (undo-tree-id7653 . -2) (undo-tree-id7654 . -2) (undo-tree-id7655 . -2) (undo-tree-id7656 . -2) (undo-tree-id7657 . -2) (undo-tree-id7658 . -2) (undo-tree-id7659 . -2) (undo-tree-id7660 . -2) (undo-tree-id7661 . -2) (undo-tree-id7662 . -2) (undo-tree-id7663 . -2) (undo-tree-id7664 . -4) (undo-tree-id7665 . -4) (undo-tree-id7666 . -4) (undo-tree-id7667 . -4) (undo-tree-id7668 . -4) (undo-tree-id7669 . -4) (undo-tree-id7670 . -4) (undo-tree-id7671 . -4) (undo-tree-id7672 . -4) (undo-tree-id7673 . -4) (undo-tree-id7674 . -4) (undo-tree-id7675 . -4) (undo-tree-id7676 . -4) (undo-tree-id7677 . -4) (undo-tree-id7678 . -4) (undo-tree-id7679 . -4) (undo-tree-id7680 . -4) (undo-tree-id7681 . -4) (undo-tree-id7682 . -4) (undo-tree-id7683 . -4) (undo-tree-id7684 . -4) (undo-tree-id7685 . -4) (undo-tree-id7686 . -4) (undo-tree-id7687 . -4) (undo-tree-id7688 . -4) (undo-tree-id7689 . -4) (undo-tree-id7690 . -4) (undo-tree-id7691 . -4) (undo-tree-id7692 . -4) (undo-tree-id7693 . -4) (undo-tree-id7694 . -4) (undo-tree-id7695 . -4) (undo-tree-id7696 . -4) (undo-tree-id7697 . -4) (undo-tree-id7698 . -4) (undo-tree-id7699 . -4) (undo-tree-id7700 . -4) (undo-tree-id7701 . -4) (undo-tree-id7702 . -4) (undo-tree-id7703 . -4) (undo-tree-id7704 . -4) (undo-tree-id7705 . -4) (undo-tree-id7706 . -4) (undo-tree-id7707 . -4) (undo-tree-id7708 . -4) (undo-tree-id7709 . -4) (undo-tree-id7710 . -4) (undo-tree-id7711 . -4) (undo-tree-id7712 . -4) (undo-tree-id7713 . -4) (undo-tree-id7714 . -4) (undo-tree-id7715 . -4) (undo-tree-id7716 . -4) (undo-tree-id7717 . -4) (undo-tree-id7718 . -4) (undo-tree-id7719 . -4) (undo-tree-id7720 . -4) (undo-tree-id7721 . -4) (undo-tree-id7722 . -4) (undo-tree-id7723 . -4) (undo-tree-id7724 . -4) (undo-tree-id7725 . -4) (undo-tree-id7726 . -4) (undo-tree-id7727 . -4) (undo-tree-id7728 . -4) (undo-tree-id7729 . -4) (undo-tree-id7730 . -4) (undo-tree-id7731 . -4) (undo-tree-id7732 . -4) (undo-tree-id7733 . -4) (undo-tree-id7734 . -4) (undo-tree-id7735 . -4) (undo-tree-id7736 . -4) (undo-tree-id7737 . -4) (undo-tree-id7738 . -4) (undo-tree-id7739 . -4) (undo-tree-id7740 . -4) (undo-tree-id7741 . -4) (undo-tree-id7742 . -4) (undo-tree-id7743 . -4) (undo-tree-id7744 . -4) (undo-tree-id7745 . -4) (undo-tree-id7746 . -4) (undo-tree-id7747 . -4) (undo-tree-id7748 . -4) (undo-tree-id7749 . -4) (undo-tree-id7750 . -4) (undo-tree-id7751 . -4) (undo-tree-id7752 . -4) (undo-tree-id7753 . -4) (undo-tree-id7754 . -4) (undo-tree-id7755 . -4) (undo-tree-id7756 . -4) (undo-tree-id7757 . -4) (undo-tree-id7758 . -4) (undo-tree-id7759 . -4) (undo-tree-id7760 . -4) (undo-tree-id7761 . -4) (undo-tree-id7762 . -4) (undo-tree-id7763 . -4) (undo-tree-id7764 . -71) (undo-tree-id7765 . -71) (undo-tree-id7766 . -71) (undo-tree-id7767 . -71) (undo-tree-id7768 . -71) (undo-tree-id7769 . -71) (undo-tree-id7770 . -71) (undo-tree-id7771 . -71) (undo-tree-id7772 . -71) (undo-tree-id7773 . -71) (undo-tree-id7774 . -71) (undo-tree-id7775 . -71) (undo-tree-id7776 . -71) (undo-tree-id7777 . -71) (undo-tree-id7778 . -71) (undo-tree-id7779 . -71) (undo-tree-id7780 . -71) (undo-tree-id7781 . -71) (undo-tree-id7782 . -71) (undo-tree-id7783 . -71) (undo-tree-id7784 . -71) (undo-tree-id7785 . -71) (undo-tree-id7786 . -71) (undo-tree-id7787 . -71) (undo-tree-id7788 . -71) (undo-tree-id7789 . -71) (undo-tree-id7790 . -71) (undo-tree-id7791 . -71) (undo-tree-id7792 . -71) (undo-tree-id7793 . -138) (undo-tree-id7794 . -138) (undo-tree-id7795 . -138) (undo-tree-id7796 . -138) (undo-tree-id7797 . -138) (undo-tree-id7798 . -138) (undo-tree-id7799 . -138) (undo-tree-id7800 . -138) (undo-tree-id7801 . -138) (undo-tree-id7802 . -138) (undo-tree-id7803 . -138) (undo-tree-id7804 . -138) (undo-tree-id7805 . -138) (undo-tree-id7806 . -138) (undo-tree-id7807 . -138) (undo-tree-id7808 . -138) (undo-tree-id7809 . -138) (undo-tree-id7810 . -138) (undo-tree-id7811 . -138) (undo-tree-id7812 . -138) (undo-tree-id7813 . -138) (undo-tree-id7814 . -138) (undo-tree-id7815 . -138) (undo-tree-id7816 . -138) (undo-tree-id7817 . -138) (undo-tree-id7818 . -138) (undo-tree-id7819 . -138) (undo-tree-id7820 . -138) (undo-tree-id7821 . -138) (undo-tree-id7822 . -138) (undo-tree-id7823 . -138) (undo-tree-id7824 . -138) (undo-tree-id7825 . -138) (undo-tree-id7826 . -138) (undo-tree-id7827 . -138) (undo-tree-id7828 . -138) (undo-tree-id7829 . -138) (undo-tree-id7830 . -138) (undo-tree-id7831 . -138) (undo-tree-id7832 . -138) (undo-tree-id7833 . -138) (undo-tree-id7834 . -138) (undo-tree-id7835 . -138) (undo-tree-id7836 . -138) (undo-tree-id7837 . -138) (undo-tree-id7838 . -138) (undo-tree-id7839 . -138) (undo-tree-id7840 . -138) (undo-tree-id7841 . -138) (undo-tree-id7842 . -138) (undo-tree-id7843 . -138) (undo-tree-id7844 . -138) (undo-tree-id7845 . -138) (undo-tree-id7846 . -138) (undo-tree-id7847 . -138) (undo-tree-id7848 . -138) (undo-tree-id7849 . -138) (undo-tree-id7850 . -138) (undo-tree-id7851 . -138) (undo-tree-id7852 . -138) (undo-tree-id7853 . -138) (undo-tree-id7854 . -138) (undo-tree-id7855 . -138) (undo-tree-id7856 . -138) (undo-tree-id7857 . -138) (undo-tree-id7858 . -138) (undo-tree-id7859 . -138) (undo-tree-id7860 . -138) (undo-tree-id7861 . -138) (undo-tree-id7862 . -138) (undo-tree-id7863 . -138) (undo-tree-id7864 . -138) (undo-tree-id7865 . -138) (undo-tree-id7866 . -138) (undo-tree-id7867 . -138) (undo-tree-id7868 . -138) (undo-tree-id7869 . -138) (undo-tree-id7870 . -138) (undo-tree-id7871 . -138) (undo-tree-id7872 . -138) (undo-tree-id7873 . -138) (undo-tree-id7874 . -138) (undo-tree-id7875 . -138) (undo-tree-id7876 . -138) (undo-tree-id7877 . -138) (undo-tree-id7878 . -138) (undo-tree-id7879 . -138) (undo-tree-id7880 . -138) (undo-tree-id7881 . -138) (undo-tree-id7882 . -138) (undo-tree-id7883 . -138) (undo-tree-id7884 . -138) (undo-tree-id7885 . -138) (undo-tree-id7886 . -138) (undo-tree-id7887 . -138) (undo-tree-id7888 . -138) (undo-tree-id7889 . -138) (undo-tree-id7890 . -138) (undo-tree-id7891 . -138) (undo-tree-id7892 . -138) (undo-tree-id7893 . -138) (undo-tree-id7894 . -138) (undo-tree-id7895 . -138) (undo-tree-id7896 . -138) (undo-tree-id7897 . -138) (undo-tree-id7898 . -138) (undo-tree-id7899 . -138) (undo-tree-id7900 . -138) (undo-tree-id7901 . -138) (undo-tree-id7902 . -138) (undo-tree-id7903 . -138) (undo-tree-id7904 . -138) (undo-tree-id7905 . -138) (undo-tree-id7906 . -138) (undo-tree-id7907 . -138) (undo-tree-id7908 . -138) (undo-tree-id7909 . -138) (undo-tree-id7910 . -138) (undo-tree-id7911 . -138) (undo-tree-id7912 . -138) (undo-tree-id7913 . -138) (undo-tree-id7914 . -138) (undo-tree-id7915 . -138) (undo-tree-id7916 . -138) (undo-tree-id7917 . -138) (undo-tree-id7918 . -138) (undo-tree-id7919 . -138) (undo-tree-id7920 . -138) (undo-tree-id7921 . -138) (undo-tree-id7922 . -138) (undo-tree-id7923 . -138) (undo-tree-id7924 . -138) (undo-tree-id7925 . -138) (undo-tree-id7926 . -138) (undo-tree-id7927 . -138) (undo-tree-id7928 . -138) (undo-tree-id7929 . -138) (undo-tree-id7930 . -138) (undo-tree-id7931 . -138) (undo-tree-id7932 . -138) (undo-tree-id7933 . -138) (undo-tree-id7934 . -138) (undo-tree-id7935 . -138) (undo-tree-id7936 . -138) (undo-tree-id7937 . -138) (undo-tree-id7938 . -138) (undo-tree-id7939 . -138) (undo-tree-id7940 . -138) (undo-tree-id7941 . -138) (undo-tree-id7942 . -138) (undo-tree-id7943 . -138) (undo-tree-id7944 . -138) (undo-tree-id7945 . -138) (undo-tree-id7946 . -138) (undo-tree-id7947 . -138) (undo-tree-id7948 . -138) (undo-tree-id7949 . -138) (undo-tree-id7950 . -138) (undo-tree-id7951 . -138) (undo-tree-id7952 . -138) (undo-tree-id7953 . -138) (undo-tree-id7954 . -138) (undo-tree-id7955 . -138) (undo-tree-id7956 . -138) (undo-tree-id7957 . -138) (undo-tree-id7958 . -138) (undo-tree-id7959 . -138) (undo-tree-id7960 . -138) (undo-tree-id7961 . -138) (undo-tree-id7962 . -138) (undo-tree-id7963 . -138) (undo-tree-id7964 . -138) (undo-tree-id7965 . -138) (undo-tree-id7966 . -138) (undo-tree-id7967 . -138) (undo-tree-id7968 . -138) (undo-tree-id7969 . -138) (undo-tree-id7970 . -138) (undo-tree-id7971 . -138) (undo-tree-id7972 . -138) (undo-tree-id7973 . -138) (undo-tree-id7974 . -138) (undo-tree-id7975 . -138) (undo-tree-id7976 . -138) (undo-tree-id7977 . -138) (undo-tree-id7978 . -138) (undo-tree-id7979 . -138) (undo-tree-id7980 . -138) (undo-tree-id7981 . -138) (undo-tree-id7982 . -138) (undo-tree-id7983 . -138) (undo-tree-id7984 . -138) (undo-tree-id7985 . -138) (undo-tree-id7986 . -138) (undo-tree-id7987 . -138) (undo-tree-id7988 . -138) (undo-tree-id7989 . -138) (undo-tree-id7990 . -138) (undo-tree-id7991 . -138) (undo-tree-id7992 . -138) (undo-tree-id7993 . -138) (undo-tree-id7994 . -138) (undo-tree-id7995 . -138) (undo-tree-id7996 . -138) (undo-tree-id7997 . -138) (undo-tree-id7998 . -138) (undo-tree-id7999 . -138) (undo-tree-id8000 . -138) (undo-tree-id8001 . -138) (undo-tree-id8002 . -138) (undo-tree-id8003 . -138) (undo-tree-id8004 . -138) (undo-tree-id8005 . -138) (undo-tree-id8006 . -138) (undo-tree-id8007 . -138) (undo-tree-id8008 . -138) (undo-tree-id8009 . -138) (undo-tree-id8010 . -138) (undo-tree-id8011 . -138) (undo-tree-id8012 . -138) (undo-tree-id8013 . -138) (undo-tree-id8014 . -138) (undo-tree-id8015 . -138) (undo-tree-id8016 . -138) (undo-tree-id8017 . -138) (undo-tree-id8018 . -138) (undo-tree-id8019 . -138) (undo-tree-id8020 . -138) (undo-tree-id8021 . -138) (undo-tree-id8022 . -138) (undo-tree-id8023 . -138) (undo-tree-id8024 . -138) (undo-tree-id8025 . -138) (undo-tree-id8026 . -138) (undo-tree-id8027 . -138) (undo-tree-id8028 . -138) (undo-tree-id8029 . -138) (undo-tree-id8030 . -138) (undo-tree-id8031 . -138) (undo-tree-id8032 . -138) (undo-tree-id8033 . -138) (undo-tree-id8034 . -138) (undo-tree-id8035 . -138) (undo-tree-id8036 . -138) (undo-tree-id8037 . -138) (undo-tree-id8038 . -138) (undo-tree-id8039 . -138) (undo-tree-id8040 . -138) (undo-tree-id8041 . -138) (undo-tree-id8042 . -138) (undo-tree-id8043 . -138) (undo-tree-id8044 . -138) (undo-tree-id8045 . -138) (undo-tree-id8046 . -138) (undo-tree-id8047 . -138) (undo-tree-id8048 . -138) (undo-tree-id8049 . -138) (undo-tree-id8050 . -138) (undo-tree-id8051 . -138) (undo-tree-id8052 . -138) (undo-tree-id8053 . -138) (undo-tree-id8054 . -138) (undo-tree-id8055 . -138) (undo-tree-id8056 . -138) (undo-tree-id8057 . -138) (undo-tree-id8058 . -138) (undo-tree-id8059 . -138) (undo-tree-id8060 . -138) (undo-tree-id8061 . -138) (undo-tree-id8062 . -138) (undo-tree-id8063 . -138) (undo-tree-id8064 . -138) (undo-tree-id8065 . -138) (undo-tree-id8066 . -138) (undo-tree-id8067 . -138) (undo-tree-id8068 . -138) (undo-tree-id8069 . -138) (undo-tree-id8070 . -138) (undo-tree-id8071 . -138) (undo-tree-id8072 . -138) (undo-tree-id8073 . -138) (undo-tree-id8074 . -138) (undo-tree-id8075 . -138) (undo-tree-id8076 . -138) (undo-tree-id8077 . -138) (undo-tree-id8078 . -138) (undo-tree-id8079 . -138) (undo-tree-id8080 . -138) (undo-tree-id8081 . -138) (undo-tree-id8082 . -138) (undo-tree-id8083 . -138) (undo-tree-id8084 . -138) (undo-tree-id8085 . -138) (undo-tree-id8086 . -138) (undo-tree-id8087 . -138) (undo-tree-id8088 . -138) (undo-tree-id8089 . -138) (undo-tree-id8090 . -138) (undo-tree-id8091 . -138) (undo-tree-id8092 . -138) (undo-tree-id8093 . -138) (undo-tree-id8094 . -138) (undo-tree-id8095 . -138) (undo-tree-id8096 . -138) (undo-tree-id8097 . -138) (undo-tree-id8098 . -138) (undo-tree-id8099 . -138) (undo-tree-id8100 . -138) (undo-tree-id8101 . -138) (undo-tree-id8102 . -138) (undo-tree-id8103 . -138) (undo-tree-id8104 . -138) (undo-tree-id8105 . -138) (undo-tree-id8106 . -138) (undo-tree-id8107 . -138) (undo-tree-id8108 . -138) (undo-tree-id8109 . -138) (undo-tree-id8110 . -138) (undo-tree-id8111 . -138) (undo-tree-id8112 . -138) (undo-tree-id8113 . -138) (undo-tree-id8114 . -138) (undo-tree-id8115 . -138) (undo-tree-id8116 . -138) (undo-tree-id8117 . -138) (undo-tree-id8118 . -138) (undo-tree-id8119 . -138) (undo-tree-id8120 . -138) (undo-tree-id8121 . -138) (undo-tree-id8122 . -138) (undo-tree-id8123 . -138) (undo-tree-id8124 . -138) (undo-tree-id8125 . -138) (undo-tree-id8126 . -138) (undo-tree-id8127 . -138) (undo-tree-id8128 . -138) (undo-tree-id8129 . -138) (undo-tree-id8130 . -138) (undo-tree-id8131 . -138) (undo-tree-id8132 . -138) (undo-tree-id8133 . -138) (undo-tree-id8134 . -138) (undo-tree-id8135 . -138) (undo-tree-id8136 . -138) (undo-tree-id8137 . -138) (undo-tree-id8138 . -138) (undo-tree-id8139 . -138) (undo-tree-id8140 . -138) (undo-tree-id8141 . -138) (undo-tree-id8142 . -138) (undo-tree-id8143 . -138) (undo-tree-id8144 . -138) (undo-tree-id8145 . -138) (undo-tree-id8146 . -138) (undo-tree-id8147 . -138) (undo-tree-id8148 . -138) (undo-tree-id8149 . -138) (undo-tree-id8150 . -138) (undo-tree-id8151 . -138) (undo-tree-id8152 . -138) (undo-tree-id8153 . -138) (undo-tree-id8154 . -138) (undo-tree-id8155 . -138) (undo-tree-id8156 . -138) (undo-tree-id8157 . -138) (undo-tree-id8158 . -138) (undo-tree-id8159 . -138) (undo-tree-id8160 . -138) (undo-tree-id8161 . -138) (undo-tree-id8162 . -138) (undo-tree-id8163 . -138) (undo-tree-id8164 . -138) (undo-tree-id8165 . -138) (undo-tree-id8166 . -138) (undo-tree-id8167 . -138) (undo-tree-id8168 . -138) (undo-tree-id8169 . -138) (undo-tree-id8170 . -138) (undo-tree-id8171 . -138) (undo-tree-id8172 . -138) (undo-tree-id8173 . -138) (undo-tree-id8174 . -138) (undo-tree-id8175 . -138) (undo-tree-id8176 . -138) (undo-tree-id8177 . -138) (undo-tree-id8178 . -138) (undo-tree-id8179 . -138) (undo-tree-id8180 . -138) (undo-tree-id8181 . -138) (undo-tree-id8182 . -138) (undo-tree-id8183 . -138) (undo-tree-id8184 . -138) (undo-tree-id8185 . -138) (undo-tree-id8186 . -138) (undo-tree-id8187 . -138) (undo-tree-id8188 . -138) (undo-tree-id8189 . -138) (undo-tree-id8190 . -138) (undo-tree-id8191 . -138) (undo-tree-id8192 . -138) (undo-tree-id8193 . -138) (undo-tree-id8194 . -138) (undo-tree-id8195 . -138) (undo-tree-id8196 . -138) (undo-tree-id8197 . -138) (undo-tree-id8198 . -138) (undo-tree-id8199 . -138) (undo-tree-id8200 . -138) (undo-tree-id8201 . -138) (undo-tree-id8202 . -138) (undo-tree-id8203 . -138) (undo-tree-id8204 . -138) (undo-tree-id8205 . -138) (undo-tree-id8206 . -138) (undo-tree-id8207 . -138) (undo-tree-id8208 . -138) (undo-tree-id8209 . -138) (undo-tree-id8210 . -138) (undo-tree-id8211 . -138) (undo-tree-id8212 . -138) (undo-tree-id8213 . -138) (undo-tree-id8214 . -138) (undo-tree-id8215 . -138) (undo-tree-id8216 . -138) (undo-tree-id8217 . -138) (undo-tree-id8218 . -138) (undo-tree-id8219 . -138) (undo-tree-id8220 . -138) (undo-tree-id8221 . -138) (undo-tree-id8222 . -138) (undo-tree-id8223 . -138) (undo-tree-id8224 . -138) (undo-tree-id8225 . -138) (undo-tree-id8226 . -138) (undo-tree-id8227 . -138) (undo-tree-id8228 . -138) (undo-tree-id8229 . -138) (undo-tree-id8230 . -138) (undo-tree-id8231 . -138) (undo-tree-id8232 . -138) (undo-tree-id8233 . -138) (undo-tree-id8234 . -138) (undo-tree-id8235 . -138) (undo-tree-id8236 . -138) (undo-tree-id8237 . -138) (undo-tree-id8238 . -138) (undo-tree-id8239 . -138) (undo-tree-id8240 . -138) (undo-tree-id8241 . -138) (undo-tree-id8242 . -138) (undo-tree-id8243 . -138) (undo-tree-id8244 . -138) (undo-tree-id8245 . -138) (undo-tree-id8246 . -138) (undo-tree-id8247 . -138) (undo-tree-id8248 . -138) (undo-tree-id8249 . -138) (undo-tree-id8250 . -138) (undo-tree-id8251 . -138) (undo-tree-id8252 . -138) (undo-tree-id8253 . -138) (undo-tree-id8254 . -138) (undo-tree-id8255 . -138) (undo-tree-id8256 . -138) (undo-tree-id8257 . -138) (undo-tree-id8258 . -138) (undo-tree-id8259 . -138) (undo-tree-id8260 . -138) (undo-tree-id8261 . -138) (undo-tree-id8262 . -138) (undo-tree-id8263 . -138) (undo-tree-id8264 . -138) (undo-tree-id8265 . -138) (undo-tree-id8266 . -138) (undo-tree-id8267 . -138) (undo-tree-id8268 . -138) (undo-tree-id8269 . -138) (undo-tree-id8270 . -138) (undo-tree-id8271 . -138) (undo-tree-id8272 . -138) (undo-tree-id8273 . -138) (undo-tree-id8274 . -138) (undo-tree-id8275 . -138) (undo-tree-id8276 . -138) (undo-tree-id8277 . -138) (undo-tree-id8278 . -138) (undo-tree-id8279 . -138) (undo-tree-id8280 . -138) (undo-tree-id8281 . -138) (undo-tree-id8282 . -138) (undo-tree-id8283 . -138) (undo-tree-id8284 . -138) (undo-tree-id8285 . -138) (undo-tree-id8286 . -138) (undo-tree-id8287 . -138) (undo-tree-id8288 . -138) (undo-tree-id8289 . -138) (undo-tree-id8290 . -138) (undo-tree-id8291 . -138) (undo-tree-id8292 . -138) (undo-tree-id8293 . -138) (undo-tree-id8294 . -138) (undo-tree-id8295 . -138) (undo-tree-id8296 . -138) (undo-tree-id8297 . -138) (undo-tree-id8298 . -138) (undo-tree-id8299 . -138) (undo-tree-id8300 . -138) (undo-tree-id8301 . -138) (undo-tree-id8302 . -138) (undo-tree-id8303 . -138) (undo-tree-id8304 . -138) (undo-tree-id8305 . -138) (undo-tree-id8306 . -138) (undo-tree-id8307 . -138) (undo-tree-id8308 . -138) (undo-tree-id8309 . -138) (undo-tree-id8310 . -138) (undo-tree-id8311 . -138) (undo-tree-id8312 . -138) (undo-tree-id8313 . -138) (undo-tree-id8314 . -138) (undo-tree-id8315 . -138) (undo-tree-id8316 . -138) (undo-tree-id8317 . -138) (undo-tree-id8318 . -138) (undo-tree-id8319 . -138) (undo-tree-id8320 . -138) (undo-tree-id8321 . -138) (undo-tree-id8322 . -138) (undo-tree-id8323 . -138) (undo-tree-id8324 . -138) (undo-tree-id8325 . -138) (undo-tree-id8326 . -138) (undo-tree-id8327 . -138) (undo-tree-id8328 . -138) (undo-tree-id8329 . -138) (undo-tree-id8330 . -138) (undo-tree-id8331 . -138) (undo-tree-id8332 . -138) (undo-tree-id8333 . -138) (undo-tree-id8334 . -138) (undo-tree-id8335 . -138) (undo-tree-id8336 . -138) (undo-tree-id8337 . -138) (undo-tree-id8338 . -138) (undo-tree-id8339 . -138) (undo-tree-id8340 . -138) (undo-tree-id8341 . -138) (undo-tree-id8342 . -138) (undo-tree-id8343 . -138) (undo-tree-id8344 . -138) (undo-tree-id8345 . -138) (undo-tree-id8346 . -138) (undo-tree-id8347 . -138) (undo-tree-id8348 . -138) (undo-tree-id8349 . -138) (undo-tree-id8350 . -138) (undo-tree-id8351 . -138) (undo-tree-id8352 . -138) (undo-tree-id8353 . -138) (undo-tree-id8354 . -138) (undo-tree-id8355 . -138) (undo-tree-id8356 . -138) (undo-tree-id8357 . -138) (undo-tree-id8358 . -138) (undo-tree-id8359 . -138) (undo-tree-id8360 . -138) (undo-tree-id8361 . -138) (undo-tree-id8362 . -138) (undo-tree-id8363 . -138) (undo-tree-id8364 . -138) (undo-tree-id8365 . -138) (undo-tree-id8366 . -138) (undo-tree-id8367 . -138) (undo-tree-id8368 . -138) (undo-tree-id8369 . -138) (undo-tree-id8370 . -138) (undo-tree-id8371 . -138) (undo-tree-id8372 . -138) (undo-tree-id8373 . -138) (undo-tree-id8374 . -138) (undo-tree-id8375 . -138) (undo-tree-id8376 . -138) (undo-tree-id8377 . -138) (undo-tree-id8378 . -138) (undo-tree-id8379 . -138) (undo-tree-id8380 . -138) (undo-tree-id8381 . -138) (undo-tree-id8382 . -138) (undo-tree-id8383 . -138) (undo-tree-id8384 . -138) (undo-tree-id8385 . -138) (undo-tree-id8386 . -138) (undo-tree-id8387 . -138) (undo-tree-id8388 . -138) (undo-tree-id8389 . -138) (undo-tree-id8390 . -138) (undo-tree-id8391 . -138) (undo-tree-id8392 . -138) (undo-tree-id8393 . -138) (undo-tree-id8394 . -138) (undo-tree-id8395 . -138) (undo-tree-id8396 . -138) (undo-tree-id8397 . -138) (undo-tree-id8398 . -138) (undo-tree-id8399 . -138) (undo-tree-id8400 . -138) (undo-tree-id8401 . -138) (undo-tree-id8402 . -138) (undo-tree-id8403 . -138) (undo-tree-id8404 . -138) (undo-tree-id8405 . -138) (undo-tree-id8406 . -138) (undo-tree-id8407 . -138) (undo-tree-id8408 . -138) (undo-tree-id8409 . -138) (undo-tree-id8410 . -138) (undo-tree-id8411 . -138) (undo-tree-id8412 . -138) (undo-tree-id8413 . -138) (undo-tree-id8414 . -138) (undo-tree-id8415 . -138) (undo-tree-id8416 . -138) (undo-tree-id8417 . -138) (undo-tree-id8418 . -138) (undo-tree-id8419 . -138) (undo-tree-id8420 . -138) (undo-tree-id8421 . -138) (undo-tree-id8422 . -138) (undo-tree-id8423 . -138) (undo-tree-id8424 . -138) (undo-tree-id8425 . -138) (undo-tree-id8426 . -138) (undo-tree-id8427 . -138) (undo-tree-id8428 . -138) (undo-tree-id8429 . -138) (undo-tree-id8430 . -138) (undo-tree-id8431 . -138) (undo-tree-id8432 . -138) (undo-tree-id8433 . -138) (undo-tree-id8434 . -138) (undo-tree-id8435 . -138) (undo-tree-id8436 . -138) (undo-tree-id8437 . -138) (undo-tree-id8438 . -138) (undo-tree-id8439 . -138) (undo-tree-id8440 . -138) (undo-tree-id8441 . -138) (undo-tree-id8442 . -138) (undo-tree-id8443 . -138) (undo-tree-id8444 . -138) (undo-tree-id8445 . -138) (undo-tree-id8446 . -138) (undo-tree-id8447 . -138) (undo-tree-id8448 . -138) (undo-tree-id8449 . -138) (undo-tree-id8450 . -138) (undo-tree-id8451 . -138) (undo-tree-id8452 . -138) (undo-tree-id8453 . -138) (undo-tree-id8454 . -138) (undo-tree-id8455 . -138) (undo-tree-id8456 . -138) (undo-tree-id8457 . -138) (undo-tree-id8458 . -138) (undo-tree-id8459 . -138) (undo-tree-id8460 . -138) (undo-tree-id8461 . -138) (undo-tree-id8462 . -138) (undo-tree-id8463 . -138) (undo-tree-id8464 . -138) (undo-tree-id8465 . -138) (undo-tree-id8466 . -138) (undo-tree-id8467 . -138) (undo-tree-id8468 . -138) (undo-tree-id8469 . -138) (undo-tree-id8470 . -138) (undo-tree-id8471 . -138) (undo-tree-id8472 . -138) (undo-tree-id8473 . -138) (undo-tree-id8474 . -138) (undo-tree-id8475 . -138) (undo-tree-id8476 . -138) (undo-tree-id8477 . -138) (undo-tree-id8478 . -138) (undo-tree-id8479 . -138) (undo-tree-id8480 . -138) (undo-tree-id8481 . -138) (undo-tree-id8482 . -138) (undo-tree-id8483 . -138) (undo-tree-id8484 . -138) (undo-tree-id8485 . -138) (undo-tree-id8486 . -138) (undo-tree-id8487 . -138) (undo-tree-id8488 . -138) (undo-tree-id8489 . -138) (undo-tree-id8490 . -138) (undo-tree-id8491 . -138) (undo-tree-id8492 . -138) (undo-tree-id8493 . -138) (undo-tree-id8494 . -138) (undo-tree-id8495 . -138) (undo-tree-id8496 . -138) (undo-tree-id8497 . -138) (undo-tree-id8498 . -138) (undo-tree-id8499 . -138) (undo-tree-id8500 . -138) (undo-tree-id8501 . -138) (undo-tree-id8502 . -138) (undo-tree-id8503 . -138) (undo-tree-id8504 . -138) (undo-tree-id8505 . -138) (undo-tree-id8506 . -138) (undo-tree-id8507 . -138) (undo-tree-id8508 . -138) (undo-tree-id8509 . -138) (undo-tree-id8510 . -138) (undo-tree-id8511 . -138) (undo-tree-id8512 . -138) (undo-tree-id8513 . -138) (undo-tree-id8514 . -138) (undo-tree-id8515 . -138) (undo-tree-id8516 . -138) (undo-tree-id8517 . -138) (undo-tree-id8518 . -138) (undo-tree-id8519 . -138) (undo-tree-id8520 . -138) (undo-tree-id8521 . -138) (undo-tree-id8522 . -138) (undo-tree-id8523 . -138) (undo-tree-id8524 . -138) (undo-tree-id8525 . -138) (undo-tree-id8526 . -138) (undo-tree-id8527 . -138) (undo-tree-id8528 . -138) (undo-tree-id8529 . -138) (undo-tree-id8530 . -138) (undo-tree-id8531 . -138) (undo-tree-id8532 . -138) (undo-tree-id8533 . -138) (undo-tree-id8534 . -138) (undo-tree-id8535 . -138) (undo-tree-id8536 . -138) (undo-tree-id8537 . -138) (undo-tree-id8538 . -138) (undo-tree-id8539 . -138) (undo-tree-id8540 . -138) (undo-tree-id8541 . -138) (undo-tree-id8542 . -138) (undo-tree-id8543 . -138) (undo-tree-id8544 . -138) (undo-tree-id8545 . -138) (undo-tree-id8546 . -138) (undo-tree-id8547 . -138) (undo-tree-id8548 . -138) (undo-tree-id8549 . -138) (undo-tree-id8550 . -138) (undo-tree-id8551 . -138) (undo-tree-id8552 . -138) (undo-tree-id8553 . -138) (undo-tree-id8554 . -138) (undo-tree-id8555 . -138) (undo-tree-id8556 . -138) (undo-tree-id8557 . -138) (undo-tree-id8558 . -138) (undo-tree-id8559 . -138) (undo-tree-id8560 . -138) (undo-tree-id8561 . -138) (undo-tree-id8562 . -138) (undo-tree-id8563 . -138) (undo-tree-id8564 . -138) (undo-tree-id8565 . -138) (undo-tree-id8566 . -138) (undo-tree-id8567 . -138) (undo-tree-id8568 . -138) (undo-tree-id8569 . -138) (undo-tree-id8570 . -138) (undo-tree-id8571 . -138) (undo-tree-id8572 . -138) (undo-tree-id8573 . -138) (undo-tree-id8574 . -138) (undo-tree-id8575 . -138) (undo-tree-id8576 . -138) (undo-tree-id8577 . -138) (undo-tree-id8578 . -138) (undo-tree-id8579 . -138) (undo-tree-id8580 . -138) (undo-tree-id8581 . -138) (undo-tree-id8582 . -138) (undo-tree-id8583 . -138) (undo-tree-id8584 . -138) (undo-tree-id8585 . -138) (undo-tree-id8586 . -138) (undo-tree-id8587 . -138) (undo-tree-id8588 . -138) (undo-tree-id8589 . -138) (undo-tree-id8590 . -138) (undo-tree-id8591 . -138) (undo-tree-id8592 . -138) (undo-tree-id8593 . -138) (undo-tree-id8594 . -138) (undo-tree-id8595 . -138) (undo-tree-id8596 . -138) (undo-tree-id8597 . -138) (undo-tree-id8598 . -138) (undo-tree-id8599 . -138) (undo-tree-id8600 . -138) (undo-tree-id8601 . -138) (undo-tree-id8602 . -138) (undo-tree-id8603 . -138) (undo-tree-id8604 . -138) (undo-tree-id8605 . -138) (undo-tree-id8606 . -138) (undo-tree-id8607 . -138) (undo-tree-id8608 . -138) (undo-tree-id8609 . -138) (undo-tree-id8610 . -138) (undo-tree-id8611 . -138) (undo-tree-id8612 . -138) (undo-tree-id8613 . -138) (undo-tree-id8614 . -138) (undo-tree-id8615 . -138) (undo-tree-id8616 . -138) (undo-tree-id8617 . -138) (undo-tree-id8618 . -138) (undo-tree-id8619 . -138) (undo-tree-id8620 . -138) (undo-tree-id8621 . -138) (undo-tree-id8622 . -138) (undo-tree-id8623 . -138) (undo-tree-id8624 . -138) (undo-tree-id8625 . -138) (undo-tree-id8626 . -138) (undo-tree-id8627 . -138) (undo-tree-id8628 . -138) (undo-tree-id8629 . -263) (undo-tree-id8630 . -138) (undo-tree-id8631 . -138) (undo-tree-id8632 . -138) (undo-tree-id8633 . -138) (undo-tree-id8634 . -138) (undo-tree-id8635 . -138) (undo-tree-id8636 . -138) (undo-tree-id8637 . -138) (undo-tree-id8638 . -138) (undo-tree-id8639 . -138) (undo-tree-id8640 . -138) (undo-tree-id8641 . -138) (undo-tree-id8642 . -138) (undo-tree-id8643 . -138) (undo-tree-id8644 . -138) (undo-tree-id8645 . -138) (undo-tree-id8646 . -138) (undo-tree-id8647 . -138) (undo-tree-id8648 . -138) (undo-tree-id8649 . -138) (undo-tree-id8650 . -138) (undo-tree-id8651 . -138) (undo-tree-id8652 . -138) (undo-tree-id8653 . -138) (undo-tree-id8654 . -138) (undo-tree-id8655 . -138) (undo-tree-id8656 . -138) (undo-tree-id8657 . -138) (undo-tree-id8658 . -138) (undo-tree-id8659 . -138) (undo-tree-id8660 . -138) (undo-tree-id8661 . -138) (undo-tree-id8662 . -138) (undo-tree-id8663 . -138) (undo-tree-id8664 . -138) (undo-tree-id8665 . -138) (undo-tree-id8666 . -138) (undo-tree-id8667 . -138) (undo-tree-id8668 . -138) (undo-tree-id8669 . -138) (undo-tree-id8670 . -138) (undo-tree-id8671 . -138) (undo-tree-id8672 . -138) (undo-tree-id8673 . -138) (undo-tree-id8674 . -138) (undo-tree-id8675 . -138) (undo-tree-id8676 . -138) (undo-tree-id8677 . -138) (undo-tree-id8678 . -138) (undo-tree-id8679 . -138) (undo-tree-id8680 . -138) (undo-tree-id8681 . -138) (undo-tree-id8682 . -138) (undo-tree-id8683 . -138) (undo-tree-id8684 . -138) (undo-tree-id8685 . -138) (undo-tree-id8686 . -138) (undo-tree-id8687 . -138) (undo-tree-id8688 . -79) (undo-tree-id8689 . -88) (undo-tree-id8690 . -138) (undo-tree-id8691 . -138) (undo-tree-id8692 . -138) (undo-tree-id8693 . -138) (undo-tree-id8694 . -138) (undo-tree-id8695 . -138) (undo-tree-id8696 . -138) (undo-tree-id8697 . -138) (undo-tree-id8698 . -138) (undo-tree-id8699 . -138) (undo-tree-id8700 . -138) (undo-tree-id8701 . -138) (undo-tree-id8702 . -138) (undo-tree-id8703 . -138) (undo-tree-id8704 . -138) (undo-tree-id8705 . -138) (undo-tree-id8706 . -138) (undo-tree-id8707 . -138) (undo-tree-id8708 . -138) (undo-tree-id8709 . -138) (undo-tree-id8710 . -138) (undo-tree-id8711 . -138) (undo-tree-id8712 . -138) (undo-tree-id8713 . -138) (undo-tree-id8714 . -138) (undo-tree-id8715 . -138) (undo-tree-id8716 . -138) (undo-tree-id8717 . -138) (undo-tree-id8718 . -138) (undo-tree-id8719 . -138) (undo-tree-id8720 . -138) (undo-tree-id8721 . -138) (undo-tree-id8722 . -138) (undo-tree-id8723 . -138) (undo-tree-id8724 . -138) (undo-tree-id8725 . -138) (undo-tree-id8726 . -138) (undo-tree-id8727 . -138) (undo-tree-id8728 . -138) (undo-tree-id8729 . -138) (undo-tree-id8730 . -138) (undo-tree-id8731 . -138) (undo-tree-id8732 . -138) (undo-tree-id8733 . -138) (undo-tree-id8734 . -138) (undo-tree-id8735 . -138) (undo-tree-id8736 . -138) (undo-tree-id8737 . -138) (undo-tree-id8738 . -138) (undo-tree-id8739 . -138) (undo-tree-id8740 . -138) (undo-tree-id8741 . -138) (undo-tree-id8742 . -138) (undo-tree-id8743 . -138) (undo-tree-id8744 . -138) (undo-tree-id8745 . -263) 1146 (t 25760 29891 508491 846000)) nil (25760 29922 838640 528000) 0 nil] [nil nil ((#("# **Note**: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 263 (fontified t face font-lock-comment-face)) . 1008) (undo-tree-id7362 . -262) (undo-tree-id7363 . -138) (undo-tree-id7364 . -2) (undo-tree-id7365 . -2) (undo-tree-id7366 . -2) (undo-tree-id7367 . -2) (undo-tree-id7368 . -2) (undo-tree-id7369 . -2) (undo-tree-id7370 . -2) (undo-tree-id7371 . -2) (undo-tree-id7372 . -2) (undo-tree-id7373 . -2) (undo-tree-id7374 . -2) (undo-tree-id7375 . -2) (undo-tree-id7376 . -2) (undo-tree-id7377 . -2) (undo-tree-id7378 . -2) (undo-tree-id7379 . -2) (undo-tree-id7380 . -2) (undo-tree-id7381 . -2) (undo-tree-id7382 . -2) (undo-tree-id7383 . -2) (undo-tree-id7384 . -2) (undo-tree-id7385 . -2) (undo-tree-id7386 . -2) (undo-tree-id7387 . -2) (undo-tree-id7388 . -2) (undo-tree-id7389 . -2) (undo-tree-id7390 . -2) (undo-tree-id7391 . -2) (undo-tree-id7392 . -2) (undo-tree-id7393 . -2) (undo-tree-id7394 . -2) (undo-tree-id7395 . -2) (undo-tree-id7396 . -2) (undo-tree-id7397 . -2) (undo-tree-id7398 . -2) (undo-tree-id7399 . -2) (undo-tree-id7400 . -2) (undo-tree-id7401 . -2) (undo-tree-id7402 . -2) (undo-tree-id7403 . -2) (undo-tree-id7404 . -2) (undo-tree-id7405 . -2) (undo-tree-id7406 . -2) (undo-tree-id7407 . -2) (undo-tree-id7408 . -2) (undo-tree-id7409 . -2) (undo-tree-id7410 . -2) (undo-tree-id7411 . -4) (undo-tree-id7412 . -4) (undo-tree-id7413 . -4) (undo-tree-id7414 . -4) (undo-tree-id7415 . -4) (undo-tree-id7416 . -4) (undo-tree-id7417 . -4) (undo-tree-id7418 . -4) (undo-tree-id7419 . -4) (undo-tree-id7420 . -4) (undo-tree-id7421 . -4) (undo-tree-id7422 . -4) (undo-tree-id7423 . -4) (undo-tree-id7424 . -4) (undo-tree-id7425 . -4) (undo-tree-id7426 . -4) (undo-tree-id7427 . -4) (undo-tree-id7428 . -4) (undo-tree-id7429 . -4) (undo-tree-id7430 . -4) (undo-tree-id7431 . -4) (undo-tree-id7432 . -4) (undo-tree-id7433 . -4) (undo-tree-id7434 . -4) (undo-tree-id7435 . -4) (undo-tree-id7436 . -4) (undo-tree-id7437 . -4) (undo-tree-id7438 . -4) (undo-tree-id7439 . -4) (undo-tree-id7440 . -4) (undo-tree-id7441 . -4) (undo-tree-id7442 . -4) (undo-tree-id7443 . -4) (undo-tree-id7444 . -4) (undo-tree-id7445 . -4) (undo-tree-id7446 . -4) (undo-tree-id7447 . -4) (undo-tree-id7448 . -4) (undo-tree-id7449 . -4) (undo-tree-id7450 . -4) (undo-tree-id7451 . -4) (undo-tree-id7452 . -4) (undo-tree-id7453 . -4) (undo-tree-id7454 . -4) (undo-tree-id7455 . -4) (undo-tree-id7456 . -4) (undo-tree-id7457 . -4) (undo-tree-id7458 . -4) (undo-tree-id7459 . -4) (undo-tree-id7460 . -4) (undo-tree-id7461 . -4) (undo-tree-id7462 . -4) (undo-tree-id7463 . -4) (undo-tree-id7464 . -4) (undo-tree-id7465 . -4) (undo-tree-id7466 . -4) (undo-tree-id7467 . -4) (undo-tree-id7468 . -4) (undo-tree-id7469 . -4) (undo-tree-id7470 . -4) (undo-tree-id7471 . -4) (undo-tree-id7472 . -4) (undo-tree-id7473 . -4) (undo-tree-id7474 . -4) (undo-tree-id7475 . -4) (undo-tree-id7476 . -4) (undo-tree-id7477 . -4) (undo-tree-id7478 . -4) (undo-tree-id7479 . -4) (undo-tree-id7480 . -4) (undo-tree-id7481 . -4) (undo-tree-id7482 . -4) (undo-tree-id7483 . -4) (undo-tree-id7484 . -4) (undo-tree-id7485 . -4) (undo-tree-id7486 . -4) (undo-tree-id7487 . -4) (undo-tree-id7488 . -4) (undo-tree-id7489 . -4) (undo-tree-id7490 . -4) (undo-tree-id7491 . -4) (undo-tree-id7492 . -4) (undo-tree-id7493 . -4) (undo-tree-id7494 . -4) (undo-tree-id7495 . -4) (undo-tree-id7496 . -4) (undo-tree-id7497 . -4) (undo-tree-id7498 . -4) (undo-tree-id7499 . -4) (undo-tree-id7500 . -4) (undo-tree-id7501 . -4) (undo-tree-id7502 . -4) (undo-tree-id7503 . -4) (undo-tree-id7504 . -4) (undo-tree-id7505 . -4) (undo-tree-id7506 . -4) (undo-tree-id7507 . -4) (undo-tree-id7508 . -4) (undo-tree-id7509 . -4) (undo-tree-id7510 . -4) (undo-tree-id7511 . -71) (undo-tree-id7512 . -71) (undo-tree-id7513 . -71) (undo-tree-id7514 . -71) (undo-tree-id7515 . -71) (undo-tree-id7516 . -71) (undo-tree-id7517 . -71) (undo-tree-id7518 . -71) (undo-tree-id7519 . -71) (undo-tree-id7520 . -71) (undo-tree-id7521 . -71) (undo-tree-id7522 . -71) (undo-tree-id7523 . -71) (undo-tree-id7524 . -71) (undo-tree-id7525 . -71) (undo-tree-id7526 . -71) (undo-tree-id7527 . -71) (undo-tree-id7528 . -71) (undo-tree-id7529 . -71) (undo-tree-id7530 . -71) (undo-tree-id7531 . -71) (undo-tree-id7532 . -71) (undo-tree-id7533 . -71) (undo-tree-id7534 . -71) (undo-tree-id7535 . -71) (undo-tree-id7536 . -71) (undo-tree-id7537 . -71) (undo-tree-id7538 . -71) (undo-tree-id7539 . -71) (undo-tree-id7540 . -138) (undo-tree-id7541 . -138) (undo-tree-id7542 . -138) (undo-tree-id7543 . -138) (undo-tree-id7544 . -138) (undo-tree-id7545 . -138) (undo-tree-id7546 . -138) (undo-tree-id7547 . -138) (undo-tree-id7548 . -138) (undo-tree-id7549 . -138) (undo-tree-id7550 . -138) (undo-tree-id7551 . -138) (undo-tree-id7552 . -138) (undo-tree-id7553 . -138) (undo-tree-id7554 . -138) (undo-tree-id7555 . -138) (undo-tree-id7556 . -138) (undo-tree-id7557 . -138) (undo-tree-id7558 . -138) (undo-tree-id7559 . -138) (undo-tree-id7560 . -138) (undo-tree-id7561 . -138) (undo-tree-id7562 . -138) (undo-tree-id7563 . -138) (undo-tree-id7564 . -138) (undo-tree-id7565 . -138) (undo-tree-id7566 . -138) (undo-tree-id7567 . -138) (undo-tree-id7568 . -138) (undo-tree-id7569 . -138) (undo-tree-id7570 . -138) (undo-tree-id7571 . -138) (undo-tree-id7572 . -138) (undo-tree-id7573 . -138) (undo-tree-id7574 . -138) (undo-tree-id7575 . -138) (undo-tree-id7576 . -138) (undo-tree-id7577 . -138) (undo-tree-id7578 . -138) (undo-tree-id7579 . -138) (undo-tree-id7580 . -138) (undo-tree-id7581 . -138) (undo-tree-id7582 . -138) (undo-tree-id7583 . -138) (undo-tree-id7584 . -138) (undo-tree-id7585 . -138) (undo-tree-id7586 . -138) (undo-tree-id7587 . -138) (undo-tree-id7588 . -138) (undo-tree-id7589 . -138) (undo-tree-id7590 . -138) (undo-tree-id7591 . -138) (undo-tree-id7592 . -138) (undo-tree-id7593 . -138) (undo-tree-id7594 . -138) (undo-tree-id7595 . -138) (undo-tree-id7596 . -138) (undo-tree-id7597 . -138) (undo-tree-id7598 . -138) (undo-tree-id7599 . -138) (undo-tree-id7600 . -138) (undo-tree-id7601 . -138) (undo-tree-id7602 . -138) (undo-tree-id7603 . -138) (undo-tree-id7604 . -138) (undo-tree-id7605 . -138) (undo-tree-id7606 . -138) (undo-tree-id7607 . -138) (undo-tree-id7608 . -138) (undo-tree-id7609 . -138) (undo-tree-id7610 . -138) (undo-tree-id7611 . -138) (undo-tree-id7612 . -263) 1146 (t 25760 29891 508491 846000)) ((1008 . 1271)) (25760 29907 546939 480000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1008) (undo-tree-id7613 . -1) (undo-tree-id7614 . -1)) nil (25760 29922 837032 88000) 0 nil])
nil
([nil nil ((#("# In[6]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 9 (fontified t face font-lock-comment-face)) . 1100) (undo-tree-id8814 . -8) (undo-tree-id8815 . -9) (t 25760 29922 862009 277000)) nil (25760 29928 969252 467000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1100) (undo-tree-id8813 . -1)) nil (25760 29928 969249 735000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1099) (undo-tree-id8747 . -1) (undo-tree-id8748 . -1) (undo-tree-id8749 . -1) (undo-tree-id8750 . -1) (undo-tree-id8751 . -1) (undo-tree-id8752 . -1) (undo-tree-id8753 . -1) (undo-tree-id8754 . -1) (undo-tree-id8755 . -1) (undo-tree-id8756 . -1) (undo-tree-id8757 . -1) (undo-tree-id8758 . -1) (undo-tree-id8759 . -1) (undo-tree-id8760 . -1) (undo-tree-id8761 . -1) (undo-tree-id8762 . -1) (undo-tree-id8763 . -1) (undo-tree-id8764 . -1) (undo-tree-id8765 . -1) (undo-tree-id8766 . -1) (undo-tree-id8767 . -1) (undo-tree-id8768 . -1) (undo-tree-id8769 . -1) (undo-tree-id8770 . -1) (undo-tree-id8771 . -1) (undo-tree-id8772 . -1) (undo-tree-id8773 . -1) (undo-tree-id8774 . -1) (undo-tree-id8775 . -1) (undo-tree-id8776 . -1) (undo-tree-id8777 . -1) (undo-tree-id8778 . -1) (undo-tree-id8779 . -1) (undo-tree-id8780 . -1) (undo-tree-id8781 . -1) (undo-tree-id8782 . -1) (undo-tree-id8783 . -1) (undo-tree-id8784 . -1) (undo-tree-id8785 . -1) (undo-tree-id8786 . -1) (undo-tree-id8787 . -1) (undo-tree-id8788 . -1) (undo-tree-id8789 . -1) (undo-tree-id8790 . -1) (undo-tree-id8791 . -1) (undo-tree-id8792 . -1) (undo-tree-id8793 . -1) (undo-tree-id8794 . -1) (undo-tree-id8795 . -1) (undo-tree-id8796 . -1) (undo-tree-id8797 . -1) (undo-tree-id8798 . -1) (undo-tree-id8799 . -1) (undo-tree-id8800 . -1) (undo-tree-id8801 . -1) (undo-tree-id8802 . -1) (undo-tree-id8803 . -1) (undo-tree-id8804 . -1) (undo-tree-id8805 . -1) (undo-tree-id8806 . -1) (undo-tree-id8807 . -1) (undo-tree-id8808 . -1) (undo-tree-id8809 . -1) (undo-tree-id8810 . -1) (undo-tree-id8811 . -1) (undo-tree-id8812 . -1) 1100) nil (25760 29928 969245 180000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1099) (undo-tree-id8746 . -1)) nil (25760 29928 969185 977000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1182) (undo-tree-id8823 . -1) (t 25760 29928 982301 534000)) nil (25760 29933 210172 164000) 0 nil])
([nil nil ((#("# In[7]:
" 0 2 (fontified t face font-lock-comment-delimiter-face) 2 8 (fontified t face font-lock-comment-face) 8 9 (fontified t face font-lock-comment-face)) . 1182) (undo-tree-id8820 . -8) (undo-tree-id8821 . -8) (undo-tree-id8822 . -9)) nil (25760 29933 210167 834000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1182) (undo-tree-id8819 . -1)) nil (25760 29933 210160 868000) 0 nil])
([nil nil ((#("
" 0 1 (fontified t)) . 1182) (undo-tree-id8817 . -1) (undo-tree-id8818 . -1)) nil (25760 29933 212607 164000) 0 nil])
([nil nil ((#("save_fig(\"forecast_ahead_plot\")
" 0 2 (fontified t) 2 8 (fontified t) 8 9 (fontified t face (rainbow-delimiters-depth-1-face)) 9 30 (fontified t face font-lock-string-face) 30 31 (fontified t face (rainbow-delimiters-depth-1-face)) 31 32 (fontified t)) . 5189) (undo-tree-id8830 . -31) (undo-tree-id8831 . -8) (undo-tree-id8832 . -2) (undo-tree-id8833 . -2) (undo-tree-id8834 . -2) (undo-tree-id8835 . -2) (undo-tree-id8836 . -2) (undo-tree-id8837 . -2) (undo-tree-id8838 . -2) (undo-tree-id8839 . -2) (undo-tree-id8840 . -2) (undo-tree-id8841 . -2) (undo-tree-id8842 . -2) (undo-tree-id8843 . -2) (undo-tree-id8844 . -2) (undo-tree-id8845 . -2) (undo-tree-id8846 . -2) (undo-tree-id8847 . -2) (undo-tree-id8848 . -2) (undo-tree-id8849 . -2) (undo-tree-id8850 . -2) (undo-tree-id8851 . -2) (undo-tree-id8852 . -2) (undo-tree-id8853 . -2) (undo-tree-id8854 . -2) (undo-tree-id8855 . -2) (undo-tree-id8856 . -2) (undo-tree-id8857 . -2) (undo-tree-id8858 . -2) (undo-tree-id8859 . -2) (undo-tree-id8860 . -2) (undo-tree-id8861 . -2) (undo-tree-id8862 . -2) (undo-tree-id8863 . -2) (undo-tree-id8864 . -2) (undo-tree-id8865 . -2) (undo-tree-id8866 . -2) (undo-tree-id8867 . -2) (undo-tree-id8868 . -2) (undo-tree-id8869 . -3) (undo-tree-id8870 . -3) (undo-tree-id8871 . -3) (undo-tree-id8872 . -3) (undo-tree-id8873 . -3) (undo-tree-id8874 . -3) (undo-tree-id8875 . -3) (undo-tree-id8876 . -3) (undo-tree-id8877 . -3) (undo-tree-id8878 . -3) (undo-tree-id8879 . -3) (undo-tree-id8880 . -3) (undo-tree-id8881 . -3) (undo-tree-id8882 . -3) (undo-tree-id8883 . -3) (undo-tree-id8884 . -3) (undo-tree-id8885 . -3) (undo-tree-id8886 . -3) (undo-tree-id8887 . -3) (undo-tree-id8888 . -3) (undo-tree-id8889 . -3) (undo-tree-id8890 . -3) (undo-tree-id8891 . -3) (undo-tree-id8892 . -3) (undo-tree-id8893 . -3) (undo-tree-id8894 . -3) (undo-tree-id8895 . -4) (undo-tree-id8896 . -4) (undo-tree-id8897 . -4) (undo-tree-id8898 . -4) (undo-tree-id8899 . -4) (undo-tree-id8900 . -4) (undo-tree-id8901 . -4) (undo-tree-id8902 . -4) (undo-tree-id8903 . -4) (undo-tree-id8904 . -4) (undo-tree-id8905 . -4) (undo-tree-id8906 . -4) (undo-tree-id8907 . -4) (undo-tree-id8908 . -4) (undo-tree-id8909 . -4) (undo-tree-id8910 . -4) (undo-tree-id8911 . -4) (undo-tree-id8912 . -4) (undo-tree-id8913 . -4) (undo-tree-id8914 . -4) (undo-tree-id8915 . -4) (undo-tree-id8916 . -4) (undo-tree-id8917 . -4) (undo-tree-id8918 . -4) (undo-tree-id8919 . -4) (undo-tree-id8920 . -8) (undo-tree-id8921 . -4) (undo-tree-id8922 . -4) (undo-tree-id8923 . -4) (undo-tree-id8924 . -4) (undo-tree-id8925 . -4) (undo-tree-id8926 . -4) (undo-tree-id8927 . -4) (undo-tree-id8928 . -4) (undo-tree-id8929 . -4) (undo-tree-id8930 . -4) (undo-tree-id8931 . -4) (undo-tree-id8932 . -4) (undo-tree-id8933 . -4) (undo-tree-id8934 . -4) (undo-tree-id8935 . -4) (undo-tree-id8936 . -4) (undo-tree-id8937 . -4) (undo-tree-id8938 . -4) (undo-tree-id8939 . -4) (undo-tree-id8940 . -4) (undo-tree-id8941 . -4) (undo-tree-id8942 . -4) (undo-tree-id8943 . -4) (undo-tree-id8944 . -4) (undo-tree-id8945 . -4) (undo-tree-id8946 . -4) (undo-tree-id8947 . -4) (undo-tree-id8948 . -4) (undo-tree-id8949 . -4) (undo-tree-id8950 . -4) (undo-tree-id8951 . -4) (undo-tree-id8952 . -4) (undo-tree-id8953 . -4) (undo-tree-id8954 . -4) (undo-tree-id8955 . -8) (undo-tree-id8956 . -4) (undo-tree-id8957 . -4) (undo-tree-id8958 . -4) (undo-tree-id8959 . -4) (undo-tree-id8960 . -4) (undo-tree-id8961 . -4) (undo-tree-id8962 . -4) (undo-tree-id8963 . -4) (undo-tree-id8964 . -4) (undo-tree-id8965 . -4) (undo-tree-id8966 . -4) (undo-tree-id8967 . -4) (undo-tree-id8968 . -4) (undo-tree-id8969 . -4) (undo-tree-id8970 . -4) (undo-tree-id8971 . -4) (undo-tree-id8972 . -4) (undo-tree-id8973 . -4) (undo-tree-id8974 . -5) (undo-tree-id8975 . -5) (undo-tree-id8976 . -5) (undo-tree-id8977 . -5) (undo-tree-id8978 . -5) (undo-tree-id8979 . -5) (undo-tree-id8980 . -5) (undo-tree-id8981 . -5) (undo-tree-id8982 . -5) (undo-tree-id8983 . -5) (undo-tree-id8984 . -5) (undo-tree-id8985 . -5) (undo-tree-id8986 . -5) (undo-tree-id8987 . -5) (undo-tree-id8988 . -5) (undo-tree-id8989 . -5) (undo-tree-id8990 . -5) (undo-tree-id8991 . -5) (undo-tree-id8992 . -5) (undo-tree-id8993 . -5) (undo-tree-id8994 . -5) (undo-tree-id8995 . -5) (undo-tree-id8996 . -5) (undo-tree-id8997 . -5) (undo-tree-id8998 . -5) (undo-tree-id8999 . -5) (undo-tree-id9000 . -5) (undo-tree-id9001 . -5) (undo-tree-id9002 . -5) (undo-tree-id9003 . -5) (undo-tree-id9004 . -5) (undo-tree-id9005 . -5) (undo-tree-id9006 . -5) (undo-tree-id9007 . -5) (undo-tree-id9008 . -5) (undo-tree-id9009 . -5) (undo-tree-id9010 . -5) (undo-tree-id9011 . -5) (undo-tree-id9012 . -5) (undo-tree-id9013 . -5) (undo-tree-id9014 . -5) (undo-tree-id9015 . -5) (undo-tree-id9016 . -5) (undo-tree-id9017 . -5) (undo-tree-id9018 . -5) (undo-tree-id9019 . -5) (undo-tree-id9020 . -5) (undo-tree-id9021 . -5) (undo-tree-id9022 . -5) (undo-tree-id9023 . -5) (undo-tree-id9024 . -5) (undo-tree-id9025 . -5) (undo-tree-id9026 . -6) (undo-tree-id9027 . -6) (undo-tree-id9028 . -6) (undo-tree-id9029 . -6) (undo-tree-id9030 . -6) (undo-tree-id9031 . -6) (undo-tree-id9032 . -6) (undo-tree-id9033 . -6) (undo-tree-id9034 . -6) (undo-tree-id9035 . -6) (undo-tree-id9036 . -6) (undo-tree-id9037 . -6) (undo-tree-id9038 . -6) (undo-tree-id9039 . -6) (undo-tree-id9040 . -6) (undo-tree-id9041 . -6) (undo-tree-id9042 . -6) (undo-tree-id9043 . -6) (undo-tree-id9044 . -6) (undo-tree-id9045 . -6) (undo-tree-id9046 . -6) (undo-tree-id9047 . -6) (undo-tree-id9048 . -6) (undo-tree-id9049 . -6) (undo-tree-id9050 . -6) (undo-tree-id9051 . -6) (undo-tree-id9052 . -7) (undo-tree-id9053 . -7) (undo-tree-id9054 . -7) (undo-tree-id9055 . -7) (undo-tree-id9056 . -7) (undo-tree-id9057 . -7) (undo-tree-id9058 . -7) (undo-tree-id9059 . -7) (undo-tree-id9060 . -7) (undo-tree-id9061 . -7) (undo-tree-id9062 . -7) (undo-tree-id9063 . -7) (undo-tree-id9064 . -7) (undo-tree-id9065 . -7) (undo-tree-id9066 . -7) (undo-tree-id9067 . -7) (undo-tree-id9068 . -7) (undo-tree-id9069 . -7) (undo-tree-id9070 . -7) (undo-tree-id9071 . -7) (undo-tree-id9072 . -7) (undo-tree-id9073 . -7) (undo-tree-id9074 . -7) (undo-tree-id9075 . -7) (undo-tree-id9076 . -7) (undo-tree-id9077 . -7) (undo-tree-id9078 . -7) (undo-tree-id9079 . -7) (undo-tree-id9080 . -7) (undo-tree-id9081 . -7) (undo-tree-id9082 . -7) (undo-tree-id9083 . -7) (undo-tree-id9084 . -7) (undo-tree-id9085 . -32)) nil (25760 29944 659128 665000) 0 nil] [nil nil ((1182 . 1183) (#("p" 0 1 (fontified t)) . 1182) (undo-tree-id8816 . -1)) ((1182 . 1183) (#("w" 0 1 (fontified t)) . 1182)) (25760 29933 210147 19000) 0 nil])
([nil current ((#("save_fig(\"time_series_plot\")
" 0 8 (fontified t) 8 9 (fontified t face (rainbow-delimiters-depth-1-face)) 9 27 (fontified t face font-lock-string-face) 27 28 (fontified t face (rainbow-delimiters-depth-1-face)) 28 29 (fontified t)) . 966) (undo-tree-id8824 . -28) (undo-tree-id8825 . -8) (undo-tree-id8826 . -8) (undo-tree-id8827 . -8) (undo-tree-id8828 . -8) (undo-tree-id8829 . -29)) nil (25760 29944 658424 787000) 0 nil])
nil
nil
